{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://yelp-dataset-bucket/data-munging.ipynb...\n",
      "Copying gs://yelp-dataset-bucket/getting-data.ipynb...                          \n",
      "Copying gs://yelp-dataset-bucket/map-reduce.ipynb...                            \n",
      "Copying gs://yelp-dataset-bucket/mapper.py...                                   \n",
      "/ [4 files][ 26.6 KiB/ 26.6 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://yelp-dataset-bucket/reducer.py...\n",
      "Copying gs://yelp-dataset-bucket/spark-ml.ipynb...                              \n",
      "Copying gs://yelp-dataset-bucket/working-with-hdfs.ipynb...                     \n",
      "Copying gs://yelp-dataset-bucket/yelp_academic_dataset_review.json...           \n",
      "/ [8 files][  5.9 GiB/  5.9 GiB]   51.7 MiB/s                                   \n",
      "Operation completed over 8 objects/5.9 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# getting data from the Google Cloud\n",
    "!gsutil cp gs://yelp-dataset-bucket/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading https://files.pythonhosted.org/packages/99/33/365c0d13f07a2a54744d027fe20b60dacdfdfb33bc04746db6ad0b79340b/kaggle-1.5.10.tar.gz (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/conda/anaconda/lib/python2.7/site-packages (from kaggle)\n",
      "Requirement already satisfied: certifi in /opt/conda/anaconda/lib/python2.7/site-packages (from kaggle)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/anaconda/lib/python2.7/site-packages (from kaggle)\n",
      "Requirement already satisfied: requests in /opt/conda/anaconda/lib/python2.7/site-packages (from kaggle)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/54/115f0c28a61d56674c3a5e05c46d6c3523ad196e1dcd3e2d8b119026df36/tqdm-4.54.1-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 5.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/42/e336f96a8b6007428df772d0d159b8eee9b2f1811593a4931150660402c0/python-slugify-4.0.1.tar.gz\n",
      "Requirement already satisfied: urllib3 in /opt/conda/anaconda/lib/python2.7/site-packages (from kaggle)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/anaconda/lib/python2.7/site-packages (from requests->kaggle)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/anaconda/lib/python2.7/site-packages (from requests->kaggle)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/a5/c0b6468d3824fe3fde30dbb5e1f687b291608f9473681bbf7dabbf5a87d7/text_unidecode-1.3-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 7.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
      "  Running setup.py bdist_wheel for kaggle ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3a/d1/7e/6ce09b72b770149802c653a02783821629146983ee5a360f10\n",
      "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/67/b8/ba/041548f30a6fc058c9b3f79a5b7b6aea925a15dd1e5c4992a4\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: tqdm, text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.10 python-slugify-4.0.1 text-unidecode-1.3 tqdm-4.54.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# you can download data from Kaggle directly using their package\n",
    "# https://github.com/Kaggle/kaggle-api\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: home/borisshminke/some.model/metadata/ (stored 0%)\r\n",
      "  adding: home/borisshminke/some.model/stages/ (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -9 some.zip /home/borisshminke/some.model/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  some.zip\r\n"
     ]
    }
   ],
   "source": [
    "# if you have a zipped data, you should unzip it before uploading to HDFS\n",
    "# storing zip-files on Googl Cloud is better\n",
    "!unzip some.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading your data to HDFS\n",
    "!hdfs dfs -put yelp_academic_dataset_review.json /user/borisshminke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading your data, JSON and CSV are preferred if using Spark\n",
    "data = (\n",
    "    spark.read\n",
    "    .json(\"/user/borisshminke/yelp_academic_dataset_review.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    Tokenizer(inputCol=\"text\", outputCol=\"words\"),\n",
    "    HashingTF(inputCol=\"words\", outputCol=\"term_frequency\"),\n",
    "    IDF(inputCol=\"term_frequency\", outputCol=\"features\"),\n",
    "    LinearRegression(labelCol=\"stars\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your param grid, use at least two options\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\"regParam\", [0])\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a small fraction of data for debug\n",
    "# if running on all the data lasts forever, you can create a larger cluster\n",
    "# or if you run out of credits, don't wory, send an working copy on sample\n",
    "debug_data = data.sample(0.01).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use cross validation here, or split on train and test manually\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "models = TrainValidationSplit(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=RegressionEvaluator(labelCol=\"stars\")\n",
    ").fit(debug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassClassificationEvaluator_42a29d5ede0a3a45f6b4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a classification use a tangible metric\n",
    "# http://spark.apache.org/docs/2.4.3/api/python/pyspark.ml.html#module-pyspark.ml.evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "MulticlassClassificationEvaluator(metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.27781356143004]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reporting values for training set is not necessary\n",
    "models.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rmse'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# be sure to use the right metric:)\n",
    "models.getEvaluator().getMetricName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deadline is Jan 8th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting model on all data (without splits)\n",
    "some_model = pipeline.fit(debug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_4bcf8c3f854bcd357c1b"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a train model\n",
    "some_model.write().overwrite().save(\"/user/borisshminke/some.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "drwxr-xr-x   - root hadoop          0 2020-12-17 14:05 /user/borisshminke/some.model/stages/0_Tokenizer_4e15be7484ded4f2fdff\r\n",
      "drwxr-xr-x   - root hadoop          0 2020-12-17 14:05 /user/borisshminke/some.model/stages/1_HashingTF_4a109dbe8d4c890f79a0\r\n",
      "drwxr-xr-x   - root hadoop          0 2020-12-17 14:05 /user/borisshminke/some.model/stages/2_IDF_438581dbe3d72dc01450\r\n",
      "drwxr-xr-x   - root hadoop          0 2020-12-17 14:05 /user/borisshminke/some.model/stages/3_LinearRegression_4aa58c2169880984a486\r\n"
     ]
    }
   ],
   "source": [
    "# check that the model was saved\n",
    "!hdfs dfs -ls /user/borisshminke/some.model/stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model from HDFS\n",
    "!hdfs dfs -get /user/borisshminke/some.model /home/borisshminke/some.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/borisshminke/some.model/stages/2_IDF_438581dbe3d72dc01450/metadata/part-00000 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/2_IDF_438581dbe3d72dc01450/metadata/_SUCCESS [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/2_IDF_438581dbe3d72dc01450/data/part-00000-848624a9-7100-4804-8e2c-44ccdd011e34-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/2_IDF_438581dbe3d72dc01450/data/_SUCCESS [Content-Type=application/octet-stream]...\n",
      "/ [4 files][248.4 KiB/248.4 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file:///home/borisshminke/some.model/stages/3_LinearRegression_4aa58c2169880984a486/metadata/part-00000 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/3_LinearRegression_4aa58c2169880984a486/metadata/_SUCCESS [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/3_LinearRegression_4aa58c2169880984a486/data/part-00000-efa39c68-0cca-4f23-bd92-1be7877cdfbf-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/3_LinearRegression_4aa58c2169880984a486/data/_SUCCESS [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/1_HashingTF_4a109dbe8d4c890f79a0/metadata/part-00000 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/1_HashingTF_4a109dbe8d4c890f79a0/metadata/_SUCCESS [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/0_Tokenizer_4e15be7484ded4f2fdff/metadata/part-00000 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/stages/0_Tokenizer_4e15be7484ded4f2fdff/metadata/_SUCCESS [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/metadata/part-00000 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/borisshminke/some.model/metadata/_SUCCESS [Content-Type=application/octet-stream]...\n",
      "\\ [14 files][  1.9 MiB/  1.9 MiB]                                               \n",
      "Operation completed over 14 objects/1.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# uploading your model to Google Cloud Storage\n",
    "!gsutil cp -r /home/borisshminke/some.model gs://yelp-dataset-bucket/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can load the model which you saved previously\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "some_model = PipelineModel.read().load(\"/user/borisshminke/some.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_predictions = some_model.transform(debug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3824686010483127"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "RegressionEvaluator(labelCol=\"stars\").evaluate(\n",
    "    some_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id',\n",
       " 'cool',\n",
       " 'date',\n",
       " 'funny',\n",
       " 'review_id',\n",
       " 'stars',\n",
       " 'text',\n",
       " 'useful',\n",
       " 'user_id']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79613\n",
      "79613\n"
     ]
    }
   ],
   "source": [
    "print(debug_data.count())\n",
    "print(debug_data.dropna().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to do scaling and prepare number columns for feeding a model\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    VectorAssembler(\n",
    "        inputCols=[\"funny\", \"useful\", \"cool\"],\n",
    "        outputCol=\"pre_features\"\n",
    "    ),\n",
    "    MinMaxScaler(inputCol=\"pre_features\", outputCol=\"features\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+--------------------+-------------+\n",
      "|funny|useful|cool|            features| pre_features|\n",
      "+-----+------+----+--------------------+-------------+\n",
      "|    0|     0|   0|       [0.0,0.0,0.0]|    (3,[],[])|\n",
      "|    1|     6|   1|[0.00584795321637...|[1.0,6.0,1.0]|\n",
      "|    0|     0|   0|       [0.0,0.0,0.0]|    (3,[],[])|\n",
      "|    1|     2|   0|[0.00584795321637...|[1.0,2.0,0.0]|\n",
      "|    0|     1|   0|[0.0,0.0067114093...|[0.0,1.0,0.0]|\n",
      "|    0|     0|   0|       [0.0,0.0,0.0]|    (3,[],[])|\n",
      "|    0|     0|   0|       [0.0,0.0,0.0]|    (3,[],[])|\n",
      "|    0|     0|   0|       [0.0,0.0,0.0]|    (3,[],[])|\n",
      "|    0|     1|   0|[0.0,0.0067114093...|[0.0,1.0,0.0]|\n",
      "|    0|     1|   0|[0.0,0.0067114093...|[0.0,1.0,0.0]|\n",
      "|    0|     0|   1|[0.0,0.0,0.007194...|[0.0,0.0,1.0]|\n",
      "|    0|     0|   1|[0.0,0.0,0.007194...|[0.0,0.0,1.0]|\n",
      "|    0|     5|   0|[0.0,0.0335570469...|[0.0,5.0,0.0]|\n",
      "|    0|     0|   0|       [0.0,0.0,0.0]|    (3,[],[])|\n",
      "|    1|     1|   5|[0.00584795321637...|[1.0,1.0,5.0]|\n",
      "|    0|     0|   0|       [0.0,0.0,0.0]|    (3,[],[])|\n",
      "|    1|     5|   4|[0.00584795321637...|[1.0,5.0,4.0]|\n",
      "|    0|     0|   0|       [0.0,0.0,0.0]|    (3,[],[])|\n",
      "|    0|     1|   1|[0.0,0.0067114093...|[0.0,1.0,1.0]|\n",
      "|    0|     2|   0|[0.0,0.0134228187...|[0.0,2.0,0.0]|\n",
      "+-----+------+----+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    pipeline.fit(debug_data).transform(debug_data)\n",
    "    .select(\"funny\", \"useful\", \"cool\", \"features\", \"pre_features\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>79613</td>\n",
       "      <td>79613</td>\n",
       "      <td>79613</td>\n",
       "      <td>79613</td>\n",
       "      <td>79613</td>\n",
       "      <td>79613</td>\n",
       "      <td>79613</td>\n",
       "      <td>79613</td>\n",
       "      <td>79613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5793651790536721</td>\n",
       "      <td>None</td>\n",
       "      <td>0.46796377476040346</td>\n",
       "      <td>None</td>\n",
       "      <td>3.706228882217728</td>\n",
       "      <td>None</td>\n",
       "      <td>1.3165814628264227</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>2.503847667428883</td>\n",
       "      <td>None</td>\n",
       "      <td>2.1866375974104084</td>\n",
       "      <td>None</td>\n",
       "      <td>1.489918562112281</td>\n",
       "      <td>None</td>\n",
       "      <td>3.4152387486574987</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-03-16 17:08:51</td>\n",
       "      <td>0</td>\n",
       "      <td>--0pfY3vQilgl20btE0fVQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>! ! ! BEST MASSAGE THERAPIST IN TOWN ! ! ! \\nA...</td>\n",
       "      <td>0</td>\n",
       "      <td>---1lKK3aKOuomHnwAkAow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25%</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50%</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75%</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max</td>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>139</td>\n",
       "      <td>2019-12-13 15:22:44</td>\n",
       "      <td>171</td>\n",
       "      <td>zzsSYtKmFzbg5as5n4LS_Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>（忘记照相了，也忘记菜名了...所以盗用了一些大家的图片）点了下面图上这几样小菜和面，味道感...</td>\n",
       "      <td>149</td>\n",
       "      <td>zzyrLRly27i2dQdsE4XdPg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary             business_id                cool                 date  \\\n",
       "0   count                   79613               79613                79613   \n",
       "1    mean                    None  0.5793651790536721                 None   \n",
       "2  stddev                    None   2.503847667428883                 None   \n",
       "3     min  --1UhMGODdWsrMastO9DZw                   0  2005-03-16 17:08:51   \n",
       "4     25%                    None                   0                 None   \n",
       "5     50%                    None                   0                 None   \n",
       "6     75%                    None                   0                 None   \n",
       "7     max  zzwicjPC9g246MK2M1ZFBA                 139  2019-12-13 15:22:44   \n",
       "\n",
       "                 funny               review_id              stars  \\\n",
       "0                79613                   79613              79613   \n",
       "1  0.46796377476040346                    None  3.706228882217728   \n",
       "2   2.1866375974104084                    None  1.489918562112281   \n",
       "3                    0  --0pfY3vQilgl20btE0fVQ                1.0   \n",
       "4                    0                    None                3.0   \n",
       "5                    0                    None                4.0   \n",
       "6                    0                    None                5.0   \n",
       "7                  171  zzsSYtKmFzbg5as5n4LS_Q                5.0   \n",
       "\n",
       "                                                text              useful  \\\n",
       "0                                              79613               79613   \n",
       "1                                               None  1.3165814628264227   \n",
       "2                                               None  3.4152387486574987   \n",
       "3  ! ! ! BEST MASSAGE THERAPIST IN TOWN ! ! ! \\nA...                   0   \n",
       "4                                               None                   0   \n",
       "5                                               None                   0   \n",
       "6                                               None                   1   \n",
       "7  （忘记照相了，也忘记菜名了...所以盗用了一些大家的图片）点了下面图上这几样小菜和面，味道感...                 149   \n",
       "\n",
       "                  user_id  \n",
       "0                   79613  \n",
       "1                    None  \n",
       "2                    None  \n",
       "3  ---1lKK3aKOuomHnwAkAow  \n",
       "4                    None  \n",
       "5                    None  \n",
       "6                    None  \n",
       "7  zzyrLRly27i2dQdsE4XdPg  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_data.summary().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(funny=0),\n",
       " Row(funny=1),\n",
       " Row(funny=0),\n",
       " Row(funny=1),\n",
       " Row(funny=0),\n",
       " Row(funny=0),\n",
       " Row(funny=0),\n",
       " Row(funny=0),\n",
       " Row(funny=0),\n",
       " Row(funny=0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_data.select(\"funny\").rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  17.1,\n",
       "  34.2,\n",
       "  51.300000000000004,\n",
       "  68.4,\n",
       "  85.5,\n",
       "  102.60000000000001,\n",
       "  119.70000000000002,\n",
       "  136.8,\n",
       "  153.9,\n",
       "  171],\n",
       " [79442, 133, 14, 12, 7, 3, 0, 0, 0, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# histograms are not ported yet to DataFrames API\n",
    "# so you need to use RDDs\n",
    "(\n",
    "    debug_data.select(\"funny\")\n",
    "    .rdd.map(lambda row: row[0])\n",
    "    .histogram(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41062"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_data.select(\"business_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical variables you can do one-hot encoding\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    StringIndexer(inputCol=\"business_id\", outputCol=\"category_id\"),\n",
    "    OneHotEncoder(inputCol=\"category_id\", outputCol=\"one\"),\n",
    "    VectorAssembler(\n",
    "        inputCols=[\"funny\", \"useful\", \"cool\", \"one\"],\n",
    "        outputCol=\"pre_features\"\n",
    "    ),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pre_features\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1  (1.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3  (1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "8  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    pipeline.fit(debug_data).transform(debug_data)\n",
    "    .select(\"pre_features\")\n",
    "    .limit(10)\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
