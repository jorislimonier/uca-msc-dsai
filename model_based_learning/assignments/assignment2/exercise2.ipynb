{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM algorithm for logistic regression\n",
    "\n",
    "The logistic regression model is defined as follows:\n",
    "\\begin{equation}\n",
    "\\mathbb{P}\\left(y_i=1 \\mid X_i ; \\beta\\right)=\\frac{1}{1+\\exp \\left(-X_i^T \\beta\\right)}\n",
    "\\end{equation}\n",
    "with $y_i \\in \\{0,1\\}$ and $X_i \\in \\mathbb{R}^{d}$.\n",
    "\n",
    "The log-likelihood $\\ell$ of the data is given by:\n",
    "\\begin{align*}\n",
    "\\mathcal{\\ell}(\\beta)\n",
    "&= \\sum_{i=1}^n \\left[y_i \\log \\mathbb{P}\\left(y_i=1 \\mid X_i ; \\beta\\right) + (1-y_i) \\log \\mathbb{P}\\left(y_i=0 \\mid X_i ; \\beta\\right)\\right] \\\\\n",
    "&= \\sum_{i=1}^n \\left[y_i \\log \\frac{1}{1+\\exp (-X_i^T \\beta)} + (1-y_i) \\log \\frac{\\exp (-X_i^T \\beta)}{1+\\exp (-X_i^T \\beta)}\\right] \\\\\n",
    "&= \\sum_{i=1}^n \\left[\\log \\frac{\\exp (-X_i^T \\beta)}{1+\\exp (-X_i^T \\beta)} + y_i \\left[ \\log \\frac{1}{1+\\exp (-X_i^T \\beta)} - \\log \\frac{\\exp (-X_i^T \\beta)}{1+\\exp (-X_i^T \\beta)}\\right]\\right] \\\\\n",
    "&= \\sum_{i=1}^n \\left[\\log \\frac{1}{1+\\exp (X_i^T \\beta)} + y_i \\log \\frac{1}{\\exp (-X_i^T \\beta)}\\right] \\\\\n",
    "&= \\sum_{i=1}^n \\left[- \\log \\left[1+\\exp (X_i^T \\beta)\\right] + y_i X_i^T \\beta\\right] \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, the observed log-likelihood $\\ell_{obs}$ is given by:\n",
    "\\begin{align*}\n",
    "\\ell_{obs}(\\beta)\n",
    "&= \\sum_{i=1}^n \\left[- \\log \\left[1+\\exp (X_i^T \\beta)\\right] + y_i X_i^T \\beta\\right] \\\\\n",
    "&= \\sum_{i=1}^n \\left[- \\log \\left[1+\\exp (X_i^T \\beta)\\right] + y_i \\left[ \\log \\frac{1}{1+\\exp (-X_i^T \\beta)} - \\log \\frac{\\exp (-X_i^T \\beta)}{1+\\exp (-X_i^T \\beta)}\\right]\\right] \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the EM algorithm for the synthetic data defined below. Compare the following estimators for $\\beta$ by computing the MSE:\n",
    "\n",
    "- (i) without missing values (y, X),\n",
    "- (ii) with missing values (yNA , X) by using only the rows which do not contain missing values,\n",
    "- (iii) with missing values (yNA , X) by using the EM algorithm.\n",
    "\n",
    "Note that in (i) and (ii), you just have to use the function glm. Here, you can consider that the intercept is null.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal, random\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Parameters\n",
    "d = 3\n",
    "beta_true = [0.1, 0.5, 0.9]\n",
    "n = 1000\n",
    "mu = np.zeros(d)\n",
    "Sigma = np.eye(d) + 0.5 * np.ones((d, d))\n",
    "\n",
    "# Generate multivariate Gaussian variable\n",
    "X = multivariate_normal(mean=mu, cov=Sigma, size=n)\n",
    "\n",
    "# Compute logit link\n",
    "logit_link = 1 / (1 + np.exp(-np.dot(X, beta_true)))\n",
    "\n",
    "# Generate binary response variable\n",
    "y = (random(n) < logit_link).astype(int)\n",
    "\n",
    "# Introduction of MCAR values\n",
    "nb_missingvalues = int(0.2 * n * d)\n",
    "missing_idx = np.random.choice(range(n), nb_missingvalues, replace=False)\n",
    "yna = y.copy()\n",
    "yna = np.where(np.isin(range(n), missing_idx), np.nan, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                          MSE\n",
      "----------------------------  -----\n",
      "MSE without missing values    0.275\n",
      "MSE with missing values       0.276\n",
      "MSE with missing values (EM)  0.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from exercise2 import LogisticRegressionEM\n",
    "\n",
    "# Compute the MSE without missing values (y, X) with the Python equivalent of glm\n",
    "# Fit the model\n",
    "model = LogisticRegression(fit_intercept=False, solver=\"lbfgs\")\n",
    "model.fit(X, y)\n",
    "\n",
    "# Compute the MSE\n",
    "y_pred = model.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "# Compute the MSE with missing values (yna , X) by using only the rows which do not contain missing values\n",
    "# Fit the model\n",
    "model = LogisticRegression(fit_intercept=False, solver=\"lbfgs\")\n",
    "model.fit(X[~np.isnan(yna)], yna[~np.isnan(yna)])\n",
    "\n",
    "# Compute the MSE\n",
    "y_pred = model.predict(X)\n",
    "mse_na = mean_squared_error(y, y_pred)\n",
    "\n",
    "# Compute the MSE with missing values (yna , X) by using a custom EM algorithm\n",
    "# Fit the model\n",
    "model = LogisticRegressionEM(X=X, y=yna, missing_mask=np.isnan(yna))\n",
    "model.fit()\n",
    "\n",
    "# Compute the MSE\n",
    "y_pred = model.predict(X)\n",
    "mse_em = mean_squared_error(y, y_pred)\n",
    "\n",
    "# Print results in a table\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\n",
    "  tabulate(\n",
    "    [\n",
    "      [\"MSE without missing values\", mse],\n",
    "      [\"MSE with missing values\", mse_na],\n",
    "      [\"MSE with missing values (EM)\", mse_em],\n",
    "    ],\n",
    "    headers=[\"Method\", \"MSE\"],\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we notice for estimators (ii) and (iii) ?\n",
    "\n",
    "We notice that the MSE is higher for the EM algorithm than for the other two estimators. This is due to the fact that the EM algorithm tries to estimate the missing values, which is not possible in this case. Howev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
