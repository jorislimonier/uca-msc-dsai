{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM algorithm for logistic regression\n",
    "\n",
    "The logistic regression model is defined as follows:\n",
    "\\begin{equation*}\n",
    "\\mathbb{P}\\left(y_i=1 \\mid X_i ; \\beta\\right)=\\frac{1}{1+\\exp \\left(-X_i^T \\beta\\right)}\n",
    "\\end{equation*}\n",
    "with $y_i \\in \\{0,1\\}$ and $X_i \\in \\mathbb{R}^{d}$.\n",
    "\n",
    "The log-likelihood $\\ell$ of the data is given by:\n",
    "\\begin{align*}\n",
    "\\mathcal{\\ell}(\\beta)\n",
    "&= \\sum*{i=1}^n \\left[y_i \\log \\mathbb{P}\\left(y_i=1 \\mid X_i ; \\beta\\right) + (1-y_i) \\log \\mathbb{P}\\left(y_i=0 \\mid X_i ; \\beta\\right)\\right] \\\\\n",
    "&= \\sum*{i=1}^n \\left[y_i \\log \\frac{1}{1+\\exp (-X_i^T \\beta)} + (1-y_i) \\log \\frac{\\exp (-X_i^T \\beta)}{1+\\exp (-X_i^T \\beta)}\\right] \\\\\n",
    "&= \\sum*{i=1}^n \\left[\\log \\frac{\\exp (-X_i^T \\beta)}{1+\\exp (-X_i^T \\beta)} + y_i \\left[ \\log \\frac{1}{1+\\exp (-X_i^T \\beta)} - \\log \\frac{\\exp (-X_i^T \\beta)}{1+\\exp (-X_i^T \\beta)}\\right]\\right] \\\\\n",
    "&= \\sum*{i=1}^n \\left[\\log \\frac{1}{1+\\exp (X_i^T \\beta)} + y_i \\log \\frac{1}{\\exp (-X_i^T \\beta)}\\right] \\\\\n",
    "&= \\sum\\_{i=1}^n \\left[- \\log \\left[1+\\exp (X_i^T \\beta)\\right] + y_i X_i^T \\beta\\right] \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, the full log-likelihood, taking into account missing data, $\\ell_{full}$ is given by:\n",
    "\\begin{align*}\n",
    "\\ell\\_{full}(\\beta)\n",
    "&= \\log \\prod_{i=1}^{n} \\left\\{ \\mathbb{P}(y_i | x_i, \\beta)^{\\boldsymbol{1}_{(y_i \\text{ observed})}} \\mathbb{P}(y_i | x_i, \\beta)^{\\boldsymbol{1}_{(y_i \\text{ missing})}} \\right\\} \\\\\n",
    "&= \\sum_{i=1}^{n} \\left\\{ \\boldsymbol{1}_{(y_i \\text{ observed})} \\log \\mathbb{P}(y_i | x_i, \\beta) + \\boldsymbol{1}_{(y_i \\text{ missing})} \\log \\mathbb{P}(y_i | x_i, \\beta) \\right\\} \\\\\n",
    "&= \\sum_{i=1}^{n} \\left\\{ \\boldsymbol{1}_{(y_i \\text{ observed})} \\left[ y_i \\log \\left( \\frac{1}{1+e^{-x_i^T \\beta}} \\right) + (1-y_i) \\log \\left( 1 - \\frac{1}{1+e^{-x_i^T \\beta}} \\right) \\right] \\right. + \\\\\n",
    "&\\left. \\boldsymbol{1}_{(y_i \\text{ missing})} \\mathbb{E}\\left[ y_i | x_i, \\beta, y_{obs} \\right] \\log \\left( \\frac{1}{1+e^{-x_i^T \\beta}} \\right) + (1-\\mathbb{E}\\left[ y_i | x_i, \\beta, y_{obs} \\right]) \\log \\left( 1 - \\frac{1}{1+e^{-x_i^T \\beta}} \\right) \\right\\}\n",
    "\\end{align*}\n",
    "\n",
    "where $y_{ij} \\in \\{0,1\\}$ is the $j$-th label of the $i$-th sample.\n",
    "\n",
    "We now want to show that the E-step can be written as follows:\n",
    "\\begin{equation*}\n",
    "Q(\\beta; \\beta^{(r)}) = \\sum_{i=1}^n Q_i(\\beta; \\beta^{(r)})\n",
    "\\end{equation*}\n",
    "where $\\beta^{(r)}$ is the current estimate of $\\beta$, and $Q_i(\\beta; \\beta^{(r)})$ is given by:\n",
    "\\begin{equation*}\n",
    "Q_i(\\beta; \\beta^{(r)}) =\n",
    "\\begin{cases}\n",
    "\\sum*{y_i \\in \\{0, 1\\}} \\mathbb{P}(y_i \\mid x_i; \\beta^{(r)}) \\log \\mathbb{P}(y_i \\mid x_i; \\beta) & y \\text{ is missing.}\\\\\n",
    "\\log \\mathbb{P}(y_i \\mid x_i; \\beta) & \\text{otherwise.} \\\\\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "Here is the proof:\n",
    "\\begin{align*}\n",
    "Q(\\beta; \\beta^{(r)})\n",
    "&= \\ldots\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the EM algorithm for the synthetic data defined below. Compare the following estimators for $\\beta$ by computing the MSE:\n",
    "\n",
    "- (i) without missing values (y, X),\n",
    "- (ii) with missing values (yNA , X) by using only the rows which do not contain missing values,\n",
    "- (iii) with missing values (yNA , X) by using the EM algorithm.\n",
    "\n",
    "Note that in (i) and (ii), you just have to use the function glm. Here, you can consider that the intercept is null.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from exercise2 import LogisticRegressionEM\n",
    "from numpy.random import multivariate_normal, random\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "d = 3\n",
    "beta_true = [0.1, 0.5, 0.9]\n",
    "n = 1000\n",
    "mu = np.zeros(d)\n",
    "sigma = np.eye(d) + 0.5 * np.ones((d, d))\n",
    "\n",
    "# Generate multivariate Gaussian variable\n",
    "X = multivariate_normal(mean=mu, cov=sigma, size=n)\n",
    "\n",
    "# Compute logit link\n",
    "logit_link = 1 / (1 + np.exp(-np.dot(X, beta_true)))\n",
    "\n",
    "# Generate binary response variable\n",
    "y = (random(n) < logit_link).astype(int)\n",
    "\n",
    "# Introduction of MCAR values\n",
    "nb_missingvalues = int(0.2 * n * d)\n",
    "missing_idx = np.random.choice(range(n), nb_missingvalues, replace=False)\n",
    "yna = y.copy()\n",
    "yna = np.where(np.isin(range(n), missing_idx), np.nan, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                          MSE\n",
      "----------------------------  -----\n",
      "MSE without missing values    0.271\n",
      "MSE with missing values       0.273\n",
      "MSE with missing values (EM)  0.373\n"
     ]
    }
   ],
   "source": [
    "# Compute the MSE without missing values (y, X) with the Python equivalent of glm\n",
    "# Fit the model\n",
    "model = LogisticRegression(fit_intercept=False, solver=\"lbfgs\", max_iter=1000, tol=1e-6)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Compute the MSE\n",
    "y_pred = model.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "\n",
    "# Compute the MSE with missing values (yna , X) by using only the rows which do not contain missing values\n",
    "# Fit the model\n",
    "model = LogisticRegression(fit_intercept=False, solver=\"lbfgs\", max_iter=1000, tol=1e-6)\n",
    "model.fit(X[~np.isnan(yna)], yna[~np.isnan(yna)])\n",
    "\n",
    "# Compute the MSE\n",
    "y_pred = model.predict(X)\n",
    "mse_na = mean_squared_error(y, y_pred)\n",
    "\n",
    "\n",
    "# Compute the MSE with missing values (yna , X) by using a custom EM algorithm\n",
    "# Fit the model\n",
    "model = LogisticRegressionEM(X=X, y=yna, missing_mask=np.isnan(yna))\n",
    "model.fit()\n",
    "\n",
    "# Compute the MSE\n",
    "y_pred = model.predict(X)\n",
    "mse_em = mean_squared_error(y, y_pred)\n",
    "\n",
    "\n",
    "# Print results in a table\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\n",
    "  tabulate(\n",
    "    [\n",
    "      [\"MSE without missing values\", mse],\n",
    "      [\"MSE with missing values\", mse_na],\n",
    "      [\"MSE with missing values (EM)\", mse_em],\n",
    "    ],\n",
    "    headers=[\"Method\", \"MSE\"],\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we notice for estimators (ii) and (iii) ?\n",
    "\n",
    "We notice that the MSE is higher for the estimator (iii) than for the estimator (ii).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer prostate data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Read data\n",
    "canpros = pd.read_csv(\"cancerprostate.csv\", sep=\";\")\n",
    "\n",
    "# Select quantitative variables\n",
    "quanti_var = [0, 1, 5, 6]\n",
    "canpros = canpros.iloc[:, quanti_var]\n",
    "\n",
    "# Define response variable and predictor matrix\n",
    "n = canpros.shape[0]\n",
    "y = canpros[\"Y\"]\n",
    "X = np.hstack((np.ones((n, 1)), canpros[[\"age\", \"acide\", \"log.acid\"]]))\n",
    "d = X.shape[1]\n",
    "\n",
    "# Introduction of MCAR values\n",
    "nb_missingvalues = int(0.2 * n * d)\n",
    "missing_idx = np.random.choice(range(n), nb_missingvalues, replace=False)\n",
    "yna = y.copy()\n",
    "yna.iloc[missing_idx] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                           beta_0    beta_1    beta_2    beta_3       MSE\n",
      "-----------------------------  --------  --------  --------  --------  --------\n",
      "beta with missing values (EM)    1.1419   -1.1296   -0.8501    0.9608  0.377358\n",
      "beta with missing values         0.0006   -0.0782    0.0985    0.1818  0.377358\n",
      "beta without missing values      0        -0.0507    0.4026    0.9858  0.339623\n"
     ]
    }
   ],
   "source": [
    "# Apply the EM algorithm and compare different estimators for beta\n",
    "# Fit the model\n",
    "model = LogisticRegressionEM(X=X, y=yna, missing_mask=np.isnan(yna))\n",
    "model.fit()\n",
    "beta_em = model.beta\n",
    "\n",
    "# Compute MSE\n",
    "y_pred_em = model.predict(X)\n",
    "mse_em = mean_squared_error(y, y_pred_em)\n",
    "\n",
    "\n",
    "# Compute beta with missing values by using only the rows which do not contain missing values, with intercept\n",
    "# Fit the model\n",
    "model = LogisticRegression(fit_intercept=True, max_iter=1000, tol=1e-6)\n",
    "model.fit(X[~np.isnan(yna)], yna[~np.isnan(yna)])\n",
    "beta_na = model.coef_\n",
    "\n",
    "# Compute MSE\n",
    "y_pred_na = model.predict(X)\n",
    "mse_na = mean_squared_error(y, y_pred_na)\n",
    "\n",
    "\n",
    "# Compute beta without missing values, with intercept\n",
    "model = LogisticRegression(fit_intercept=True, max_iter=1000, tol=1e-6)\n",
    "model.fit(X, y)\n",
    "beta_full = model.coef_\n",
    "\n",
    "# Compute MSE\n",
    "y_pred_full = model.predict(X)\n",
    "mse_full = mean_squared_error(y, y_pred_full)\n",
    "\n",
    "# Print results in a table\n",
    "print(\n",
    "  tabulate(\n",
    "    [\n",
    "      [\"beta with missing values (EM)\", *beta_em.round(4), mse_em],\n",
    "      [\"beta with missing values\", *beta_na[0].round(4), mse_na],\n",
    "      [\"beta without missing values\", *beta_full[0].round(4), mse_full],\n",
    "    ],\n",
    "    headers=[\"Method\", *[f\"beta_{i}\" for i in range(len(beta_em))], \"MSE\"],\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  6.60000000e+01,  4.80000000e-01,\n",
       "        -7.33969175e-01],\n",
       "       [ 1.00000000e+00,  6.80000000e+01,  5.60000000e-01,\n",
       "        -5.79818495e-01],\n",
       "       [ 1.00000000e+00,  6.60000000e+01,  5.00000000e-01,\n",
       "        -6.93147181e-01],\n",
       "       [ 1.00000000e+00,  5.60000000e+01,  5.20000000e-01,\n",
       "        -6.53926467e-01],\n",
       "       [ 1.00000000e+00,  5.80000000e+01,  5.00000000e-01,\n",
       "        -6.93147181e-01],\n",
       "       [ 1.00000000e+00,  6.00000000e+01,  4.90000000e-01,\n",
       "        -7.13349888e-01],\n",
       "       [ 1.00000000e+00,  6.50000000e+01,  4.60000000e-01,\n",
       "        -7.76528789e-01],\n",
       "       [ 1.00000000e+00,  6.00000000e+01,  6.20000000e-01,\n",
       "        -4.78035801e-01],\n",
       "       [ 1.00000000e+00,  5.00000000e+01,  5.60000000e-01,\n",
       "        -5.79818495e-01],\n",
       "       [ 1.00000000e+00,  4.90000000e+01,  5.50000000e-01,\n",
       "        -5.97837001e-01],\n",
       "       [ 1.00000000e+00,  6.10000000e+01,  6.20000000e-01,\n",
       "        -4.78035801e-01],\n",
       "       [ 1.00000000e+00,  5.80000000e+01,  7.10000000e-01,\n",
       "        -3.42490309e-01],\n",
       "       [ 1.00000000e+00,  5.10000000e+01,  6.50000000e-01,\n",
       "        -4.30782916e-01],\n",
       "       [ 1.00000000e+00,  6.70000000e+01,  6.70000000e-01,\n",
       "        -4.00477567e-01],\n",
       "       [ 1.00000000e+00,  6.70000000e+01,  4.70000000e-01,\n",
       "        -7.55022584e-01],\n",
       "       [ 1.00000000e+00,  5.10000000e+01,  4.90000000e-01,\n",
       "        -7.13349888e-01],\n",
       "       [ 1.00000000e+00,  5.60000000e+01,  5.00000000e-01,\n",
       "        -6.93147181e-01],\n",
       "       [ 1.00000000e+00,  6.00000000e+01,  7.80000000e-01,\n",
       "        -2.48461359e-01],\n",
       "       [ 1.00000000e+00,  5.20000000e+01,  8.30000000e-01,\n",
       "        -1.86329578e-01],\n",
       "       [ 1.00000000e+00,  5.60000000e+01,  9.80000000e-01,\n",
       "        -2.02027073e-02],\n",
       "       [ 1.00000000e+00,  6.70000000e+01,  5.20000000e-01,\n",
       "        -6.53926467e-01],\n",
       "       [ 1.00000000e+00,  6.30000000e+01,  7.50000000e-01,\n",
       "        -2.87682072e-01],\n",
       "       [ 1.00000000e+00,  5.90000000e+01,  9.90000000e-01,\n",
       "        -1.00503359e-02],\n",
       "       [ 1.00000000e+00,  6.40000000e+01,  1.87000000e+00,\n",
       "         6.25938431e-01],\n",
       "       [ 1.00000000e+00,  6.10000000e+01,  1.36000000e+00,\n",
       "         3.07484700e-01],\n",
       "       [ 1.00000000e+00,  5.60000000e+01,  8.20000000e-01,\n",
       "        -1.98450939e-01],\n",
       "       [ 1.00000000e+00,  6.40000000e+01,  4.00000000e-01,\n",
       "        -9.16290732e-01],\n",
       "       [ 1.00000000e+00,  6.10000000e+01,  5.00000000e-01,\n",
       "        -6.93147181e-01],\n",
       "       [ 1.00000000e+00,  6.40000000e+01,  5.00000000e-01,\n",
       "        -6.93147181e-01],\n",
       "       [ 1.00000000e+00,  6.30000000e+01,  4.00000000e-01,\n",
       "        -9.16290732e-01],\n",
       "       [ 1.00000000e+00,  5.20000000e+01,  5.50000000e-01,\n",
       "        -5.97837001e-01],\n",
       "       [ 1.00000000e+00,  6.60000000e+01,  5.90000000e-01,\n",
       "        -5.27632742e-01],\n",
       "       [ 1.00000000e+00,  5.80000000e+01,  4.80000000e-01,\n",
       "        -7.33969175e-01],\n",
       "       [ 1.00000000e+00,  5.70000000e+01,  5.10000000e-01,\n",
       "        -6.73344553e-01],\n",
       "       [ 1.00000000e+00,  6.50000000e+01,  4.90000000e-01,\n",
       "        -7.13349888e-01],\n",
       "       [ 1.00000000e+00,  6.50000000e+01,  4.80000000e-01,\n",
       "        -7.33969175e-01],\n",
       "       [ 1.00000000e+00,  5.90000000e+01,  6.30000000e-01,\n",
       "        -4.62035460e-01],\n",
       "       [ 1.00000000e+00,  6.10000000e+01,  1.02000000e+00,\n",
       "         1.98026273e-02],\n",
       "       [ 1.00000000e+00,  5.30000000e+01,  7.60000000e-01,\n",
       "        -2.74436846e-01],\n",
       "       [ 1.00000000e+00,  6.70000000e+01,  9.50000000e-01,\n",
       "        -5.12932944e-02],\n",
       "       [ 1.00000000e+00,  5.30000000e+01,  6.60000000e-01,\n",
       "        -4.15515444e-01],\n",
       "       [ 1.00000000e+00,  6.50000000e+01,  8.40000000e-01,\n",
       "        -1.74353387e-01],\n",
       "       [ 1.00000000e+00,  5.00000000e+01,  8.10000000e-01,\n",
       "        -2.10721031e-01],\n",
       "       [ 1.00000000e+00,  6.00000000e+01,  7.60000000e-01,\n",
       "        -2.74436846e-01],\n",
       "       [ 1.00000000e+00,  4.50000000e+01,  7.00000000e-01,\n",
       "        -3.56674944e-01],\n",
       "       [ 1.00000000e+00,  5.60000000e+01,  7.80000000e-01,\n",
       "        -2.48461359e-01],\n",
       "       [ 1.00000000e+00,  4.60000000e+01,  7.00000000e-01,\n",
       "        -3.56674944e-01],\n",
       "       [ 1.00000000e+00,  6.70000000e+01,  6.70000000e-01,\n",
       "        -4.00477567e-01],\n",
       "       [ 1.00000000e+00,  6.30000000e+01,  8.20000000e-01,\n",
       "        -1.98450939e-01],\n",
       "       [ 1.00000000e+00,  5.70000000e+01,  6.70000000e-01,\n",
       "        -4.00477567e-01],\n",
       "       [ 1.00000000e+00,  5.10000000e+01,  7.20000000e-01,\n",
       "        -3.28504067e-01],\n",
       "       [ 1.00000000e+00,  6.40000000e+01,  8.90000000e-01,\n",
       "        -1.16533816e-01],\n",
       "       [ 1.00000000e+00,  6.80000000e+01,  1.26000000e+00,\n",
       "         2.31111721e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_em, y_pred_na, y_pred_full, y\n",
    "X\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss the link with semi-supervised learning\n",
    "\n",
    "The EM algorithm can be used as a semi-supervised learning algorithm. Indeed, it is used to estimate the parameters of a model when some of the data are missing. In this case, the missing data are the values of the response variable `y`. This is the definition of semi-supervised learning, _i.e._ the learning of a model when some of the data is present, but not all of them. This is a very common situation in real life, for example when we have to estimate the parameters of a model when we have a small number of labeled observations, but a large number of unlabeled observations (_e.g._ when labeling is expensive). This may be the case for cancer data where medical doctors have to label each and every data point, which is very time consuming. In this case, the EM algorithm can be used to estimate the parameters of the model when some of the data is missing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
