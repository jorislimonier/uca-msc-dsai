\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue, 
}

\newcommand{\1}{\mathbf{1}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Rcal}{\mathcal{R}}
\renewcommand{\P}{\mathbb{P}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\thetahat}{\hat\theta}
\newcommand{\ie}{\textit{i.e. }}
\newcommand{\var}{\operatorname{Var}}


\title{Introduction to Information Theory}
\author{Joris LIMONIER}
\begin{document}
\maketitle

\tableofcontents

\section{Exercise sheet}
\subsection{Exercise 1}
Given a game of 52 cards, we draws cards with replacement.

\paragraph{Probability to get a queen}
There are 4 queens in the deck, so the probability to get a queen is:
$$\P(queen) = 4/52.$$

\paragraph{Probability to get a heart}
There are 13 hearts in the deck, so the probability to get a heart is:
$$\P(heart) = 13/52.$$

\paragraph{Probability to get the queen of hearts or the ace of spades}
There is one queen of heart and one ace of spades, which are disjoint events, so the probability to get one of them is:
\begin{align*}
  \P(\text{QH or AS}) & = \P(QH) + \P(AS) \\
                      & = 1/52 + 1/52     \\
                      & = 2/52
\end{align*}

\paragraph{Probability to get a queen or a spade}
There are 4 queens and 13 spades, which are not disjoint events, so the probability to get one of them is:
\begin{align*}
  \P(\text{Q or S}) & = \P(Q) + \P(S) - \P(Q \cap S) \\
                    & = 4/52 + 13/52 - 1/52          \\
                    & = 16/52
\end{align*}

\paragraph{Probability to get neither a queen, nor a spade}
This is the complement of the previous event, so the probability to get neither a queen, nor a spade is:
\begin{align*}
  \P(\text{not Q and not S}) & = 1 - \P(\text{Q or S}) \\
                             & = 1 - 16/52             \\
                             & = 36/52
\end{align*}


\subsection{Exercise 2}
We draw one ball from an urn with 5 white balls, 4 red balls and 2 black balls.

\paragraph{Probability to draw white}
There are 11 balls in total and 5 white balls, so the probability to draw a white ball is:
$$\P(W) = 5/11$$

\paragraph{Probability to draw not white}
This is the complement of the previous event, so the probability to draw not white is:
\begin{align*}
  \P(\neg W)
   & = 1 - \P(W) \\
   & = 6/11
\end{align*}

\paragraph{Probability to draw white or red}
These events are disoint, so the probability to draw a white or a red ball is:
\begin{align*}
  \P(W \cup R)
   & = \P(W) + \P(R) \\
   & = 5/11 + 4/11   \\
   & = 9/11
\end{align*}

\subsection{Exercise 3}
\subsection{Exercise 4}
\subsection{Exercise 5}
\subsection{Exercise 6}
\subsection{Exercise 7}


\section{Exercise sheet Quantitative Measure of Information (part 1)}
\subsection{Exercise 6}
Given
\begin{align*}
  \P(X = 0) & = \frac{1}{4} \\
  \P(X = 1) & = \frac{3}{4} \\
  p_0       & = 10^{-1}
\end{align*}
where $p_0$ is the probability of incorrect transmission of a bit.


\paragraph{Compute $H(X)$}
\begin{align*}
  H(X) & = - \sum_{i=1}^{m} \P(X = x_i) \log_2 \P(X = x_i)                   \\
       & = - \frac{1}{4} \log_2 \frac{1}{4} - \frac{3}{4} \log_2 \frac{3}{4} \\
       & \approx 0.811 \text{ sh / state of X}
\end{align*}


\paragraph{Compute $H(Y)$}
We first compute the probability distribution of $Y$:
\begin{align*}
  \P(Y = 1)
   & = \P(Y = 1, X = 0) + \P(Y = 1, X = 1)                             \\
   & = \P(Y = 1 \mid X = 0) \P(X = 0) + \P(Y = 1 \mid X = 1) \P(X = 1) \\
   & = p_0 \frac{1}{4} + (1 - p_0) \frac{3}{4}                         \\
   & = 10^{-1} \frac{1}{4} + (1 - 10^{-1}) \frac{3}{4}                 \\
   & = \frac{1}{10} \frac{1}{4} + \frac{9}{10} \frac{3}{4}             \\
   & = \frac{1}{40} + \frac{27}{40}                                    \\
   & = \frac{28}{40}                                                   \\
\end{align*}
and on the other hand:
\begin{align*}
  \P(Y = 0)
   & = \P(Y = 0, X = 0) + \P(Y = 0, X = 1)                             \\
   & = \P(Y = 0 \mid X = 0) \P(X = 0) + \P(Y = 0 \mid X = 1) \P(X = 1) \\
   & = (1 - p_0) \frac{1}{4} + p_0 \frac{3}{4}                         \\
   & = \frac{9}{10} \frac{1}{4} + \frac{1}{10} \frac{3}{4}             \\
   & = \frac{9}{40} + \frac{3}{40}                                     \\
   & = \frac{12}{40}                                                   \\
\end{align*}
\begin{align*}
  H(Y) & = - \sum_{i=1}^{m} \P(Y = y_i) \log_2 \P(Y = y_i)                           \\
       & = - \frac{28}{40} \log_2 \frac{28}{40} - \frac{12}{40} \log_2 \frac{12}{40} \\
       & = - \frac{28}{40} \log_2 \frac{28}{40} - \frac{12}{40} \log_2 \frac{12}{40} \\
       & \approx 0.881 \text{ sh / state of Y}
\end{align*}
So we have:
$$
  \begin{cases}
    \P(X = 0, Y = 0) = \frac{9}{40} \\
    \P(X = 0, Y = 1) = \frac{1}{40} \\
    \P(X = 1, Y = 0) = \frac{3}{40} \\
    \P(X = 1, Y = 1) = \frac{27}{40}
  \end{cases}
$$

\paragraph{Compute $H(X, Y)$}
\begin{align*}
  H(X, Y)
   & = - \sum_{i=1}^n \sum_{j=1}^m \P(X = x_i, Y = y_j) \log \P(X = x_i, Y = y_j)                                                            \\
   & = - \P(X = 0, Y = 0) \log \P(X = 0, Y = 0)                                                                                              \\
   & - \P(X = 0, Y = 1) \log \P(X = 0, Y = 1)                                                                                                \\
   & - \P(X = 1, Y = 0) \log \P(X = 1, Y = 0)                                                                                                \\
   & - \P(X = 1, Y = 1) \log \P(X = 1, Y = 1)                                                                                                \\
   & = - \frac{9}{40} \log \frac{9}{40} - \frac{1}{40} \log \frac{1}{40} - \frac{3}{40} \log \frac{3}{40} - \frac{27}{40} \log \frac{27}{40} \\
   & \approx 1.28                                                                                                                            \\
\end{align*}

\paragraph{Compute $H(Y \mid X)$}
\begin{align*}
  H(Y \mid X)
   & = H(X, Y) - H(Y)              \\
   & = 1.28 - 0.88                 \\
   & = 0.4 \text{ sh / state of X}
\end{align*}

\paragraph{Compute $H(X \mid Y)$}
\begin{align*}
  H(X \mid Y)
   & = H(X, Y) - H(X)               \\
   & = 1.28 - 0.81                  \\
   & = 0.47 \text{ sh / state of Y}
\end{align*}


\paragraph{Compute $I(X, Y)$}
\begin{align*}
  I(X, Y)
   & = H(X) - H(X \mid Y)                \\
   & = 0.81 - 0.40                       \\
   & = 0.41 \text{ sh / state of (X, Y)}
\end{align*}

\section{Exercise sheet Quantitative Measure of Information (part 2)}
\subsection{Exercise}
\paragraph{$Y$ is uniformly distributed}
\begin{align*}
  \P(Y = y_1)
   & = \frac{1}{24} + \frac{1}{6} + \frac{1}{24} \\
   & = \frac{6}{24}                              \\
\end{align*}
\begin{align*}
  \P(Y = y_2)
   & = \frac{1}{12} + \frac{1}{8} + \frac{1}{24} \\
   & = \frac{6}{24}                              \\
\end{align*}
\begin{align*}
  \P(Y = y_3)
   & = \frac{1}{6} + \frac{1}{24} + \frac{1}{24} \\
   & = \frac{6}{24}                              \\
\end{align*}
\begin{align*}
  \P(Y = y_4)
   & = \frac{1}{6} + \frac{1}{6} + \frac{1}{24} \\
   & = \frac{6}{24}                             \\
\end{align*}
$Y$ is indeed uniformly distributed.

\paragraph{Compute $I(X, Y)$}
\begin{align*}
  I(X, Y)
   & = H(Y) - H(Y \mid X)     \\
   & = \log_2 4 - H(Y \mid X) \\
\end{align*}
The distribution of $X$ is given by:
$$
  \begin{cases}
    \P(X = x_1) = \frac{1}{3} \\
    \P(X = x_2) = \frac{1}{2} \\
    \P(X = x_3) = \frac{1}{6} \\
  \end{cases}
$$

\begin{align*}
  H(Y \mid X)
   & = \sum_{i=1}^3 H(Y \mid X = x_i) \log \P(X = x_i) \\
\end{align*}

\subsection{Problem}

\subsubsection*{1.}

\begin{align*}
  \P(M = 0)
   & = \P(M = 0, T = 0) + \P(M = 0, T = 1) \\
   & = 1/8 + 3/16                          \\
   & = 5/16                                \\
\end{align*}
\begin{align*}
  \P(M = 1)
   & = \P(M = 1, T = 0) + \P(M = 1, T = 1) \\
   & = 1/16 + 5/8                          \\
   & = 11/16                               \\
\end{align*}
\begin{align*}
  \P(T = 0)
   & = \P(T = 0, M = 0) + \P(T = 0, M = 1) \\
   & = 1/8 + 1/16                          \\
   & = 3/16                                \\
\end{align*}
\begin{align*}
  \P(T = 1)
   & = \P(T = 1, M = 0) + \P(T = 1, M = 1) \\
   & = 3/16 + 5/8                          \\
   & = 13/16                               \\
\end{align*}

\subsubsection*{2.}
$$
  \P(M = 0, T = 1) + \P(M = 1, T = 0) = 3/16 + 1/16 = 4/16 = 1/4
$$

\subsubsection*{3.}
$$
  1 - \P(T = 1) = 1 - 13/16 = 3/16 < 1/4
$$
Indeed.

\subsubsection*{4.}
\begin{align*}
  I(E, T)
   & = \sum_{i=0, 1}\sum_{j=0,1} \P(E = i, T = j) \log \frac{\P(E = i, T = j)}{\P(E = i) \P(T = j)}    \\
   & = \sum_{j=0,1} \P(E = 1, T = j) \log \frac{\P(E = 1, T = j)}{\P(E = 1) \P(T = j)}                 \\
   & = \P(E = 1, T = 0) \log \frac{\P(E = 1, T = 0)}{\P(E = 1) \P(T = 0)} +                            \\
   & \P(E = 1, T = 1) \log \frac{\P(E = 1, T = 1)}{\P(E = 1) \P(T = 1)}                                \\
   & = \P(T = 0) \log \frac{\P(T = 0)}{1 * \P(T = 0)} + \P(T = 1) \log \frac{\P(T = 1)}{1 * \P(T = 1)} \\
   & = 0                                                                                               \\
\end{align*}

\subsubsection*{5.}
\begin{align*}
  I(M, T)
   & = \sum_{i=0, 1}\sum_{j=0,1} \P(M = i, T = j) \log \frac{\P(M = i, T = j)}{\P(M = i) \P(T = j)} \\
   & =
  \frac{1}{8} \log \frac{\frac{1}{8}}{\frac{5}{16}\frac{3}{16}} +
  \frac{3}{16} \log \frac{\frac{3}{16}}{\frac{5}{16}\frac{13}{16}} +
  \frac{1}{16} \log \frac{\frac{1}{16}}{\frac{11}{16}\frac{3}{16}} +
  \frac{1}{16} \log \frac{\frac{5}{8}}{\frac{11}{16}\frac{13}{16}}
  \\
   & =
  \frac{1}{16} \left(
  2 \log \frac{2}{\frac{5}{16} * 3} +
  3 \log \frac{3}{\frac{5}{16} * 13} +
  1 \log \frac{1}{\frac{11}{16} * 3} +
  1 \log \frac{10}{\frac{11}{16} * 13}
  \right)
  \\
   & =
  \frac{1}{16} \left(
  2 \log \frac{16*2}{5 * 3} +
  3 \log \frac{16*3}{5 * 13} +
  1 \log \frac{16*1}{11 * 3} +
  1 \log \frac{16*10}{11 * 13}
  \right)
  \\
\end{align*}


\subsection{Problem 2}
Consider a twin-pan balance and $c = 9$ coins. We know that one of these coins is fake. The problem is to find the fake coin given that it only differs from the other 8 coins by its weight.

\paragraph{1. Number of states and entropy}
The number of states is 18. Each coin may be lighter or heavier than the other one it is checked against. \\
The entropy is:
$$
  H(S) = \log_2 18 \approx 4.17 \text{ sh }
$$

\paragraph{2.}
Each weighting operation may give one of the following results: left is heavier, right is heavier or equal weight. \\
The maximum entropy that can be achieved is:
$$
  H_{max}(S) = \log_2 3 \approx 1.58 \text{ sh }
$$
so the average number of weighting operations is equal to:
\begin{align*}
  \bar{n}_{min}
   & = \frac{\log_2(18)}{\log_2(3)} \\
   & \approx 2.63                   \\
\end{align*}

\paragraph{3.}
\begin{align*}
  \P_e
   & = \frac{C^{2n}_9}{C^{2n}_8}                               \\
   & = \frac{\frac{8!}{2n!(8 - 2n)!}}{\frac{9!}{2n!(9 - 2n)!}} \\
   & = 1 - \frac{2}{9}n                                        \\
\end{align*}
\begin{align*}
  \P_l = \P_r
   & = \frac{1}{2} (1 - \P_e) \\
   & = \frac{1}{9}n           \\
\end{align*}
We want $\P_l = \P_r = \P_e$, to get maximum information. This is achieved for $n = 3$, that is 3 coins on each side.

\section{Discrete source coding}
\subsection{Exercise 4}
\begin{itemize}
  \item We encore the following commands:
  \item Raise the stylus (RS)
  \item Press the stylus (PS)
  \item move the stylus left (–X)
  \item move the stylus right (+X)
  \item move the stylus up (+Y)
  \item move the stylus down (–Y)
\end{itemize}
We have:
$$
  \P_{RS} = \P_{PS} = \P_{-X} = 0.1, \quad \P_{+X} = 0.3, \quad \P_{+Y} = \P_{-Y} = 0.2
$$

\section{In-class exercises 2023-01-23}
Consider the following matrix:
$$
  \Pi =
  \begin{bmatrix}
    0   & 0.7 & 0.3 \\
    0.5 & 0   & 0.5 \\
    0   & 0.8 & 0.2
  \end{bmatrix}
$$
and:
$$
  p_\infty =
  \begin{bmatrix}
    x & y & z
  \end{bmatrix}
$$
Therefore:
\begin{align*}
           & p_\infty \Pi = p_\infty       \\
  \implies &
  \det(p_\infty (\Pi - Id)) = 0            \\
  \implies &
  \det\left[p_\infty (\Pi - Id)\right] = 0 \\
  \implies &
  \det p_\infty
  \begin{bmatrix}
    -1  & 0.7 & 0.3  \\
    0.5 & -1  & 0.5  \\
    0   & 0.8 & -0.8
  \end{bmatrix}
  = 0                                      \\
\end{align*}
\end{document}