\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue, 
}

\newcommand{\1}{\mathbf{1}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Rcal}{\mathcal{R}}
\renewcommand{\P}{\mathbb{P}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\thetahat}{\hat\theta}
\newcommand{\ie}{\textit{i.e. }}
\newcommand{\var}{\operatorname{Var}}


\title{Introduction to Information Theory}
\author{Joris LIMONIER}
\begin{document}
\maketitle

\tableofcontents

\section{Exercise sheet}
\subsection{Exercise 1}
Given a game of 52 cards, we draws cards with replacement.

\paragraph{Probability to get a queen}
There are 4 queens in the deck, so the probability to get a queen is:
$$\P(queen) = 4/52.$$

\paragraph{Probability to get a heart}
There are 13 hearts in the deck, so the probability to get a heart is:
$$\P(heart) = 13/52.$$

\paragraph{Probability to get the queen of hearts or the ace of spades}
There is one queen of heart and one ace of spades, which are disjoint events, so the probability to get one of them is:
\begin{align*}
  \P(\text{QH or AS}) & = \P(QH) + \P(AS) \\
                      & = 1/52 + 1/52     \\
                      & = 2/52
\end{align*}

\paragraph{Probability to get a queen or a spade}
There are 4 queens and 13 spades, which are not disjoint events, so the probability to get one of them is:
\begin{align*}
  \P(\text{Q or S}) & = \P(Q) + \P(S) - \P(Q \cap S) \\
                    & = 4/52 + 13/52 - 1/52          \\
                    & = 16/52
\end{align*}

\paragraph{Probability to get neither a queen, nor a spade}
This is the complement of the previous event, so the probability to get neither a queen, nor a spade is:
\begin{align*}
  \P(\text{not Q and not S}) & = 1 - \P(\text{Q or S}) \\
                             & = 1 - 16/52             \\
                             & = 36/52
\end{align*}


\subsection{Exercise 2}
We draw one ball from an urn with 5 white balls, 4 red balls and 2 black balls.

\paragraph{Probability to draw white}
There are 11 balls in total and 5 white balls, so the probability to draw a white ball is:
$$\P(W) = 5/11$$

\paragraph{Probability to draw not white}
This is the complement of the previous event, so the probability to draw not white is:
\begin{align*}
  \P(\neg W)
   & = 1 - \P(W) \\
   & = 6/11
\end{align*}

\paragraph{Probability to draw white or red}
These events are disoint, so the probability to draw a white or a red ball is:
\begin{align*}
  \P(W \cup R)
   & = \P(W) + \P(R) \\
   & = 5/11 + 4/11   \\
   & = 9/11
\end{align*}

\subsection{Exercise 3}
\subsection{Exercise 4}
\subsection{Exercise 5}
\subsection{Exercise 6}
\subsection{Exercise 7}


\section{Exercise sheet Quantitative Measure of Information (part 1)}
\subsection{Exercise 6}
Given
\begin{align*}
  \P(X = 0) & = \frac{1}{4} \\
  \P(X = 1) & = \frac{3}{4} \\
  p_0       & = 10^{-1}
\end{align*}
where $p_0$ is the probability of incorrect transmission of a bit.


\paragraph{Compute $H(X)$}
\begin{align*}
  H(X) & = - \sum_{i=1}^{m} \P(X = x_i) \log_2 \P(X = x_i)                   \\
       & = - \frac{1}{4} \log_2 \frac{1}{4} - \frac{3}{4} \log_2 \frac{3}{4} \\
       & \approx 0.811 \text{ sh / state of X}
\end{align*}


\paragraph{Compute $H(Y)$}
We first compute the probability distribution of $Y$:
\begin{align*}
  \P(Y = 1)
   & = \P(Y = 1, X = 0) + \P(Y = 1, X = 1)                             \\
   & = \P(Y = 1 \mid X = 0) \P(X = 0) + \P(Y = 1 \mid X = 1) \P(X = 1) \\
   & = p_0 \frac{1}{4} + (1 - p_0) \frac{3}{4}                         \\
   & = 10^{-1} \frac{1}{4} + (1 - 10^{-1}) \frac{3}{4}                 \\
   & = \frac{1}{10} \frac{1}{4} + \frac{9}{10} \frac{3}{4}             \\
   & = \frac{1}{40} + \frac{27}{40}                                    \\
   & = \frac{28}{40}                                                   \\
\end{align*}
and on the other hand:
\begin{align*}
  \P(Y = 0)
   & = \P(Y = 0, X = 0) + \P(Y = 0, X = 1)                             \\
   & = \P(Y = 0 \mid X = 0) \P(X = 0) + \P(Y = 0 \mid X = 1) \P(X = 1) \\
   & = (1 - p_0) \frac{1}{4} + p_0 \frac{3}{4}                         \\
   & = \frac{9}{10} \frac{1}{4} + \frac{1}{10} \frac{3}{4}             \\
   & = \frac{9}{40} + \frac{3}{40}                                     \\
   & = \frac{12}{40}                                                   \\
\end{align*}
\begin{align*}
  H(Y) & = - \sum_{i=1}^{m} \P(Y = y_i) \log_2 \P(Y = y_i)                           \\
       & = - \frac{28}{40} \log_2 \frac{28}{40} - \frac{12}{40} \log_2 \frac{12}{40} \\
       & = - \frac{28}{40} \log_2 \frac{28}{40} - \frac{12}{40} \log_2 \frac{12}{40} \\
       & \approx 0.881 \text{ sh / state of Y}
\end{align*}
So we have:
$$
  \begin{cases}
    \P(X = 0, Y = 0) = \frac{9}{40} \\
    \P(X = 0, Y = 1) = \frac{1}{40} \\
    \P(X = 1, Y = 0) = \frac{3}{40} \\
    \P(X = 1, Y = 1) = \frac{27}{40}
  \end{cases}
$$

\paragraph{Compute $H(X, Y)$}
\begin{align*}
  H(X, Y)
   & = - \sum_{i=1}^n \sum_{j=1}^m \P(X = x_i, Y = y_j) \log \P(X = x_i, Y = y_j)                                                            \\
   & = - \P(X = 0, Y = 0) \log \P(X = 0, Y = 0)                                                                                              \\
   & - \P(X = 0, Y = 1) \log \P(X = 0, Y = 1)                                                                                                \\
   & - \P(X = 1, Y = 0) \log \P(X = 1, Y = 0)                                                                                                \\
   & - \P(X = 1, Y = 1) \log \P(X = 1, Y = 1)                                                                                                \\
   & = - \frac{9}{40} \log \frac{9}{40} - \frac{1}{40} \log \frac{1}{40} - \frac{3}{40} \log \frac{3}{40} - \frac{27}{40} \log \frac{27}{40} \\
   & \approx 1.28                                                                                                                            \\
\end{align*}

\paragraph{Compute $H(Y \mid X)$}
\begin{align*}
  H(Y \mid X)
   & = H(X, Y) - H(Y)              \\
   & = 1.28 - 0.88                 \\
   & = 0.4 \text{ sh / state of X}
\end{align*}

\paragraph{Compute $H(X \mid Y)$}
\begin{align*}
  H(X \mid Y)
   & = H(X, Y) - H(X)               \\
   & = 1.28 - 0.81                  \\
   & = 0.47 \text{ sh / state of Y}
\end{align*}


\paragraph{Compute $I(X, Y)$}
\begin{align*}
  I(X, Y)
   & = H(X) - H(X \mid Y)                \\
   & = 0.81 - 0.40                       \\
   & = 0.41 \text{ sh / state of (X, Y)}
\end{align*}

\section{Exercise sheet Quantitative Measure of Information (part 2)}
\subsection{Exercise}
\paragraph{$Y$ is uniformly distributed}
\begin{align*}
  \P(Y = y_1)
   & = \frac{1}{24} + \frac{1}{6} + \frac{1}{24} \\
   & = \frac{6}{24}                              \\
\end{align*}
\begin{align*}
  \P(Y = y_2)
   & = \frac{1}{12} + \frac{1}{8} + \frac{1}{24} \\
   & = \frac{6}{24}                              \\
\end{align*}
\begin{align*}
  \P(Y = y_3)
   & = \frac{1}{6} + \frac{1}{24} + \frac{1}{24} \\
   & = \frac{6}{24}                              \\
\end{align*}
\begin{align*}
  \P(Y = y_4)
   & = \frac{1}{6} + \frac{1}{6} + \frac{1}{24} \\
   & = \frac{6}{24}                             \\
\end{align*}
$Y$ is indeed uniformly distributed.

\paragraph{Compute $I(X, Y)$}
\begin{align*}
  I(X, Y)
   & = H(Y) - H(Y \mid X)     \\
   & = \log_2 4 - H(Y \mid X) \\
\end{align*}
The distribution of $X$ is given by:
$$
  \begin{cases}
    \P(X = x_1) = \frac{1}{3} \\
    \P(X = x_2) = \frac{1}{2} \\
    \P(X = x_3) = \frac{1}{6} \\
  \end{cases}
$$

\begin{align*}
  H(Y \mid X)
   & = \sum_{i=1}^3 H(Y \mid X = x_i) \log \P(X = x_i) \\
\end{align*}

\subsection{Problem 2}
Consider a twin-pan balance and $c = 9$ coins. We know that one of these coins is fake. The problem is to find the fake coin given that it only differs from the other 8 coins by its weight.

\paragraph{1. Number of states and entropy}
The number of states is 18. Each coin may be lighter or heavier than the other one it is checked against. \\
The entropy is:
$$
  H(S) = \log_2 18 \approx 4.17 \text{ sh }
$$

\paragraph{2.}
Each weighting operation may give one of the following results: left is heavier, right is heavier or equal weight. \\
The maximum entropy that can be achieved is:
$$
  H_{max}(S) = \log_2 3 \approx 1.58 \text{ sh }
$$
so the average number of weighting operations is equal to:
\begin{align*}
  \bar{n}_{min}
   & = \frac{\log_2(18)}{\log_2(3)} \\
   & \approx 2.63                   \\
\end{align*}



\end{document}