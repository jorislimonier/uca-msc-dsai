{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a5cc77",
   "metadata": {},
   "source": [
    "# Work with Missing value, Outlier, Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d1fe3",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-Dataset\" data-toc-modified-id=\"Imports-and-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and Dataset</a></span></li><li><span><a href=\"#Sampler,--transformer-and-estimator\" data-toc-modified-id=\"Sampler,--transformer-and-estimator-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sampler,  transformer and estimator</a></span></li><li><span><a href=\"#Lab-1:-Missing-value\" data-toc-modified-id=\"Lab-1:-Missing-value-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Lab 1: Missing value</a></span></li><li><span><a href=\"#Outlier-removal\" data-toc-modified-id=\"Outlier-removal-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Outlier removal</a></span></li><li><span><a href=\"#Unbalance-dataset\" data-toc-modified-id=\"Unbalance-dataset-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Unbalance dataset</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526203a3",
   "metadata": {},
   "source": [
    "## Imports and Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607a3ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:00:40.038388Z",
     "start_time": "2022-01-06T08:00:40.035775Z"
    }
   },
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8affe0c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:00:41.037188Z",
     "start_time": "2022-01-06T08:00:40.442310Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import seaborn as sns                                     # For plotting data\n",
    "import pandas as pd                                       # For dataframes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                           # For plotting data\n",
    "%matplotlib inline\n",
    "\n",
    "# For splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For setting up pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn import FunctionSampler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# For Missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# For Outlier detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# For Unbalanced dataset\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# For classification\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "# For optimization\n",
    "from sklearn.model_selection import GridSearchCV      \n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a39162d",
   "metadata": {},
   "source": [
    "The **original ForestCover/Covertype dataset** from UCI machine learning repository is a multiclass classification dataset. This dataset contains tree observations from four areas of the Roosevelt National Forest in Colorado. This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices. \n",
    "\n",
    "In this notebook you are asked to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data). The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is in raw form (not scaled) and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type.\n",
    "\n",
    "This dataset has 54 attributes :\n",
    "* 10 quantitative variables,\n",
    "* 4 binary wilderness areas\n",
    "* and 40 binary soil type variables).\n",
    "Here, outlier detection dataset is created using only 10 quantitative attributes. Instances from class 2 are considered as normal points and instances from class 4 are anomalies. The anomalies ratio is 0.9%. Instances from the other classes are omitted.\n",
    "\n",
    "Dataset description available on [Kaggle](https://www.kaggle.com/uciml/forest-cover-type-dataset).\n",
    "* Elevation: Elevation in meters.\n",
    "* Aspect: Aspect in degrees azimuth.\n",
    "* Slope: Slope in degrees.\n",
    "* Horizontal_Distance_To_Hydrology: Horizontal distance in meters to nearest surface water features.\n",
    "* Vertical_Distance_To_Hydrology: Vertical distance in meters to nearest surface water features.\n",
    "* Horizontal_Distance_To_Roadways: Horizontal distance in meters to the nearest roadway.\n",
    "* Hillshade_9am: hillshade index at 9am, summer solstice. Value out of 255.\n",
    "* Hillshade_Noon: hillshade index at noon, summer solstice. Value out of 255.\n",
    "* Hillshade_3pm: shade index at 3pm, summer solstice. Value out of 255.\n",
    "* Horizontal_Distance_To_Fire_Point*: horizontal distance in meters to nearest wildfire ignition points.\n",
    "* Wilderness_Area#: wilderness area designation.\n",
    "* Soil_Type#: soil type designation.\n",
    "\n",
    "Wilderness_Area feature is one-hot encoded to 4 binary columns (0 = absence or 1 = presence), each of these corresponds to a wilderness area designation. Areas are mapped to value in the following way:\n",
    "1. Rawah Wilderness Area\n",
    "1. Neota Wilderness Area\n",
    "1. Comanche Peak Wilderness Area\n",
    "1. Cache la Poudre Wilderness Area\n",
    "\n",
    "The same goes for Soil_Type feature which is encoded as 40 one-hot encoded binary columns (0 = absence or 1 = presence) and each of these represents soil type designation. All the possible options are:\n",
    "1. Cathedral family - Rock outcrop complex, extremely stony\n",
    "1. Vanet - Ratake families complex, very stony\n",
    "1. Haploborolis - Rock outcrop complex, rubbly\n",
    "1. Ratake family - Rock outcrop complex, rubbly\n",
    "1. Vanet family - Rock outcrop complex complex, rubbly\n",
    "1. Vanet - Wetmore families - Rock outcrop complex, stony\n",
    "1. Gothic family\n",
    "1. Supervisor - Limber families complex\n",
    "1. Troutville family, very stony\n",
    "1. Bullwark - Catamount families - Rock outcrop complex, rubbly\n",
    "1. Bullwark - Catamount families - Rock land complex, rubbly.\n",
    "1. Legault family - Rock land complex, stony\n",
    "1. Catamount family - Rock land - Bullwark family complex, rubbly\n",
    "1. Pachic Argiborolis - Aquolis complex\n",
    "1. Â¨unspecified in the USFS Soil and ELU Survey\n",
    "1. Cryaquolis - Cryoborolis complex\n",
    "1. Gateview family - Cryaquolis complex\n",
    "1. Rogert family, very stony\n",
    "1. Typic Cryaquolis - Borohemists complex\n",
    "1. Typic Cryaquepts - Typic Cryaquolls complex\n",
    "1. Typic Cryaquolls - Leighcan family, till substratum complex\n",
    "1. Leighcan family, till substratum, extremely bouldery\n",
    "1. Leighcan family, till substratum - Typic Cryaquolls complex\n",
    "1. Leighcan family, extremely stony\n",
    "1. Leighcan family, warm, extremely stony\n",
    "1. Granile - Catamount families complex, very stony\n",
    "1. Leighcan family, warm - Rock outcrop complex, extremely stony\n",
    "1. Leighcan family - Rock outcrop complex, extremely stony\n",
    "1. Como - Legault families complex, extremely stony\n",
    "1. Como family - Rock land - Legault family complex, extremely stony\n",
    "1. Leighcan - Catamount families complex, extremely stony\n",
    "1. Catamount family - Rock outcrop - Leighcan family complex, extremely stony\n",
    "1. Leighcan - Catamount families - Rock outcrop complex, extremely stony\n",
    "1. Cryorthents - Rock land complex, extremely stony\n",
    "1. Cryumbrepts - Rock outcrop - Cryaquepts complex\n",
    "1. Bross family - Rock land - Cryumbrepts complex, extremely stony\n",
    "1. Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony\n",
    "1. Leighcan - Moran families - Cryaquolls complex, extremely stony\n",
    "1. Moran family - Cryorthents - Leighcan family complex, extremely stony\n",
    "1. Moran family - Cryorthents - Rock land complex, extremely stony\n",
    "\n",
    "Cover_Type: forest cover type designation, its possible values are between 1 and 7, mapped in the following way:\n",
    "1. Spruce/Fir\n",
    "1. Lodgepole Pine\n",
    "1. Ponderosa Pine\n",
    "1. Cottonwood/Willow\n",
    "1. Aspen\n",
    "1. Douglas-fir\n",
    "1. Krummholz\n",
    "\n",
    "<font color=blue>\n",
    "We will use a very small part of this dataset with only classes 1 and 7.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acbedb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:00:58.376165Z",
     "start_time": "2022-01-06T08:00:58.373811Z"
    }
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "url = \"https://www.i3s.unice.fr/~riveill/dataset/covtype/\"\n",
    "filename = \"covtype.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1c4f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:14.251808Z",
     "start_time": "2022-01-06T08:01:13.894125Z"
    }
   },
   "outputs": [],
   "source": [
    "# load train and test\n",
    "train = pd.read_csv(url+\"train.csv\", delimiter=',')\n",
    "test = pd.read_csv(url+\"test.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1268a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:14.858602Z",
     "start_time": "2022-01-06T08:01:14.855174Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = list(train.columns)\n",
    "target = 'Cover_Type'\n",
    "columns.remove(target)\n",
    "cat_columns=[c for c in columns if 'Soil_Type' in c or 'Wilderness_Area' in c] # already one hot encode\n",
    "num_columns=[c for c in columns if c not in cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1692f225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:15.395465Z",
     "start_time": "2022-01-06T08:01:15.381422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 54), (10000, 54))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(train[target]).reshape(-1,1)\n",
    "X_train = train[columns]\n",
    "\n",
    "y_test = np.array(test[target]).reshape(-1,1)\n",
    "X_test = test[columns]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b086546b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:15.793149Z",
     "start_time": "2022-01-06T08:01:15.788504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 9083, 7: 917}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution\n",
    "distribution = pd.Series(y_train.flatten()).value_counts().to_dict()\n",
    "distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa9b17",
   "metadata": {},
   "source": [
    "## Sampler,  transformer and estimator\n",
    "\n",
    "There are three types of objects in imblearn/scikit-learn design:\n",
    "\n",
    "**Transformer** transform observation (modify only X_train) and implements:\n",
    "* fit: used for calculating the initial parameters on the training data and later saves them as internal objects state.\n",
    "* transform: Use the initial above calculated values and return modified training data as output. Do not modify the length of the dataset.\n",
    "\n",
    "**Predictor** is a \"model\" and implements:\n",
    "* fit: calculates the parameters or weights on the training data and saves them as an internal object state.\n",
    "* predict: Use the above-calculated weights on the test data to make the predictions.\n",
    "\n",
    "**Sampler** is a new element, from imblearn library. A sampler modifies the number of observations in the train set (modify X_train and y_train) and implements:\n",
    "* fit_resample\n",
    "\n",
    "The following cells build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a1bcb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:16.440347Z",
     "start_time": "2022-01-06T08:01:16.437511Z"
    }
   },
   "outputs": [],
   "source": [
    "# A sampler\n",
    "class mySampler(BaseEstimator):\n",
    "    def fit_resample(self, X, y):\n",
    "        data = np.concatenate((X, y), axis=1)\n",
    "        # remove rows with NaN\n",
    "        data = data[~np.isnan(data).any(axis=1), :]\n",
    "        return data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c709f",
   "metadata": {},
   "source": [
    "It's also possible to build sampler from a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc15f50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:16.900610Z",
     "start_time": "2022-01-06T08:01:16.897194Z"
    }
   },
   "outputs": [],
   "source": [
    "def mySamplerFunction(X, y, conta=0.1):\n",
    "    iforest = IsolationForest(n_estimators=300, max_samples='auto', contamination=conta)\n",
    "    outliers = iforest.fit_predict(X, y)\n",
    "\n",
    "    X_filtered = X[outliers == 1]\n",
    "    y_filtered = y[outliers == 1]\n",
    "\n",
    "    return X_filtered, y_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a8c5ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:17.384561Z",
     "start_time": "2022-01-06T08:01:17.381000Z"
    }
   },
   "outputs": [],
   "source": [
    "# A transformer\n",
    "class myTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy=\"most_frequent\"):\n",
    "        self.strategy = strategy\n",
    "        self.sample = SimpleImputer(strategy=self.strategy)\n",
    "    def fit(self, X, y=None):\n",
    "        return self.sample.fit(X, y)\n",
    "    def transform(self, X):\n",
    "        return self.sample.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c3034",
   "metadata": {},
   "source": [
    "Like sampler, it's also possible to build transformer from a function see `sklearn.preprocessing.FunctionTransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2615cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:17.944197Z",
     "start_time": "2022-01-06T08:01:17.941082Z"
    }
   },
   "outputs": [],
   "source": [
    "# A predictor\n",
    "class myPredictor(BaseEstimator):\n",
    "    def __init__(self, penalty=\"l2\"):\n",
    "        self.penalty = penalty\n",
    "        self.sample = LogisticRegression(solver=\"lbfgs\", penalty=self.penalty, max_iter=10000)\n",
    "    def fit(self, X, y):\n",
    "        return self.sample.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.sample.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe5f34a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:18.188956Z",
     "start_time": "2022-01-06T08:01:18.180933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing_data', None),\n",
       "                ('outlier',\n",
       "                 FunctionSampler(func=<function mySamplerFunction at 0x7fbb13f97280>)),\n",
       "                ('clf', None)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different version of the 2 steps pipeline\n",
    "# step 1 : remove or imput missing data\n",
    "# step 2 : remove outlier\n",
    "# step 3 : predictor\n",
    "pipeline = Pipeline([('missing_data', None),\n",
    "                     ('outlier', FunctionSampler(func=mySamplerFunction)),\n",
    "                     ('clf', None)])\n",
    "\n",
    "parameters = [{'missing_data': [mySampler()],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              {'missing_data': [myTransformer()],\n",
    "               'missing_data__strategy': ['most_frequent'],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              ]\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96540aeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:18.425350Z",
     "start_time": "2022-01-06T08:01:18.415090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x7fbb13f97280>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch with pipeline\n",
    "grid = GridSearchCV(pipeline, parameters, cv=2,\n",
    "                    scoring=\"f1_micro\", refit=True,\n",
    "                    verbose=2)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e595f9",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "Remember: samplers are only called to perform the \"fit\" and not to perform the predict. If the data set contains missing values (NaN) in the validation part, a warning may be raised.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "798afeb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:21.375699Z",
     "start_time": "2022-01-06T08:01:18.872513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 236, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 53, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\", line 120, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 419, in predict\n",
      "    return self.steps[-1][-1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-12-2937ca012408>\", line 9, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\", line 309, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\", line 284, in decision_function\n",
      "    X = check_array(X, accept_sparse='csr')\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 236, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 53, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\", line 120, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 419, in predict\n",
      "    return self.steps[-1][-1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-12-2937ca012408>\", line 9, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\", line 309, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\", line 284, in decision_function\n",
      "    X = check_array(X, accept_sparse='csr')\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   0.5s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riveill/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [ nan 0.66]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x7fbb13f97280>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor(penalty='none')],\n",
       "                          'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to find the best model\n",
    "grid.fit(X_train[:50], y_train[:50]) # Some data for testing the process... but use all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee7d400a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:21.389682Z",
     "start_time": "2022-01-06T08:01:21.377854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.66 using {'clf': myPredictor(penalty='none'), 'clf__penalty': 'none', 'missing_data': myTransformer(), 'missing_data__strategy': 'most_frequent'}\n",
      "Test set score: 0.868\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the whole dataset\n",
    "y_pred = grid.predict(X_train[:500])\n",
    "print(\"Best: {:.2f} using {}\".format(\n",
    "    grid.best_score_, \n",
    "    grid.best_params_\n",
    "))\n",
    "print('Test set score: ' + str(grid.score(X_train[:500], y_train[:500])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c419de84",
   "metadata": {},
   "source": [
    "## Lab 1: Missing value\n",
    "\n",
    "$$[TO DO - Students]$$\n",
    "\n",
    "Test some algorithms to handle missing data.\n",
    "* Choose the classifier that you think is preferable for this job.\n",
    "\n",
    "1. with removal of missing data\n",
    "1. with of the following imputation methods\n",
    "    * With SimpleImputer\n",
    "    * With IterativeImputer\n",
    "    * With KNNimputer\n",
    "\n",
    "Build a 2 step pipeline and use a gridsearch to find the right hyperpameters.\n",
    "\n",
    "Submit your work in the form of an executable and commented notebook at lms.univ-cotedazur.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6d06e",
   "metadata": {},
   "source": [
    "## Outlier removal\n",
    "\n",
    "Removing the outliers modifies the data set, so it is a sampler.\n",
    "\n",
    "<font color='blue'> \n",
    "IsolationForest or other sklearn detector are not a sampler. You have to read the </font>[imblearn documentation](https://imbalanced-learn.org/dev/references/generated/imblearn.FunctionSampler.html)\n",
    "    \n",
    "A small example with parameters:\n",
    "<pre>\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def func(X, y, sampling_strategy, random_state):\n",
    "  return RandomUnderSampler(\n",
    "      sampling_strategy=sampling_strategy,\n",
    "      random_state=random_state).fit_resample(X, y)\n",
    "      \n",
    "sampler = FunctionSampler(func=func,\n",
    "                          kw_args={'sampling_strategy': 'auto',\n",
    "                                   'random_state': 0})\n",
    "X_res, y_res = sampler.fit_resample(X, y)\n",
    "print(f'Resampled dataset shape {sorted(Counter(y_res).items())}')\n",
    "</pre>\n",
    "\n",
    "$$[TO DO - Students]$$\n",
    "\n",
    "Test some algorithms to handle outliers.\n",
    "* Choose the classifier that you think is preferable for this job.\n",
    "\n",
    "1. Without taking any precautions\n",
    "1. By eliminating outliers with one of the following approaches:\n",
    "    * With Isolation Forest (IF)\n",
    "    * With Local Outlier Factor (LOF)\n",
    "    * With Minimum Covariance Determinant (MCD)\n",
    "\n",
    "Build a 3 step pipeline and use a gridsearch to find the right hyperpameters.\n",
    "The first step, is your best previous \"missing data method\".\n",
    "\n",
    "Submit your work in the form of an executable and commented notebook at lms.univ-cotedazur.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aba889",
   "metadata": {},
   "source": [
    "## Unbalance dataset\n",
    "\n",
    "$$[TO DO - Students]$$\n",
    "\n",
    "Test some algorithms to work with unbalanced dataset.\n",
    "Choose the classifier that you think is preferable for this job.\n",
    "\n",
    "1. Without taking any precautions\n",
    "1. With modification of the dataset by Over sampling or Under sampling or SMOTE\n",
    "1. Without modification of the dataset by weight\n",
    "\n",
    "Build a 4 step pipeline and use a gridsearch to find the right hyperpameters and use a gridsearch to find the right hyperpameters. The first and second step, is your best previous methods.\n",
    "\n",
    "Submit your work in the form of an executable and commented notebook at lms.univ-cotedazur.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad6770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
