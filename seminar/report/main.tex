\documentclass[oneside, 10pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue, 
}
\usepackage[a4paper]{geometry}


\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\thetahat}{\hat\theta}
\newcommand{\ie}{\textit{i.e. }}
\newcommand{\eg}{\textit{e.g. }}
\newcommand{\so}{\ensuremath{\mathcal{S}_1} }
\newcommand{\st}{\ensuremath{\mathcal{S}_2} }
\newcommand{\mco}{\ensuremath{\mathcal{MC}_1} }
\newcommand{\mct}{\ensuremath{\mathcal{MC}_2} }
\newcommand{\mdft}{\ensuremath{\mathcal{MDFT}} }
\newcommand{\das}{\ensuremath{\mathcal{DAS}} }
\newcommand{\dae}{\ensuremath{\mathcal{DAE}} }

\title{Seminar: Report of two speeches}
\author{Joris LIMONIER}
\date{Submission: December 5, 2021}

\begin{document}

\pagenumbering{gobble}
\maketitle

\vspace{2cm}
\section*{Introduction}
This article contains a report for each of the two following talks:
\begin{itemize}
  \item \textit{Think Fast and Slow in AI}, by Francesca ROSSI
  \item \textit{Self-supervised detection and analysis of cars in roadside Distributed Acoustic Sensing data}, by Martijn VAN DEN ENDE
\end{itemize}
Each of the reports is one page long, as required by the examiner.

\newpage
\pagenumbering{arabic}

\newgeometry{hmargin=3cm, vmargin=3cm}

\section{Think Fast and Slow in AI.}
Francesca ROSSI is an Italian IBM researcher focusing on ethics in Artificial Intelligence (AI). Her talk ``Think Fast and Slow in AI" is named after the book \textit{Thinking, Fast and Slow}, by Daniel KAHNEMAN. This book, as well as \textit{Sapiens} (HARARI), \textit{Society of Mind} (MINSKY) and \textit{Rethinking Consciousness} (GRAZIANO) are four pillars of the theory about Human minds. The framework used in this field dates back to Descartes who separated, in the 17th century, intuitive and conscious reasoning. However, it was brought back to life by Posner and Synder in 1975 and was reformulated to a more recent description by Kahneman, who introduced the so-called System 1 (\so)and System 2 (\st).

\so is fast, unconscious, automatic, error prone and is responsible for everyday decisions. \st on the other hand is slow, conscious, effortful, reliable and responsible for complex decisions. It may appear that these systems work in opposite manners, but they are actually complementary, as we shall show below. \so quickly reacts in a local and parrallel fashion, almost like a reflex, whereas \st takes time to analyze and consider its environment before performing a more accurate response. It is important to understand that the border between the two systems is blurred. Some actions may initially be managed by \so, before moving onto \st once they become more natural, more intuitive. Complex arithmetic operations for example require a lot of cognitive intensity at first, but may become routine given enough practice.

The link with AI is now straightforward, one may easily imagine a multitude of problems where a quick decision is needed, even suboptimal, before performing a more accurate decision. This however leads to several questions: Do we always need a more accurate decision from \st? Who should decide whether such a decision is required? Is the use of \st worth it given the associated costs? The key to those questions lays in meta-cognitive agents. They take as input the world (problems, actions, environment), the two systems (past decisions, rewards, cost) and other considerations such as knowledge and beliefs about other agents. Then they should assess available resources, the expected cost of using \st and the expected reward associated with getting a correct solution. Their (broad) role is to determine how to best use \so and \st. To perform this task, meta-cognitive agents take a two-phase approach. In phase one, the meta-cognitive agent (\mco) asserts whether there are enough resources to perform both \so and \st. If not, \so is chosen. Then \mco determines the confidence of \so. If it is higher than the expected reward, then \so is chosen. The second meta-cognitive agent (\mct) then comes into play. It computes the gain of using \st (reward minus cost) and compares it to the expected reward of \so. If the former is greater than the latter, \st should be used, otherwise \so suffices.

Meta-cognitive agents are also responsible for a major topic in AI: trustworthiness. They can take into consideration fairness, robustness, explainability before choosing whether to apply \st. In summary, they must be logic-based so that a reasoning can be extracted from them. The clearer this reasoning, the better.

What we presented is actually a simplified model and more sophisticated ones exist, \textit{e.g.} where there are multiple \so's and \st's. Some more sophisticated models are part of Multi-alternative Decision Field Theory (\mdft). As the name hints, \mdft considers multiple options as an input and outputs one of these options, ideally the best one. This model is weighted over attributes, where the weights are updated according to the similarity between multiple options. Eventually, either when the maximum number of iterations is reached, or when a given value of a quality metric is obtained, the algorithm should stop.

The \so- \st framework is an interesting framework, not only because it works in practice, but also because it models the way of thinking of the human mind. Both this framework and its more sophisticated counterpart, the \mdft, arise from natural concepts in cognitive theory. Another field inspired by cognitive and neural theory is deep learning. Merging the \so- \st framework with deep learning seems to be an interesting idea. Maybe it could lead to more explainability in the deep learning so-called ``black-box'', and therefore to improvements with respect to fairness in AI?

\newpage

\section{Self-supervised detection and analysis of cars in roadside Distributed Acoustic Sensing data.} Martijn VAN DEN ENDE is a Dutch researcher at Université Côte d'Azur, with interests in Physics-Based Machine Learning.

In  his talk, the speaker introduces Distributed Acoustic Sensing ( \das), which is a novel sensing technology that can he uses for road traffic analysis, using existing telecommunication cables. \das relies on vibration analysis to detect cars and measure their speed. As a result and on a more global scale, it is possible to determine the number of cars passing through a road segment at a given time, whether there an accident occured, or even enforce speed limits in a continuous manner (rather than with fixed-location radars or section radars, which disregard speeds within the section).

The signal received is of the form of so-called \das channels, which can be stacked in order to get an idea of what happens as time passes. Philosophically, this approach is similar to showing several images successively in order to produce a video. Each channel shows inpulses that shift as you move through the channels. These inpulses denote the vibrations emitted by cars and therefore give a way to track them.

However, the speaker details some challenges faced when working with \das signal. Although it is fairly easy for a human to ``see" the inpulse in a \das signal, computers have a harder time doing so. There are existing techniques that work well when cars are well-isolated, but they generally fail to generalize to crowded environments, such as urban landscapes or high-intensity commute times. The speaker proposes a self-supervised Deep Learning method ``Deconvolution Auto-Encoder" (\dae) that takes into account the previous spatio-temporal information about a vehicule (through \das signal analysis) in order to predict its movement and speed. The innovation of this technique lays in the signal deconvolution, since the deconvolved signal is then analyzed with traditional beamforming techniques (\ie signal processing techniques that can deduce informations such as speed and position from a deconvolved signal).

The \dae deconvolution process starts with a set of \das channels, which contains one (or more, in the real world but we simplify for this explanation) inpulse, \ie a ``wave'', each. It outputs for each \das channel the moment at which the inpulse occurs (\ie when the car passes). In the training phase, the output is then reconvolved and compared to the initial (true) \das channels in order to train the neural network. 

The results obtained by \dae, although probably slightly cherry-picked, as in most presentations, are superior to the state-of-the-art ``FISTA'' technique. This statement holds true on true positive, false positive and false negative counts. \dae shows even stronger results when the environment is noisy, be it because of noise \textit{per se}, or because there are multiple cars driving in both directions at the same time. These scenarios reflect the real world more accurately, which is an even stronger point in favor of \dae.

The speaker's presentation was part of the ``AI for smart cities'' part of the SophIA conference, which the speaker mentions in his talk. Because of the robustness of his method over traditional, state-of-the-art deconvolution methods, \dae can see future applications in smart cities. Problems related to heavy-traffic (\eg commute) periods could be partially solved. In a discussion I had with the speaker after his talk, he mentioned potential applications in communications with GPS systems in order to minimize such traffic jams. Furthermore, his method is faster than the state-of-the art: about 30 seconds to deconvolve a 24 hours \das dataset, against 3 hours for FISTA to deconvolve the same dataset.

In conclusion, this new deconvolution technique seems promising and could find applications in smart cities, speed limit enforcement or traffic improvement, among others. The fact that it is not only non-negligibly faster (more than 400 times) than other state-of-the-art methods, but also more precise and robust gives it a practical advantage for real world settings.



\end{document}