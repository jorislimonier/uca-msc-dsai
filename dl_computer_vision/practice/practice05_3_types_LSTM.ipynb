{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8jPpZ1rzIkxW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-08 11:28:28.619027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-08 11:28:29.016785: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-02-08 11:28:29.969654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-08 11:28:29.969942: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-08 11:28:29.969955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XKHtkAv6I1QX"
      },
      "outputs": [],
      "source": [
        "# define input sequence\n",
        "raw_seq = [*range(10, 100, 10)]\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uxPIRz6dMFnP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[10, 20, 30, 40],\n",
              "       [20, 30, 40, 50],\n",
              "       [30, 40, 50, 60],\n",
              "       [40, 50, 60, 70],\n",
              "       [50, 60, 70, 80]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8r4AFXLR_8oz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 4)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aec-e8sCI5dG"
      },
      "outputs": [],
      "source": [
        "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[10],\n",
              "         [20]],\n",
              "\n",
              "        [[30],\n",
              "         [40]]],\n",
              "\n",
              "\n",
              "       [[[20],\n",
              "         [30]],\n",
              "\n",
              "        [[40],\n",
              "         [50]]],\n",
              "\n",
              "\n",
              "       [[[30],\n",
              "         [40]],\n",
              "\n",
              "        [[50],\n",
              "         [60]]],\n",
              "\n",
              "\n",
              "       [[[40],\n",
              "         [50]],\n",
              "\n",
              "        [[60],\n",
              "         [70]]],\n",
              "\n",
              "\n",
              "       [[[50],\n",
              "         [60]],\n",
              "\n",
              "        [[70],\n",
              "         [80]]]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NONwCI6FKye3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 2, 2, 1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "5Oy8p7gLJDJd"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "The added layer must be an instance of class Layer. Received: layer=<class 'keras.layers.pooling.max_pooling1d.MaxPooling1D'> of type <class 'type'>.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39madd(TimeDistributed(Conv1D(filters\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m), input_shape\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, n_steps, n_features)))\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39madd(Conv1D(filters\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m model\u001b[39m.\u001b[39madd(MaxPooling1D)\n\u001b[1;32m      6\u001b[0m model\u001b[39m.\u001b[39mFlatten()\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39madd(LSTM)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/sequential.py:183\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    181\u001b[0m         layer \u001b[39m=\u001b[39m functional\u001b[39m.\u001b[39mModuleWrapper(layer)\n\u001b[1;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe added layer must be an instance of class Layer. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: layer=\u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(layer)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    188\u001b[0m tf_utils\u001b[39m.\u001b[39massert_no_legacy_layers([layer])\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_layer_name_unique(layer):\n",
            "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Received: layer=<class 'keras.layers.pooling.max_pooling1d.MaxPooling1D'> of type <class 'type'>."
          ]
        }
      ],
      "source": [
        "# To_Do: define a CNN LSTM model using 1D convolution of 64 filters and kernel size of 1\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
        "model.add(Conv1D(filters=64, kernel_size=1, activation='relu'))\n",
        "model.add(MaxPooling1D)\n",
        "model.Flatten()\n",
        "model.add(LSTM)\n",
        "model.add(Dense)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS4Lq08SJffX"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c970kC0LLHFT"
      },
      "outputs": [],
      "source": [
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([60, 70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndfatfd-Pxmq"
      },
      "outputs": [],
      "source": [
        "from keras.layers import ConvLSTM2D\n",
        "\n",
        " \n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))\n",
        "###### To_Do: define ConvLSTM model with 64 filters and kernel size (1,2) ##############\n",
        "\n",
        "\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([60, 70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "f0df963a0b00f23561625d2ba0a0b8b2d4dd4941b6b854c35050f99f4efed218"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
