{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbpsgVVABuTY",
        "outputId": "49bc1fa0-af7c-4098-9e7e-2a1de1bb890e"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/srijandas07/video_convolution.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwgf61SbCrba",
        "outputId": "a90438fe-e0bf-4a22-ccbf-f3c8cfee7049"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'video_convolution/scripts/'\n",
            "/media/joris/uca-msc-dsai/dl_computer_vision/practice\n"
          ]
        }
      ],
      "source": [
        "cd video_convolution/scripts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v2m5Yl1QDWHn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/media/joris/uca-msc-dsai/dl_computer_vision/practice\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ATH0s-tMEtfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-08 09:50:42.142328: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "2023-02-08 09:50:42.420362: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.applications.vgg16 import VGG16, decode_predictions, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "# To_Do: load VGG model\n",
        "model = VGG16(weights=\"imagenet\", include_top=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1QtASPOabSA",
        "outputId": "8d45591a-115a-441f-8632-2d27a45116d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nFeHq25Zapwq"
      },
      "outputs": [],
      "source": [
        "#To_Do: create a model using VGG16 architecture to perform feature extraction\n",
        "model = Model(inputs=model.input, outputs=model.get_layer('fc2').output)\n",
        "f_size = 4096"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlxyUKz3atvJ",
        "outputId": "7b314005-f164-49fb-ae70-ed681b51b127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dZSq0N-NFGyw"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/video_convolution/data/p1_arrangingobjects_subAction510175554/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/content/video_convolution/data/p1_arrangingobjects_subAction510175554/\u001b[39m\u001b[39m'\u001b[39m                           \n\u001b[0;32m----> 2\u001b[0m n_files \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(file_path))\n\u001b[1;32m      3\u001b[0m f_p \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mnormpath(file_path))\n\u001b[1;32m      4\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/video_convolution/data/p1_arrangingobjects_subAction510175554/'"
          ]
        }
      ],
      "source": [
        "file_path = '/content/video_convolution/data/p1_arrangingobjects_subAction510175554/'                           \n",
        "n_files = sorted(os.listdir(file_path))\n",
        "f_p = os.path.basename(os.path.normpath(file_path))\n",
        "batch_size = 50\n",
        "k = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bbVWkleVFf_k"
      },
      "outputs": [],
      "source": [
        "def data_load_batch(k, batch_size):\n",
        "  t_file = []\n",
        "  for img_file in n_files[0 + k : batch_size + k]:\n",
        "    img_path = file_path + \"/\" + img_file\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = img_to_array(img)\n",
        "    t_file.append(preprocess_input(x))\n",
        "  t_file = np.asarray(t_file)\n",
        "  return t_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuOWPe9QQeC_"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "features_conv = []\n",
        "\n",
        "for i in range(0, int(len(n_files)/batch_size)):\n",
        "    images = data_load_batch(k, batch_size)\n",
        "    #To_Do: extract features from the created model providing batch as input\n",
        "    features_conv.append(model.predict(images,batch_size=batch_size))\n",
        "    k = k + batch_size\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVmJFVKaEvpL",
        "outputId": "417b73e1-f48f-4570-9743-2a0b4804ffa3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 50, 4096)"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_conv = np.asarray(features_conv)\n",
        "features_conv.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Nc7CeSDvo3",
        "outputId": "c4e7834f-2015-4ac9-9838-1c9ab950f203"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200, 4096)"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_conv = np.reshape(features_conv, [features_conv.shape[0]*features_conv.shape[1], f_size])\n",
        "features_conv.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYx9Y7skVnDv",
        "outputId": "a0e72bf3-b7b1-45a9-b533-e295c113d63b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(232, 4096)"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images_remain = len(n_files) - k\n",
        "features_conv5_remain = []\n",
        "if images_remain > 0:\n",
        "   images = data_load_batch(k, images_remain)\n",
        "   features_conv5_remain.append(model.predict(images, batch_size=images_remain))\n",
        "features_conv5_remain = np.asarray(features_conv5_remain)                           \n",
        "features_conv5_remain = np.squeeze(features_conv5_remain)\n",
        "features_conv = np.vstack([features_conv, features_conv5_remain])\n",
        "features_conv.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxh3tECiH96q"
      },
      "outputs": [],
      "source": [
        "np.savetxt('./'+f_p+'.csv.gz', features_conv, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO7ncPVVJMVG"
      },
      "outputs": [],
      "source": [
        "def max_min_conv(video):\n",
        "    frame_features  = np.loadtxt(video, delimiter=',')\n",
        "    max_features = np.amax(frame_features, axis=0)\n",
        "    min_features = np.amin(frame_features, axis=0)\n",
        "    final_t1 = np.hstack([max_features, min_features])\n",
        "    return final_t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3mg_J7NJe4l"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "path = './'\n",
        "for video in glob.glob(path+'*.csv.gz'):\n",
        "    desc = []\n",
        "    features = max_min_conv(os.path.join(path, video))\n",
        "    desc = np.hstack([desc, features.ravel()])\n",
        "    np.savetxt('/content/video_convolution/results/video_descriptors/'+os.path.basename(video)+'.txt', desc, delimiter=',')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
