{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(p, q, base=2):\n",
    "    \"\"\"\n",
    "    Perform some checks, then compute the cross-entropy between `p` and `q`.\n",
    "    \"\"\"\n",
    "    for distr in [p, q]:\n",
    "        # check probabilities sum up to 1\n",
    "        err_mess = f\"the probabilities of {distr} should sum up to 1\"\n",
    "        assert np.isclose(sum(distr), 1), err_mess\n",
    "\n",
    "        # check non-negative probabilities\n",
    "        err_mess = f\"all probabilities of {distr} should be non-negative\"\n",
    "        assert np.alltrue([val >= 0 for val in distr]), err_mess\n",
    "\n",
    "        # check probabilities at most 1\n",
    "        err_mess = f\"all probabilities of {distr} should be at most 1\"\n",
    "        assert np.alltrue([val <= 1 for val in distr]), err_mess\n",
    "\n",
    "    # check same array lengths\n",
    "    err_mess = f\"both arrays should have the same length\"\n",
    "    assert len(p) == len(q), err_mess\n",
    "\n",
    "    cross_ent = 0\n",
    "    for p_i, q_i in zip(p, q):\n",
    "        if q_i == 0:\n",
    "            continue\n",
    "        cross_ent -= p_i * np.log(q_i) / np.log(base)\n",
    "\n",
    "    return cross_ent\n",
    "\n",
    "\n",
    "def entropy(p, base=2):\n",
    "    \"\"\"\n",
    "    Return the entropy of `p` (that is, the cross entropy with itself).\n",
    "    \"\"\"\n",
    "    return cross_entropy(p=p, q=p, base=base)\n",
    "\n",
    "\n",
    "def KL_div(distr_from, distr_to, base=2):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence from `distr_from` to `distr_to`.\n",
    "    \"\"\"\n",
    "    cross_ent = cross_entropy(p=distr_from, q=distr_to, base=base)\n",
    "    ent = entropy(p=distr_from, base=base)\n",
    "    return cross_ent - ent\n",
    "\n",
    "\n",
    "def fit_poly(X, y):\n",
    "    \"\"\"\n",
    "    Fit a linear model with polynomial features to data `X` and target `y`.\n",
    "    \"\"\"\n",
    "    w_ml = np.linalg.solve(X.T.dot(X), X.T.dot(y))\n",
    "    w_ml.reshape(1, (len(w_ml)))\n",
    "    sigma2_ml = np.mean((y - X.dot(w_ml.T)) ** 2)\n",
    "    return w_ml, sigma2_ml\n",
    "\n",
    "\n",
    "def gaussian_loglik(X, y, w_ml, sigma2_ml):\n",
    "    \"\"\"\n",
    "    Compute the Gaussian log-likelihood of parameterers `w_ml`, `sigma2_ml` with data `X` and target `y`.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    loglik = -N / 2 * np.log(2 * np.pi * sigma2_ml)  # term 1\n",
    "    loglik -= 1 / (2 * sigma2_ml) * np.sum((y - X.dot(w_ml.T)) ** 2)  # term 2\n",
    "    return loglik\n",
    "\n",
    "\n",
    "def deviance(loglik):\n",
    "    \"\"\"\n",
    "    Compute the deviance of a model, given its log-likelihood.\n",
    "    \"\"\"\n",
    "    return -2 * np.array(loglik)\n",
    "\n",
    "\n",
    "def AIC(training_deviance, n_params):\n",
    "    \"\"\"\n",
    "    Compute the Akaike Information Criterion of a model.\n",
    "    \"\"\"\n",
    "    return training_deviance + 2 * n_params\n",
    "\n",
    "\n",
    "def AICc(training_deviance, n_params, n_obs):\n",
    "    \"\"\"\n",
    "    Compute the corrected Akaike Information Criterion of a model.\n",
    "    Usually used if `n_obs / n_params < 40`.\n",
    "    \"\"\"\n",
    "    aic = AIC(training_deviance, n_params)\n",
    "    corr = 2 * n_params * (n_params + 1) / (n_obs - n_params - 1)\n",
    "    return aic + corr\n",
    "\n",
    "\n",
    "def BIC(training_deviance, n_params, n_obs):\n",
    "    \"\"\"\n",
    "    Compute the Akaike Information Criterion of a model.\n",
    "    \"\"\"\n",
    "    return training_deviance + 2 * n_params * np.log(n_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
