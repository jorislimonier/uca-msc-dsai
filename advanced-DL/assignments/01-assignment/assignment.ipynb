{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Deep Learning â”€ Assignment 1\n",
    "\n",
    "## Question 1\n",
    "\n",
    "Try to load the same data directly from the \"MINST database\" website http://yann.lecun.com/exdb/mnist/. Be careful that the images can have a different normalization and encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(assignment)\n",
    "\n",
    "assignment.load_data_torch()\n",
    "# Set data sets\n",
    "X_train = assignment.load_data_ylc(\n",
    "  file_name=\"train-images-idx3-ubyte.gz\",\n",
    "  is_image=True,\n",
    "  nb_images=60000,\n",
    ")\n",
    "y_train = assignment.load_data_ylc(\n",
    "  file_name=\"train-labels-idx1-ubyte.gz\",\n",
    "  is_image=False,\n",
    "  nb_images=60000,\n",
    "  normalize=False,\n",
    ")\n",
    "X_test = assignment.load_data_ylc(\n",
    "  file_name=\"t10k-images-idx3-ubyte.gz\",\n",
    "  is_image=True,\n",
    "  nb_images=10000,\n",
    ")\n",
    "y_test = assignment.load_data_ylc(\n",
    "  file_name=\"t10k-labels-idx1-ubyte.gz\",\n",
    "  is_image=False,\n",
    "  nb_images=10000,\n",
    "  normalize=False,\n",
    ")\n",
    "# Transform labels to one_hot encoding\n",
    "y_train_one_hot = torch.nn.functional.one_hot(\n",
    "  y_train.to(torch.int64), num_classes=10\n",
    ").float()\n",
    "y_test_one_hot = torch.nn.functional.one_hot(\n",
    "  y_test.to(torch.int64), num_classes=10\n",
    ").float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "Using the utilities in plt and numpy display some images and check that the corresponding labels are consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = assignment.display_digits(X_train=X_train, y_train=y_train)\n",
    "fig.show()\n",
    "fig.write_image(\"data/labels.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "Complete the code below so to have a MLP with one hidden layer with 300 neurons. \\\n",
    "Remember that we want one-hot outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us define the neural network we are using\n",
    "\n",
    "hidden_sizes = [16, 16]\n",
    "net = define_net(hidden_sizes=hidden_sizes)\n",
    "\n",
    "# Now we define the optimizer and the loss function\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "# Initialize arrays to track errors\n",
    "# The test error array is there for informative purposes.\n",
    "# We do not use it when updating weights.\n",
    "# In a real world scenario, we shoudln't even look at it to choose when to (early-) stop training.\n",
    "error_train = []\n",
    "error_test = []\n",
    "\n",
    "inputs = torch.flatten(X_train, start_dim=1, end_dim=2)\n",
    "labels = y_train_one_hot\n",
    "\n",
    "\n",
    "sum([p.numel() for p in net.parameters()])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "net = net.to(device)\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "y_test_one_hot = y_test_one_hot.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "Complete the code below to perform a GD based optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(20000):\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  outputs = net(inputs)\n",
    "  outputs = outputs.to(device)\n",
    "\n",
    "  # Define the empirical risk\n",
    "  risk = loss(outputs, labels)\n",
    "\n",
    "  # Make the backward step (1 line instruction)\n",
    "  risk.backward()\n",
    "\n",
    "  # Update the parameters (1 line instruction)\n",
    "  optimizer.step()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    y_pred_one_hot = net(torch.flatten(X_test, start_dim=1, end_dim=2))\n",
    "    prediction_loss = loss(y_pred_one_hot, y_test_one_hot)\n",
    "\n",
    "    error_train.append(risk.item())\n",
    "    error_test.append(prediction_loss.item())\n",
    "\n",
    "    print(\n",
    "      f\"k = {k}, \\tRisk = {risk.item()}, \\tPrediction loss = {prediction_loss.item()}\"\n",
    "    )\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame({\"train_error\": error_train, \"test_error\": error_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = assignment.plot_errors(df_results=df_results, hidden_sizes=hidden_sizes)\n",
    "fig.show()\n",
    "\n",
    "# Write image with logarithmic scale\n",
    "fig = assignment.plot_errors(\n",
    "  df_results=df_results, hidden_sizes=hidden_sizes, log_y=True\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "Compute the final accuracy on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_one_hot = net(torch.flatten(X_test, start_dim=1, end_dim=2))\n",
    "y_pred = torch.argmax(input=y_pred_one_hot, dim=1)\n",
    "acc = (y_test == y_pred).sum() / len(y_test)\n",
    "print(\"Final accuracy on test\", float(acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
