{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YSWmjZ7CJEMX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt5O5b0eJgCA"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-Kf8UgrxJisN"
      },
      "outputs": [],
      "source": [
        "# download the dataset FashionMNIST\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f9kbmbeeJuez"
      },
      "outputs": [],
      "source": [
        "# prepare DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, \n",
        "                              batch_size=100, \n",
        "                              shuffle=True, \n",
        "                              num_workers=2)\n",
        "test_dataloader = DataLoader(test_data, \n",
        "                             batch_size=100, \n",
        "                             shuffle=False, \n",
        "                             num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HndO7jzLKsml"
      },
      "source": [
        "## Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PWiyigtTKuaD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FashionCNN(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
            "  (drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# define the model\n",
        "class FashionCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionCNN, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=64 * 6 * 6, out_features=600)\n",
        "        self.drop = nn.Dropout2d(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = self.drop(out)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.relu(self.fc3(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "model = FashionCNN()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6Nk90JCLAdI"
      },
      "source": [
        "## Loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tbbaJO5CLDpQ"
      },
      "outputs": [],
      "source": [
        "# define loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ABXHTrfLQ26"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DrppPQOoLRz7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 0.911\n",
            "[1,   200] loss: 0.653\n",
            "[1,   300] loss: 0.595\n",
            "[1,   400] loss: 0.569\n",
            "[1,   500] loss: 0.559\n",
            "[1,   600] loss: 0.527\n",
            "[2,   100] loss: 0.497\n",
            "[2,   200] loss: 0.517\n",
            "[2,   300] loss: 0.505\n",
            "[2,   400] loss: 0.475\n",
            "[2,   500] loss: 0.279\n",
            "[2,   600] loss: 0.269\n",
            "[3,   100] loss: 0.250\n",
            "[3,   200] loss: 0.240\n",
            "[3,   300] loss: 0.233\n",
            "[3,   400] loss: 0.240\n",
            "[3,   500] loss: 0.236\n",
            "[3,   600] loss: 0.239\n",
            "[4,   100] loss: 0.205\n",
            "[4,   200] loss: 0.212\n",
            "[4,   300] loss: 0.218\n",
            "[4,   400] loss: 0.207\n",
            "[4,   500] loss: 0.220\n",
            "[4,   600] loss: 0.203\n",
            "[5,   100] loss: 0.180\n",
            "[5,   200] loss: 0.189\n",
            "[5,   300] loss: 0.183\n",
            "[5,   400] loss: 0.190\n",
            "[5,   500] loss: 0.186\n",
            "[5,   600] loss: 0.182\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz9BbaI8gKuW"
      },
      "source": [
        "Q1: Discussion on batch-size.\n",
        "*   What is batch-size in Neural Network. Where is it defined in the code?\n",
        "*   Try to vary the batch-size in the code. What do you notice?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2JmYBd8OSqJ"
      },
      "source": [
        "## Train on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYzVXpHLgor_"
      },
      "source": [
        "The following commands show how to transfer tensors and model to GPU.\n",
        "\n",
        "Place them in the correct position of the code above and monitor the changes.\n",
        "\n",
        "You need to change runtime to GPU:\n",
        "*   Go to Runtime -> Change runtime type -> Hardware accelerator: GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FhJ_HEEHOfoC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# define our device as GPU if available otherwise CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fg0N417aO3oE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FashionCNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
              "  (drop): Dropout2d(p=0.25, inplace=False)\n",
              "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
              "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# move the model to GPU\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NS3LYsLPBTj"
      },
      "outputs": [],
      "source": [
        "# move the input and label tensors to GPU\n",
        "inputs, labels = data[0].to(device), data[1].to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ldMIYQZhzj7"
      },
      "source": [
        "Q2: Discussion on GPU.\n",
        "*   Use the magic command `%%time` to measure the training time.\n",
        "*   Compare the training time when using CPU and GPU.\n",
        "*   Measure the speed-up with GPU. What is the speed-up factor?\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "torch.nn with FashionMNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
