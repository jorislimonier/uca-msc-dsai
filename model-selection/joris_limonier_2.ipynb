{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{Exercise\\, 1.}$ Illustrate with a meaningful example the bias variance decomposition, as we have seen it during lesson, for the non linear Support Vector Regression model, for increasing vaues of the regularization parameter _C_ (for example C = 1e-3, 1e-2, 1e-1, 1, 1e2, $\\ldots$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sklearn call for Support Vector Regression with C = parameter_value\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "parameter_value = 1e-2\n",
    "\n",
    "poly = SVR(kernel='rbf', C = parameter_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{Exercise\\, 2.}$ Modify the example of Exercise 1 to show the effect of increasing noise values on the bias and on the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{Exercise\\, 3.}$ Still from the example of Exercise 1, compute the difference between training error and testing error for different vaues of the regularization parameter _C_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go back to the usual iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing the data from sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# importing the data from sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "\n",
    "# extracting the relevant information\n",
    "data = iris_dataset.data\n",
    "data_feature_names = iris_dataset.feature_names\n",
    "target = iris_dataset.target\n",
    "target_names = iris_dataset.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{Exercise\\, 1.}$ Using bootstrap, compute a 95% confidence interval for the median of the feature $\\mbox{sepal length (cm)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{Exercise\\, 2.}$ Compute the null distribution for the hypothesis $H_0$: the mean of $\\mbox{'sepal width (cm)'}$ is the same for $\\mbox{setosa}$ and $\\mbox{virginica}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{Exercise\\, 3.}$ Compute a 2-sided bootstrapped p-value for the difference between the means of $\\mbox{setosa}$ and $\\mbox{virginica}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{Exercise\\, 4.}$ The central limit theorem (Lindeberg-Levy version) states that given a sequence $X_1, X_2, \\ldots, X_n $ of independent variables drawn from the same ditribution, $X_i\\sim F$, then:\n",
    "\n",
    "$$ \\sqrt{n} \\left( \\frac{1}{n} \\sum X_i - \\mu \\right) \\rightarrow \\mathcal{N}(0,\\sigma^2),$$\n",
    "\n",
    "where $\\mu = \\mathbf{E}[F]$ and $\\sigma^2 = Var(F)$.\n",
    "In particular, the sample mean converges to the normal distribution:\n",
    "\n",
    "$$ \\frac{1}{n} \\sum X_i \\rightarrow \\mathcal{N}(\\mu,\\frac{\\sigma^2}{n}). $$\n",
    "\n",
    "Let $F = Exponential(2)$ be the exponential distribution with parameter $\\lambda = 2$, and let $X_1, X_2, \\ldots, X_{20}$ be 20 samples from this distribution. Verify for this case the central limit theorem via bootstrapping. \n",
    "\n",
    "__**__ Remember, the mean of the exponential distribution is $\\mathbf{E}(F) = 1/\\lambda$, while the variance is $Var(F) = 1/\\lambda^2$ __**__\n",
    "\n",
    "Hint:\n",
    "\n",
    "- Draw n samples (n large) from the Exponential distribution (be careful, when using $\\mbox{np.random.exponential}$ the required input scale parameter is $\\frac{1}{\\lambda}$).\n",
    "- Compute their average $\\frac{\\sum X_i}{20}$ and store the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
