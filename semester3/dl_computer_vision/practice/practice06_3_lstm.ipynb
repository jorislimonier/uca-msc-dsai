{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nCcHqvXqbfp",
        "outputId": "0ee06b7d-d8bb-4fc5-9319-114f75866760"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM_poses.tar.gz  models.py\t\t   __pycache__\t test.txt\n",
            "lstm_train.sh\t   MSR_skeleton_loader.py  README.md\t train.txt\n",
            "main.py\t\t   options.py\t\t   test_code.py  validation.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwkcJNoCyFeL",
        "outputId": "01df22bf-ec0e-4af0-f317-425446599c15"
      },
      "source": [
        "rm -r TP_Action_Recognition_using_LSTM/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'TP_Action_Recognition_using_LSTM/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_p0-I0zykd7",
        "outputId": "4285d6a8-04f7-4fd1-ead9-e70f754d0d47"
      },
      "source": [
        "!pip install keras==2.3.1\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==1.14.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.7/dist-packages (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1) (1.5.2)\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: tensorflow-gpu==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.41.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Found existing installation: tensorflow-cpu 2.6.0\n",
            "Uninstalling tensorflow-cpu-2.6.0:\n",
            "  Successfully uninstalled tensorflow-cpu-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwVtrQgXhEob",
        "outputId": "aea1e919-6e93-479c-8a95-8970ebea5960"
      },
      "source": [
        "!git clone https://github.com/dairui01/TP_Action_Recognition_using_LSTM.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'TP_Action_Recognition_using_LSTM'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 33 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIhjONx9hJHP",
        "outputId": "4b610c88-b214-471e-e43b-77378193f804"
      },
      "source": [
        "cd TP_Action_Recognition_using_LSTM/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/TP_Action_Recognition_using_LSTM/TP_Action_Recognition_using_LSTM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_daTvuh0OMW",
        "outputId": "84b6cfd0-0a64-4c5b-dc5b-41920a32e291"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM_poses.tar.gz  models.py\t\t   README.md\t train.txt\n",
            "lstm_train.sh\t   MSR_skeleton_loader.py  test_code.py  validation.txt\n",
            "main.py\t\t   options.py\t\t   test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "300RAxBB2EHl"
      },
      "source": [
        "**Uncompressed the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYi8s7LJhXJ-",
        "outputId": "66193652-3c98-42ed-e14e-582c0b796673"
      },
      "source": [
        "!tar xvzf \"LSTM_poses.tar.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM_poses/a03_s07_e01_rgb.npz\n",
            "LSTM_poses/a01_s08_e02_rgb.npz\n",
            "LSTM_poses/a03_s03_e01_rgb.npz\n",
            "LSTM_poses/a10_s07_e01_rgb.npz\n",
            "LSTM_poses/a10_s05_e01_rgb.npz\n",
            "LSTM_poses/a03_s05_e01_rgb.npz\n",
            "LSTM_poses/a07_s09_e01_rgb.npz\n",
            "LSTM_poses/a01_s10_e01_rgb.npz\n",
            "LSTM_poses/a15_s02_e02_rgb.npz\n",
            "LSTM_poses/a07_s07_e01_rgb.npz\n",
            "LSTM_poses/a14_s09_e01_rgb.npz\n",
            "LSTM_poses/a14_s07_e01_rgb.npz\n",
            "LSTM_poses/a07_s05_e01_rgb.npz\n",
            "LSTM_poses/a12_s10_e01_rgb.npz\n",
            "LSTM_poses/a05_s10_e01_rgb.npz\n",
            "LSTM_poses/a16_s10_e01_rgb.npz\n",
            "LSTM_poses/a09_s10_e01_rgb.npz\n",
            "LSTM_poses/a10_s05_e02_rgb.npz\n",
            "LSTM_poses/a03_s01_e02_rgb.npz\n",
            "LSTM_poses/a10_s03_e02_rgb.npz\n",
            "LSTM_poses/a10_s01_e02_rgb.npz\n",
            "LSTM_poses/a03_s03_e02_rgb.npz\n",
            "LSTM_poses/a02_s08_e01_rgb.npz\n",
            "LSTM_poses/a14_s05_e02_rgb.npz\n",
            "LSTM_poses/a07_s05_e02_rgb.npz\n",
            "LSTM_poses/a14_s07_e02_rgb.npz\n",
            "LSTM_poses/a14_s03_e02_rgb.npz\n",
            "LSTM_poses/a07_s03_e02_rgb.npz\n",
            "LSTM_poses/a12_s10_e02_rgb.npz\n",
            "LSTM_poses/a16_s02_e01_rgb.npz\n",
            "LSTM_poses/a09_s02_e01_rgb.npz\n",
            "LSTM_poses/a16_s10_e02_rgb.npz\n",
            "LSTM_poses/a09_s10_e02_rgb.npz\n",
            "LSTM_poses/a02_s08_e02_rgb.npz\n",
            "LSTM_poses/a04_s01_e01_rgb.npz\n",
            "LSTM_poses/a02_s06_e02_rgb.npz\n",
            "LSTM_poses/a15_s05_e01_rgb.npz\n",
            "LSTM_poses/a04_s03_e01_rgb.npz\n",
            "LSTM_poses/a11_s05_e01_rgb.npz\n",
            "LSTM_poses/a11_s03_e01_rgb.npz\n",
            "LSTM_poses/a04_s05_e01_rgb.npz\n",
            "LSTM_poses/a08_s05_e01_rgb.npz\n",
            "LSTM_poses/a13_s08_e02_rgb.npz\n",
            "LSTM_poses/a06_s08_e02_rgb.npz\n",
            "LSTM_poses/a08_s03_e01_rgb.npz\n",
            "LSTM_poses/a15_s07_e01_rgb.npz\n",
            "LSTM_poses/a15_s03_e01_rgb.npz\n",
            "LSTM_poses/a08_s07_e01_rgb.npz\n",
            "LSTM_poses/a13_s10_e01_rgb.npz\n",
            "LSTM_poses/a11_s01_e02_rgb.npz\n",
            "LSTM_poses/a11_s03_e02_rgb.npz\n",
            "LSTM_poses/a03_s08_e01_rgb.npz\n",
            "LSTM_poses/a04_s01_e02_rgb.npz\n",
            "LSTM_poses/a10_s08_e01_rgb.npz\n",
            "LSTM_poses/a03_s06_e01_rgb.npz\n",
            "LSTM_poses/a15_s05_e02_rgb.npz\n",
            "LSTM_poses/a08_s01_e02_rgb.npz\n",
            "LSTM_poses/a15_s01_e02_rgb.npz\n",
            "LSTM_poses/a15_s03_e02_rgb.npz\n",
            "LSTM_poses/a08_s03_e02_rgb.npz\n",
            "LSTM_poses/a14_s08_e01_rgb.npz\n",
            "LSTM_poses/a07_s08_e01_rgb.npz\n",
            "LSTM_poses/a07_s08_e02_rgb.npz\n",
            "LSTM_poses/a07_s04_e02_rgb.npz\n",
            "LSTM_poses/a03_s04_e02_rgb.npz\n",
            "LSTM_poses/a16_s03_e01_rgb.npz\n",
            "LSTM_poses/a10_s06_e02_rgb.npz\n",
            "LSTM_poses/a01_s01_e01_rgb.npz\n",
            "LSTM_poses/a10_s04_e02_rgb.npz\n",
            "LSTM_poses/a10_s08_e02_rgb.npz\n",
            "LSTM_poses/a03_s06_e02_rgb.npz\n",
            "LSTM_poses/a05_s03_e01_rgb.npz\n",
            "LSTM_poses/a12_s03_e01_rgb.npz\n",
            "LSTM_poses/a12_s01_e01_rgb.npz\n",
            "LSTM_poses/a05_s01_e01_rgb.npz\n",
            "LSTM_poses/a14_s08_e02_rgb.npz\n",
            "LSTM_poses/a14_s06_e02_rgb.npz\n",
            "LSTM_poses/a07_s06_e02_rgb.npz\n",
            "LSTM_poses/a09_s01_e01_rgb.npz\n",
            "LSTM_poses/a16_s05_e01_rgb.npz\n",
            "LSTM_poses/a16_s01_e01_rgb.npz\n",
            "LSTM_poses/a09_s03_e01_rgb.npz\n",
            "LSTM_poses/a16_s01_e02_rgb.npz\n",
            "LSTM_poses/a04_s04_e01_rgb.npz\n",
            "LSTM_poses/a15_s08_e01_rgb.npz\n",
            "LSTM_poses/a11_s08_e01_rgb.npz\n",
            "LSTM_poses/a04_s08_e01_rgb.npz\n",
            "LSTM_poses/a02_s09_e02_rgb.npz\n",
            "LSTM_poses/a12_s01_e02_rgb.npz\n",
            "LSTM_poses/a11_s04_e01_rgb.npz\n",
            "LSTM_poses/a11_s06_e01_rgb.npz\n",
            "LSTM_poses/a04_s06_e01_rgb.npz\n",
            "LSTM_poses/a08_s06_e01_rgb.npz\n",
            "LSTM_poses/a06_s09_e02_rgb.npz\n",
            "LSTM_poses/a16_s03_e02_rgb.npz\n",
            "LSTM_poses/a09_s01_e02_rgb.npz\n",
            "LSTM_poses/a15_s06_e01_rgb.npz\n",
            "LSTM_poses/a08_s08_e01_rgb.npz\n",
            "LSTM_poses/a12_s02_e01_rgb.npz\n",
            "LSTM_poses/a11_s02_e02_rgb.npz\n",
            "LSTM_poses/a04_s04_e02_rgb.npz\n",
            "LSTM_poses/a11_s06_e02_rgb.npz\n",
            "LSTM_poses/a08_s02_e02_rgb.npz\n",
            "LSTM_poses/a10_s09_e01_rgb.npz\n",
            "LSTM_poses/a11_s04_e02_rgb.npz\n",
            "LSTM_poses/a04_s02_e02_rgb.npz\n",
            "LSTM_poses/a08_s06_e02_rgb.npz\n",
            "LSTM_poses/a03_s09_e01_rgb.npz\n",
            "LSTM_poses/a13_s01_e01_rgb.npz\n",
            "LSTM_poses/a06_s01_e01_rgb.npz\n",
            "LSTM_poses/a15_s04_e02_rgb.npz\n",
            "LSTM_poses/a15_s06_e02_rgb.npz\n",
            "LSTM_poses/a08_s04_e02_rgb.npz\n",
            "LSTM_poses/a12_s04_e01_rgb.npz\n",
            "LSTM_poses/a16_s04_e01_rgb.npz\n",
            "LSTM_poses/a10_s09_e02_rgb.npz\n",
            "LSTM_poses/a03_s07_e02_rgb.npz\n",
            "LSTM_poses/a05_s10_e02_rgb.npz\n",
            "LSTM_poses/a01_s02_e01_rgb.npz\n",
            "LSTM_poses/a01_s04_e01_rgb.npz\n",
            "LSTM_poses/a10_s07_e02_rgb.npz\n",
            "LSTM_poses/a03_s09_e02_rgb.npz\n",
            "LSTM_poses/a03_s05_e02_rgb.npz\n",
            "LSTM_poses/a05_s02_e01_rgb.npz\n",
            "LSTM_poses/a01_s10_e02_rgb.npz\n",
            "LSTM_poses/a12_s06_e01_rgb.npz\n",
            "LSTM_poses/a05_s04_e01_rgb.npz\n",
            "LSTM_poses/a14_s09_e02_rgb.npz\n",
            "LSTM_poses/a07_s07_e02_rgb.npz\n",
            "LSTM_poses/a07_s09_e02_rgb.npz\n",
            "LSTM_poses/a09_s06_e01_rgb.npz\n",
            "LSTM_poses/a16_s06_e01_rgb.npz\n",
            "LSTM_poses/a16_s08_e01_rgb.npz\n",
            "LSTM_poses/a09_s04_e01_rgb.npz\n",
            "LSTM_poses/a02_s10_e01_rgb.npz\n",
            "LSTM_poses/a12_s02_e02_rgb.npz\n",
            "LSTM_poses/a05_s02_e02_rgb.npz\n",
            "LSTM_poses/a12_s04_e02_rgb.npz\n",
            "LSTM_poses/a04_s09_e01_rgb.npz\n",
            "LSTM_poses/a11_s07_e01_rgb.npz\n",
            "LSTM_poses/a11_s09_e01_rgb.npz\n",
            "LSTM_poses/a04_s07_e01_rgb.npz\n",
            "LSTM_poses/a09_s04_e02_rgb.npz\n",
            "LSTM_poses/a16_s02_e02_rgb.npz\n",
            "LSTM_poses/a16_s04_e02_rgb.npz\n",
            "LSTM_poses/a09_s02_e02_rgb.npz\n",
            "LSTM_poses/a15_s09_e01_rgb.npz\n",
            "LSTM_poses/a08_s09_e01_rgb.npz\n",
            "LSTM_poses/a06_s10_e01_rgb.npz\n",
            "LSTM_poses/a02_s10_e02_rgb.npz\n",
            "LSTM_poses/a08_s09_e02_rgb.npz\n",
            "LSTM_poses/a11_s09_e02_rgb.npz\n",
            "LSTM_poses/a04_s03_e02_rgb.npz\n",
            "LSTM_poses/a02_s02_e01_rgb.npz\n",
            "LSTM_poses/a04_s07_e02_rgb.npz\n",
            "LSTM_poses/a11_s05_e02_rgb.npz\n",
            "LSTM_poses/a11_s07_e02_rgb.npz\n",
            "LSTM_poses/a04_s05_e02_rgb.npz\n",
            "LSTM_poses/a08_s05_e02_rgb.npz\n",
            "LSTM_poses/a13_s04_e01_rgb.npz\n",
            "LSTM_poses/a13_s02_e01_rgb.npz\n",
            "LSTM_poses/a06_s02_e01_rgb.npz\n",
            "LSTM_poses/a15_s07_e02_rgb.npz\n",
            "LSTM_poses/a15_s09_e02_rgb.npz\n",
            "LSTM_poses/a08_s07_e02_rgb.npz\n",
            "LSTM_poses/a13_s10_e02_rgb.npz\n",
            "LSTM_poses/a06_s10_e02_rgb.npz\n",
            "LSTM_poses/a12_s07_e01_rgb.npz\n",
            "LSTM_poses/a16_s09_e01_rgb.npz\n",
            "LSTM_poses/a01_s03_e01_rgb.npz\n",
            "LSTM_poses/a01_s05_e01_rgb.npz\n",
            "LSTM_poses/a03_s08_e02_rgb.npz\n",
            "LSTM_poses/a05_s05_e01_rgb.npz\n",
            "LSTM_poses/a12_s05_e01_rgb.npz\n",
            "LSTM_poses/a12_s09_e01_rgb.npz\n",
            "LSTM_poses/a05_s07_e01_rgb.npz\n",
            "LSTM_poses/a10_s10_e01_rgb.npz\n",
            "LSTM_poses/a03_s10_e01_rgb.npz\n",
            "LSTM_poses/a09_s07_e01_rgb.npz\n",
            "LSTM_poses/a16_s07_e01_rgb.npz\n",
            "LSTM_poses/a09_s05_e01_rgb.npz\n",
            "LSTM_poses/a09_s09_e01_rgb.npz\n",
            "LSTM_poses/a14_s10_e01_rgb.npz\n",
            "LSTM_poses/a07_s10_e01_rgb.npz\n",
            "LSTM_poses/a01_s03_e02_rgb.npz\n",
            "LSTM_poses/a01_s01_e02_rgb.npz\n",
            "LSTM_poses/a05_s01_e02_rgb.npz\n",
            "LSTM_poses/a05_s05_e02_rgb.npz\n",
            "LSTM_poses/a12_s05_e02_rgb.npz\n",
            "LSTM_poses/a12_s03_e02_rgb.npz\n",
            "LSTM_poses/a05_s03_e02_rgb.npz\n",
            "LSTM_poses/a09_s07_e02_rgb.npz\n",
            "LSTM_poses/a14_s02_e01_rgb.npz\n",
            "LSTM_poses/a09_s03_e02_rgb.npz\n",
            "LSTM_poses/a16_s05_e02_rgb.npz\n",
            "LSTM_poses/a16_s07_e02_rgb.npz\n",
            "LSTM_poses/a09_s05_e02_rgb.npz\n",
            "LSTM_poses/a14_s10_e02_rgb.npz\n",
            "LSTM_poses/a04_s08_e02_rgb.npz\n",
            "LSTM_poses/a02_s01_e01_rgb.npz\n",
            "LSTM_poses/a02_s03_e01_rgb.npz\n",
            "LSTM_poses/a11_s08_e02_rgb.npz\n",
            "LSTM_poses/a04_s06_e02_rgb.npz\n",
            "LSTM_poses/a13_s05_e01_rgb.npz\n",
            "LSTM_poses/a06_s05_e01_rgb.npz\n",
            "LSTM_poses/a13_s07_e01_rgb.npz\n",
            "LSTM_poses/a13_s03_e01_rgb.npz\n",
            "LSTM_poses/a06_s03_e01_rgb.npz\n",
            "LSTM_poses/a15_s08_e02_rgb.npz\n",
            "LSTM_poses/a08_s08_e02_rgb.npz\n",
            "LSTM_poses/a15_s10_e01_rgb.npz\n",
            "LSTM_poses/a08_s10_e01_rgb.npz\n",
            "LSTM_poses/a02_s01_e02_rgb.npz\n",
            "LSTM_poses/a01_s08_e01_rgb.npz\n",
            "LSTM_poses/a01_s06_e01_rgb.npz\n",
            "LSTM_poses/a05_s06_e01_rgb.npz\n",
            "LSTM_poses/a06_s03_e02_rgb.npz\n",
            "LSTM_poses/a13_s03_e02_rgb.npz\n",
            "LSTM_poses/a13_s01_e02_rgb.npz\n",
            "LSTM_poses/a06_s01_e02_rgb.npz\n",
            "LSTM_poses/a12_s08_e01_rgb.npz\n",
            "LSTM_poses/a05_s08_e01_rgb.npz\n",
            "LSTM_poses/a09_s08_e01_rgb.npz\n",
            "LSTM_poses/a01_s06_e02_rgb.npz\n",
            "LSTM_poses/a14_s01_e01_rgb.npz\n",
            "LSTM_poses/a07_s03_e01_rgb.npz\n",
            "LSTM_poses/a05_s04_e02_rgb.npz\n",
            "LSTM_poses/a01_s02_e02_rgb.npz\n",
            "LSTM_poses/a01_s04_e02_rgb.npz\n",
            "LSTM_poses/a05_s08_e02_rgb.npz\n",
            "LSTM_poses/a10_s01_e01_rgb.npz\n",
            "LSTM_poses/a10_s03_e01_rgb.npz\n",
            "LSTM_poses/a03_s01_e01_rgb.npz\n",
            "LSTM_poses/a12_s06_e02_rgb.npz\n",
            "LSTM_poses/a12_s08_e02_rgb.npz\n",
            "LSTM_poses/a05_s06_e02_rgb.npz\n",
            "LSTM_poses/a09_s08_e02_rgb.npz\n",
            "LSTM_poses/a14_s03_e01_rgb.npz\n",
            "LSTM_poses/a14_s05_e01_rgb.npz\n",
            "LSTM_poses/a07_s01_e01_rgb.npz\n",
            "LSTM_poses/a16_s08_e02_rgb.npz\n",
            "LSTM_poses/a16_s06_e02_rgb.npz\n",
            "LSTM_poses/a09_s06_e02_rgb.npz\n",
            "LSTM_poses/a06_s04_e01_rgb.npz\n",
            "LSTM_poses/a02_s04_e01_rgb.npz\n",
            "LSTM_poses/a02_s06_e01_rgb.npz\n",
            "LSTM_poses/a06_s06_e01_rgb.npz\n",
            "LSTM_poses/a04_s09_e02_rgb.npz\n",
            "LSTM_poses/a13_s08_e01_rgb.npz\n",
            "LSTM_poses/a14_s01_e02_rgb.npz\n",
            "LSTM_poses/a07_s01_e02_rgb.npz\n",
            "LSTM_poses/a13_s06_e01_rgb.npz\n",
            "LSTM_poses/a06_s08_e01_rgb.npz\n",
            "LSTM_poses/a01_s09_e01_rgb.npz\n",
            "LSTM_poses/a11_s01_e01_rgb.npz\n",
            "LSTM_poses/a02_s04_e02_rgb.npz\n",
            "LSTM_poses/a02_s02_e02_rgb.npz\n",
            "LSTM_poses/a06_s02_e02_rgb.npz\n",
            "LSTM_poses/a01_s07_e01_rgb.npz\n",
            "LSTM_poses/a13_s04_e02_rgb.npz\n",
            "LSTM_poses/a06_s06_e02_rgb.npz\n",
            "LSTM_poses/a13_s02_e02_rgb.npz\n",
            "LSTM_poses/a13_s06_e02_rgb.npz\n",
            "LSTM_poses/a06_s04_e02_rgb.npz\n",
            "LSTM_poses/a05_s09_e01_rgb.npz\n",
            "LSTM_poses/a15_s01_e01_rgb.npz\n",
            "LSTM_poses/a08_s01_e01_rgb.npz\n",
            "LSTM_poses/a01_s09_e02_rgb.npz\n",
            "LSTM_poses/a10_s04_e01_rgb.npz\n",
            "LSTM_poses/a01_s05_e02_rgb.npz\n",
            "LSTM_poses/a14_s04_e01_rgb.npz\n",
            "LSTM_poses/a07_s04_e01_rgb.npz\n",
            "LSTM_poses/a05_s07_e02_rgb.npz\n",
            "LSTM_poses/a03_s04_e01_rgb.npz\n",
            "LSTM_poses/\n",
            "LSTM_poses/a01_s07_e02_rgb.npz\n",
            "LSTM_poses/a03_s02_e01_rgb.npz\n",
            "LSTM_poses/a10_s02_e01_rgb.npz\n",
            "LSTM_poses/a10_s06_e01_rgb.npz\n",
            "LSTM_poses/a03_s10_e02_rgb.npz\n",
            "LSTM_poses/a12_s09_e02_rgb.npz\n",
            "LSTM_poses/a12_s07_e02_rgb.npz\n",
            "LSTM_poses/a05_s09_e02_rgb.npz\n",
            "LSTM_poses/a07_s06_e01_rgb.npz\n",
            "LSTM_poses/a10_s10_e02_rgb.npz\n",
            "LSTM_poses/a14_s06_e01_rgb.npz\n",
            "LSTM_poses/a07_s02_e01_rgb.npz\n",
            "LSTM_poses/a16_s09_e02_rgb.npz\n",
            "LSTM_poses/a09_s09_e02_rgb.npz\n",
            "LSTM_poses/a07_s10_e02_rgb.npz\n",
            "LSTM_poses/a02_s07_e01_rgb.npz\n",
            "LSTM_poses/a10_s02_e02_rgb.npz\n",
            "LSTM_poses/a03_s02_e02_rgb.npz\n",
            "LSTM_poses/a02_s09_e01_rgb.npz\n",
            "LSTM_poses/a02_s05_e01_rgb.npz\n",
            "LSTM_poses/a07_s02_e02_rgb.npz\n",
            "LSTM_poses/a14_s04_e02_rgb.npz\n",
            "LSTM_poses/a14_s02_e02_rgb.npz\n",
            "LSTM_poses/a13_s09_e01_rgb.npz\n",
            "LSTM_poses/a06_s09_e01_rgb.npz\n",
            "LSTM_poses/a06_s07_e01_rgb.npz\n",
            "LSTM_poses/a11_s10_e01_rgb.npz\n",
            "LSTM_poses/a04_s10_e01_rgb.npz\n",
            "LSTM_poses/a04_s10_e02_rgb.npz\n",
            "LSTM_poses/a15_s02_e01_rgb.npz\n",
            "LSTM_poses/a02_s07_e02_rgb.npz\n",
            "LSTM_poses/a02_s03_e02_rgb.npz\n",
            "LSTM_poses/a02_s05_e02_rgb.npz\n",
            "LSTM_poses/a04_s02_e01_rgb.npz\n",
            "LSTM_poses/a11_s02_e01_rgb.npz\n",
            "LSTM_poses/a13_s07_e02_rgb.npz\n",
            "LSTM_poses/a06_s05_e02_rgb.npz\n",
            "LSTM_poses/a13_s05_e02_rgb.npz\n",
            "LSTM_poses/a13_s09_e02_rgb.npz\n",
            "LSTM_poses/a06_s07_e02_rgb.npz\n",
            "LSTM_poses/a08_s04_e01_rgb.npz\n",
            "LSTM_poses/a11_s10_e02_rgb.npz\n",
            "LSTM_poses/a15_s04_e01_rgb.npz\n",
            "LSTM_poses/a08_s02_e01_rgb.npz\n",
            "LSTM_poses/a15_s10_e02_rgb.npz\n",
            "LSTM_poses/a08_s10_e02_rgb.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCP6RIKv3NIb",
        "outputId": "09eff86b-ca69-4ed7-be44-0513172a698f"
      },
      "source": [
        "!ls LSTM_poses/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a01_s01_e01_rgb.npz  a06_s04_e02_rgb.npz  a11_s08_e01_rgb.npz\n",
            "a01_s01_e02_rgb.npz  a06_s05_e01_rgb.npz  a11_s08_e02_rgb.npz\n",
            "a01_s02_e01_rgb.npz  a06_s05_e02_rgb.npz  a11_s09_e01_rgb.npz\n",
            "a01_s02_e02_rgb.npz  a06_s06_e01_rgb.npz  a11_s09_e02_rgb.npz\n",
            "a01_s03_e01_rgb.npz  a06_s06_e02_rgb.npz  a11_s10_e01_rgb.npz\n",
            "a01_s03_e02_rgb.npz  a06_s07_e01_rgb.npz  a11_s10_e02_rgb.npz\n",
            "a01_s04_e01_rgb.npz  a06_s07_e02_rgb.npz  a12_s01_e01_rgb.npz\n",
            "a01_s04_e02_rgb.npz  a06_s08_e01_rgb.npz  a12_s01_e02_rgb.npz\n",
            "a01_s05_e01_rgb.npz  a06_s08_e02_rgb.npz  a12_s02_e01_rgb.npz\n",
            "a01_s05_e02_rgb.npz  a06_s09_e01_rgb.npz  a12_s02_e02_rgb.npz\n",
            "a01_s06_e01_rgb.npz  a06_s09_e02_rgb.npz  a12_s03_e01_rgb.npz\n",
            "a01_s06_e02_rgb.npz  a06_s10_e01_rgb.npz  a12_s03_e02_rgb.npz\n",
            "a01_s07_e01_rgb.npz  a06_s10_e02_rgb.npz  a12_s04_e01_rgb.npz\n",
            "a01_s07_e02_rgb.npz  a07_s01_e01_rgb.npz  a12_s04_e02_rgb.npz\n",
            "a01_s08_e01_rgb.npz  a07_s01_e02_rgb.npz  a12_s05_e01_rgb.npz\n",
            "a01_s08_e02_rgb.npz  a07_s02_e01_rgb.npz  a12_s05_e02_rgb.npz\n",
            "a01_s09_e01_rgb.npz  a07_s02_e02_rgb.npz  a12_s06_e01_rgb.npz\n",
            "a01_s09_e02_rgb.npz  a07_s03_e01_rgb.npz  a12_s06_e02_rgb.npz\n",
            "a01_s10_e01_rgb.npz  a07_s03_e02_rgb.npz  a12_s07_e01_rgb.npz\n",
            "a01_s10_e02_rgb.npz  a07_s04_e01_rgb.npz  a12_s07_e02_rgb.npz\n",
            "a02_s01_e01_rgb.npz  a07_s04_e02_rgb.npz  a12_s08_e01_rgb.npz\n",
            "a02_s01_e02_rgb.npz  a07_s05_e01_rgb.npz  a12_s08_e02_rgb.npz\n",
            "a02_s02_e01_rgb.npz  a07_s05_e02_rgb.npz  a12_s09_e01_rgb.npz\n",
            "a02_s02_e02_rgb.npz  a07_s06_e01_rgb.npz  a12_s09_e02_rgb.npz\n",
            "a02_s03_e01_rgb.npz  a07_s06_e02_rgb.npz  a12_s10_e01_rgb.npz\n",
            "a02_s03_e02_rgb.npz  a07_s07_e01_rgb.npz  a12_s10_e02_rgb.npz\n",
            "a02_s04_e01_rgb.npz  a07_s07_e02_rgb.npz  a13_s01_e01_rgb.npz\n",
            "a02_s04_e02_rgb.npz  a07_s08_e01_rgb.npz  a13_s01_e02_rgb.npz\n",
            "a02_s05_e01_rgb.npz  a07_s08_e02_rgb.npz  a13_s02_e01_rgb.npz\n",
            "a02_s05_e02_rgb.npz  a07_s09_e01_rgb.npz  a13_s02_e02_rgb.npz\n",
            "a02_s06_e01_rgb.npz  a07_s09_e02_rgb.npz  a13_s03_e01_rgb.npz\n",
            "a02_s06_e02_rgb.npz  a07_s10_e01_rgb.npz  a13_s03_e02_rgb.npz\n",
            "a02_s07_e01_rgb.npz  a07_s10_e02_rgb.npz  a13_s04_e01_rgb.npz\n",
            "a02_s07_e02_rgb.npz  a08_s01_e01_rgb.npz  a13_s04_e02_rgb.npz\n",
            "a02_s08_e01_rgb.npz  a08_s01_e02_rgb.npz  a13_s05_e01_rgb.npz\n",
            "a02_s08_e02_rgb.npz  a08_s02_e01_rgb.npz  a13_s05_e02_rgb.npz\n",
            "a02_s09_e01_rgb.npz  a08_s02_e02_rgb.npz  a13_s06_e01_rgb.npz\n",
            "a02_s09_e02_rgb.npz  a08_s03_e01_rgb.npz  a13_s06_e02_rgb.npz\n",
            "a02_s10_e01_rgb.npz  a08_s03_e02_rgb.npz  a13_s07_e01_rgb.npz\n",
            "a02_s10_e02_rgb.npz  a08_s04_e01_rgb.npz  a13_s07_e02_rgb.npz\n",
            "a03_s01_e01_rgb.npz  a08_s04_e02_rgb.npz  a13_s08_e01_rgb.npz\n",
            "a03_s01_e02_rgb.npz  a08_s05_e01_rgb.npz  a13_s08_e02_rgb.npz\n",
            "a03_s02_e01_rgb.npz  a08_s05_e02_rgb.npz  a13_s09_e01_rgb.npz\n",
            "a03_s02_e02_rgb.npz  a08_s06_e01_rgb.npz  a13_s09_e02_rgb.npz\n",
            "a03_s03_e01_rgb.npz  a08_s06_e02_rgb.npz  a13_s10_e01_rgb.npz\n",
            "a03_s03_e02_rgb.npz  a08_s07_e01_rgb.npz  a13_s10_e02_rgb.npz\n",
            "a03_s04_e01_rgb.npz  a08_s07_e02_rgb.npz  a14_s01_e01_rgb.npz\n",
            "a03_s04_e02_rgb.npz  a08_s08_e01_rgb.npz  a14_s01_e02_rgb.npz\n",
            "a03_s05_e01_rgb.npz  a08_s08_e02_rgb.npz  a14_s02_e01_rgb.npz\n",
            "a03_s05_e02_rgb.npz  a08_s09_e01_rgb.npz  a14_s02_e02_rgb.npz\n",
            "a03_s06_e01_rgb.npz  a08_s09_e02_rgb.npz  a14_s03_e01_rgb.npz\n",
            "a03_s06_e02_rgb.npz  a08_s10_e01_rgb.npz  a14_s03_e02_rgb.npz\n",
            "a03_s07_e01_rgb.npz  a08_s10_e02_rgb.npz  a14_s04_e01_rgb.npz\n",
            "a03_s07_e02_rgb.npz  a09_s01_e01_rgb.npz  a14_s04_e02_rgb.npz\n",
            "a03_s08_e01_rgb.npz  a09_s01_e02_rgb.npz  a14_s05_e01_rgb.npz\n",
            "a03_s08_e02_rgb.npz  a09_s02_e01_rgb.npz  a14_s05_e02_rgb.npz\n",
            "a03_s09_e01_rgb.npz  a09_s02_e02_rgb.npz  a14_s06_e01_rgb.npz\n",
            "a03_s09_e02_rgb.npz  a09_s03_e01_rgb.npz  a14_s06_e02_rgb.npz\n",
            "a03_s10_e01_rgb.npz  a09_s03_e02_rgb.npz  a14_s07_e01_rgb.npz\n",
            "a03_s10_e02_rgb.npz  a09_s04_e01_rgb.npz  a14_s07_e02_rgb.npz\n",
            "a04_s01_e01_rgb.npz  a09_s04_e02_rgb.npz  a14_s08_e01_rgb.npz\n",
            "a04_s01_e02_rgb.npz  a09_s05_e01_rgb.npz  a14_s08_e02_rgb.npz\n",
            "a04_s02_e01_rgb.npz  a09_s05_e02_rgb.npz  a14_s09_e01_rgb.npz\n",
            "a04_s02_e02_rgb.npz  a09_s06_e01_rgb.npz  a14_s09_e02_rgb.npz\n",
            "a04_s03_e01_rgb.npz  a09_s06_e02_rgb.npz  a14_s10_e01_rgb.npz\n",
            "a04_s03_e02_rgb.npz  a09_s07_e01_rgb.npz  a14_s10_e02_rgb.npz\n",
            "a04_s04_e01_rgb.npz  a09_s07_e02_rgb.npz  a15_s01_e01_rgb.npz\n",
            "a04_s04_e02_rgb.npz  a09_s08_e01_rgb.npz  a15_s01_e02_rgb.npz\n",
            "a04_s05_e01_rgb.npz  a09_s08_e02_rgb.npz  a15_s02_e01_rgb.npz\n",
            "a04_s05_e02_rgb.npz  a09_s09_e01_rgb.npz  a15_s02_e02_rgb.npz\n",
            "a04_s06_e01_rgb.npz  a09_s09_e02_rgb.npz  a15_s03_e01_rgb.npz\n",
            "a04_s06_e02_rgb.npz  a09_s10_e01_rgb.npz  a15_s03_e02_rgb.npz\n",
            "a04_s07_e01_rgb.npz  a09_s10_e02_rgb.npz  a15_s04_e01_rgb.npz\n",
            "a04_s07_e02_rgb.npz  a10_s01_e01_rgb.npz  a15_s04_e02_rgb.npz\n",
            "a04_s08_e01_rgb.npz  a10_s01_e02_rgb.npz  a15_s05_e01_rgb.npz\n",
            "a04_s08_e02_rgb.npz  a10_s02_e01_rgb.npz  a15_s05_e02_rgb.npz\n",
            "a04_s09_e01_rgb.npz  a10_s02_e02_rgb.npz  a15_s06_e01_rgb.npz\n",
            "a04_s09_e02_rgb.npz  a10_s03_e01_rgb.npz  a15_s06_e02_rgb.npz\n",
            "a04_s10_e01_rgb.npz  a10_s03_e02_rgb.npz  a15_s07_e01_rgb.npz\n",
            "a04_s10_e02_rgb.npz  a10_s04_e01_rgb.npz  a15_s07_e02_rgb.npz\n",
            "a05_s01_e01_rgb.npz  a10_s04_e02_rgb.npz  a15_s08_e01_rgb.npz\n",
            "a05_s01_e02_rgb.npz  a10_s05_e01_rgb.npz  a15_s08_e02_rgb.npz\n",
            "a05_s02_e01_rgb.npz  a10_s05_e02_rgb.npz  a15_s09_e01_rgb.npz\n",
            "a05_s02_e02_rgb.npz  a10_s06_e01_rgb.npz  a15_s09_e02_rgb.npz\n",
            "a05_s03_e01_rgb.npz  a10_s06_e02_rgb.npz  a15_s10_e01_rgb.npz\n",
            "a05_s03_e02_rgb.npz  a10_s07_e01_rgb.npz  a15_s10_e02_rgb.npz\n",
            "a05_s04_e01_rgb.npz  a10_s07_e02_rgb.npz  a16_s01_e01_rgb.npz\n",
            "a05_s04_e02_rgb.npz  a10_s08_e01_rgb.npz  a16_s01_e02_rgb.npz\n",
            "a05_s05_e01_rgb.npz  a10_s08_e02_rgb.npz  a16_s02_e01_rgb.npz\n",
            "a05_s05_e02_rgb.npz  a10_s09_e01_rgb.npz  a16_s02_e02_rgb.npz\n",
            "a05_s06_e01_rgb.npz  a10_s09_e02_rgb.npz  a16_s03_e01_rgb.npz\n",
            "a05_s06_e02_rgb.npz  a10_s10_e01_rgb.npz  a16_s03_e02_rgb.npz\n",
            "a05_s07_e01_rgb.npz  a10_s10_e02_rgb.npz  a16_s04_e01_rgb.npz\n",
            "a05_s07_e02_rgb.npz  a11_s01_e01_rgb.npz  a16_s04_e02_rgb.npz\n",
            "a05_s08_e01_rgb.npz  a11_s01_e02_rgb.npz  a16_s05_e01_rgb.npz\n",
            "a05_s08_e02_rgb.npz  a11_s02_e01_rgb.npz  a16_s05_e02_rgb.npz\n",
            "a05_s09_e01_rgb.npz  a11_s02_e02_rgb.npz  a16_s06_e01_rgb.npz\n",
            "a05_s09_e02_rgb.npz  a11_s03_e01_rgb.npz  a16_s06_e02_rgb.npz\n",
            "a05_s10_e01_rgb.npz  a11_s03_e02_rgb.npz  a16_s07_e01_rgb.npz\n",
            "a05_s10_e02_rgb.npz  a11_s04_e01_rgb.npz  a16_s07_e02_rgb.npz\n",
            "a06_s01_e01_rgb.npz  a11_s04_e02_rgb.npz  a16_s08_e01_rgb.npz\n",
            "a06_s01_e02_rgb.npz  a11_s05_e01_rgb.npz  a16_s08_e02_rgb.npz\n",
            "a06_s02_e01_rgb.npz  a11_s05_e02_rgb.npz  a16_s09_e01_rgb.npz\n",
            "a06_s02_e02_rgb.npz  a11_s06_e01_rgb.npz  a16_s09_e02_rgb.npz\n",
            "a06_s03_e01_rgb.npz  a11_s06_e02_rgb.npz  a16_s10_e01_rgb.npz\n",
            "a06_s03_e02_rgb.npz  a11_s07_e01_rgb.npz  a16_s10_e02_rgb.npz\n",
            "a06_s04_e01_rgb.npz  a11_s07_e02_rgb.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "uA8OZ2-KhxaN",
        "outputId": "778a114b-bd3d-4002-d364-aa041a728cd2"
      },
      "source": [
        "from MSR_skeleton_loader import DataGenerator\n",
        "timesteps = 30\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation\n",
        "from keras.layers import TimeDistributed, GaussianNoise, GaussianDropout, Dropout\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import scipy.io \n",
        "import keras\n",
        "import h5py\n",
        "import itertools\n",
        "#import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import model_from_json\n",
        "from models import build_model_without_TS                                                       \n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-5a4996705db8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mMSR_skeleton_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TP_Action_Recognition_using_LSTM/TP_Action_Recognition_using_LSTM/MSR_skeleton_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfdev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# TODO(fchollet): Remove hourglass imports once external code is done importing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# non-public APIs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers/initializers_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeLvPszd1x6F"
      },
      "source": [
        "**Skeleton Tensor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yRX_0_w1U7r",
        "outputId": "3e4c4fa2-3ae8-4e2b-97bf-49ce3d1f41eb"
      },
      "source": [
        "import numpy as np\n",
        "np.load('./LSTM_poses/a03_s05_e02_rgb.npz')['arr_0'].shape # shape Tx(20x3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(261, 60)"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URN_Kmb512B6"
      },
      "source": [
        "Define check points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W7A5VAahr3t"
      },
      "source": [
        "class CustomModelCheckpoint(Callback):\n",
        "\n",
        "    def __init__(self, model_parallel, path):\n",
        "\n",
        "        super(CustomModelCheckpoint, self).__init__()\n",
        "\n",
        "        self.save_model = model_parallel\n",
        "        self.path = path\n",
        "        self.nb_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.nb_epoch += 1\n",
        "        self.save_model.save(self.path + str(self.nb_epoch) + '.hdf5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SAC_U8916xb"
      },
      "source": [
        "**Set Parameters, Model summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4J4qZyNiOpv",
        "outputId": "bdad90a7-3239-4bcb-a094-09658b9eb44a"
      },
      "source": [
        "data_dim = 60\n",
        "num_classes = 16\n",
        "batch_size = 8\n",
        "n_neuron = 128\n",
        "n_dropout = 0.5\n",
        "name = 'MSR'\n",
        "\n",
        "csvlogger = CSVLogger(name+'_msr.csv')\n",
        "epochs = 100\n",
        "model = build_model_without_TS(n_neuron, n_dropout, batch_size, timesteps, data_dim, num_classes)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.005, clipnorm=1), metrics=['accuracy']) \n",
        "model.summary() # Model Summary \n",
        "train_generator = DataGenerator('./train.txt', batch_size = batch_size)\n",
        "val_generator = DataGenerator('./validation.txt', batch_size = batch_size)\n",
        "test_generator = DataGenerator('./test.txt', batch_size = batch_size)\n",
        "\n",
        "model_checkpoint = CustomModelCheckpoint(model, './model_scripts/epoch_')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build model!!!\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 30, 128)           96768     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 30, 128)           131584    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                2064      \n",
            "=================================================================\n",
            "Total params: 362,000\n",
            "Trainable params: 362,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a9Nwvtps4Y1"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z00FjHiGiRer",
        "outputId": "0c329c9c-8272-41cf-c755-7d1d19dbd530"
      },
      "source": [
        "model.fit_generator(generator=train_generator,\n",
        "                    validation_data=val_generator,\n",
        "                    use_multiprocessing=False,\n",
        "                    epochs=epochs,\n",
        "                    callbacks = [csvlogger, model_checkpoint],\n",
        "                    workers=6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 10s 139ms/step - loss: 2.7841 - accuracy: 0.1126 - val_loss: 2.6250 - val_accuracy: 0.0938\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 2.5104 - accuracy: 0.1661 - val_loss: 2.3286 - val_accuracy: 0.2188\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 2.4172 - accuracy: 0.1443 - val_loss: 2.4139 - val_accuracy: 0.1562\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 2.3461 - accuracy: 0.2450 - val_loss: 2.2565 - val_accuracy: 0.2812\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 2.2955 - accuracy: 0.2442 - val_loss: 2.6773 - val_accuracy: 0.0938\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 2.1809 - accuracy: 0.2325 - val_loss: 2.1388 - val_accuracy: 0.2812\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 2.1546 - accuracy: 0.2362 - val_loss: 2.1857 - val_accuracy: 0.1562\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 2.0442 - accuracy: 0.2448 - val_loss: 2.1195 - val_accuracy: 0.2812\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 2.1232 - accuracy: 0.2613 - val_loss: 2.6467 - val_accuracy: 0.1250\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 2.2404 - accuracy: 0.2745 - val_loss: 2.0074 - val_accuracy: 0.2812\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.9393 - accuracy: 0.3096 - val_loss: 1.9742 - val_accuracy: 0.3125\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.9078 - accuracy: 0.3107 - val_loss: 2.1622 - val_accuracy: 0.2500\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 2.0532 - accuracy: 0.3264 - val_loss: 2.0696 - val_accuracy: 0.2188\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 2.0044 - accuracy: 0.2867 - val_loss: 2.1542 - val_accuracy: 0.2500\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.9337 - accuracy: 0.2981 - val_loss: 1.8930 - val_accuracy: 0.4062\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 1.8350 - accuracy: 0.3453 - val_loss: 1.9307 - val_accuracy: 0.3125\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.8253 - accuracy: 0.3746 - val_loss: 2.3046 - val_accuracy: 0.2188\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.7568 - accuracy: 0.3696 - val_loss: 1.8923 - val_accuracy: 0.3125\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.9252 - accuracy: 0.3208 - val_loss: 2.1125 - val_accuracy: 0.3125\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.8295 - accuracy: 0.3273 - val_loss: 1.9025 - val_accuracy: 0.4062\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.8020 - accuracy: 0.3266 - val_loss: 1.9500 - val_accuracy: 0.3125\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.8515 - accuracy: 0.3339 - val_loss: 1.9851 - val_accuracy: 0.2812\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.7658 - accuracy: 0.3658 - val_loss: 1.9220 - val_accuracy: 0.3125\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 1.8402 - accuracy: 0.3260 - val_loss: 1.8162 - val_accuracy: 0.4062\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.6639 - accuracy: 0.3975 - val_loss: 2.0400 - val_accuracy: 0.2500\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.8162 - accuracy: 0.3804 - val_loss: 2.0728 - val_accuracy: 0.3438\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.7580 - accuracy: 0.3898 - val_loss: 2.3191 - val_accuracy: 0.2188\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.7543 - accuracy: 0.3365 - val_loss: 1.9772 - val_accuracy: 0.2812\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.6712 - accuracy: 0.3908 - val_loss: 1.9095 - val_accuracy: 0.3750\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.6364 - accuracy: 0.3996 - val_loss: 1.9928 - val_accuracy: 0.3750\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.5465 - accuracy: 0.4687 - val_loss: 1.8574 - val_accuracy: 0.2500\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.5714 - accuracy: 0.4091 - val_loss: 2.0819 - val_accuracy: 0.2812\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.5718 - accuracy: 0.4217 - val_loss: 1.7847 - val_accuracy: 0.3438\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.4881 - accuracy: 0.4538 - val_loss: 2.0810 - val_accuracy: 0.3125\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.5803 - accuracy: 0.4456 - val_loss: 1.8396 - val_accuracy: 0.3750\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.5207 - accuracy: 0.4258 - val_loss: 1.7110 - val_accuracy: 0.4375\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 1.4978 - accuracy: 0.4716 - val_loss: 2.0194 - val_accuracy: 0.3125\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.5250 - accuracy: 0.4416 - val_loss: 2.1196 - val_accuracy: 0.3125\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.3651 - accuracy: 0.5248 - val_loss: 1.8463 - val_accuracy: 0.3750\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.6685 - accuracy: 0.4299 - val_loss: 1.8582 - val_accuracy: 0.2812\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.3755 - accuracy: 0.4866 - val_loss: 1.6666 - val_accuracy: 0.4688\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.4034 - accuracy: 0.4912 - val_loss: 1.8042 - val_accuracy: 0.2812\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.4751 - accuracy: 0.4583 - val_loss: 2.0114 - val_accuracy: 0.3125\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.4041 - accuracy: 0.4216 - val_loss: 1.9225 - val_accuracy: 0.3438\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.3550 - accuracy: 0.5205 - val_loss: 2.0606 - val_accuracy: 0.3750\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.3631 - accuracy: 0.4982 - val_loss: 1.9285 - val_accuracy: 0.3438\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.4208 - accuracy: 0.5075 - val_loss: 1.9546 - val_accuracy: 0.3438\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.2536 - accuracy: 0.5508 - val_loss: 1.6911 - val_accuracy: 0.4688\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.3271 - accuracy: 0.4986 - val_loss: 1.7525 - val_accuracy: 0.3750\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.2210 - accuracy: 0.5633 - val_loss: 1.6892 - val_accuracy: 0.2812\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.3948 - accuracy: 0.4751 - val_loss: 1.9789 - val_accuracy: 0.4375\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.3690 - accuracy: 0.5041 - val_loss: 2.0063 - val_accuracy: 0.4062\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 1.3163 - accuracy: 0.4941 - val_loss: 1.9711 - val_accuracy: 0.3438\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.2546 - accuracy: 0.5595 - val_loss: 2.0859 - val_accuracy: 0.3438\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.3281 - accuracy: 0.5100 - val_loss: 1.9585 - val_accuracy: 0.4062\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.3380 - accuracy: 0.5106 - val_loss: 1.8744 - val_accuracy: 0.3438\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.1739 - accuracy: 0.5644 - val_loss: 1.9145 - val_accuracy: 0.3750\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.2023 - accuracy: 0.6164 - val_loss: 1.7845 - val_accuracy: 0.4375\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.2480 - accuracy: 0.5854 - val_loss: 1.6518 - val_accuracy: 0.5625\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 1.2937 - accuracy: 0.5038 - val_loss: 1.8166 - val_accuracy: 0.3750\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.1573 - accuracy: 0.6442 - val_loss: 1.5654 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.2987 - accuracy: 0.5959 - val_loss: 1.9602 - val_accuracy: 0.4375\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.1346 - accuracy: 0.6503 - val_loss: 1.6913 - val_accuracy: 0.4375\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.2338 - accuracy: 0.5481 - val_loss: 1.7253 - val_accuracy: 0.4375\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.2766 - accuracy: 0.5193 - val_loss: 2.0492 - val_accuracy: 0.2812\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 1.2418 - accuracy: 0.5342 - val_loss: 1.7876 - val_accuracy: 0.4062\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.2399 - accuracy: 0.5422 - val_loss: 1.8304 - val_accuracy: 0.3438\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 1.0255 - accuracy: 0.6437 - val_loss: 2.0005 - val_accuracy: 0.3125\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.3547 - accuracy: 0.5674 - val_loss: 1.9582 - val_accuracy: 0.3438\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.1731 - accuracy: 0.5979 - val_loss: 2.0178 - val_accuracy: 0.4062\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.1273 - accuracy: 0.5559 - val_loss: 2.0349 - val_accuracy: 0.2812\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.0729 - accuracy: 0.6191 - val_loss: 1.9621 - val_accuracy: 0.3750\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.1481 - accuracy: 0.5995 - val_loss: 1.8309 - val_accuracy: 0.3750\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.2001 - accuracy: 0.5537 - val_loss: 2.1563 - val_accuracy: 0.3750\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.9696 - accuracy: 0.6492 - val_loss: 1.9476 - val_accuracy: 0.3125\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.1060 - accuracy: 0.6079 - val_loss: 1.9814 - val_accuracy: 0.3438\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.1801 - accuracy: 0.5595 - val_loss: 2.0065 - val_accuracy: 0.4062\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.1115 - accuracy: 0.5799 - val_loss: 1.9645 - val_accuracy: 0.4062\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.1248 - accuracy: 0.5746 - val_loss: 1.8545 - val_accuracy: 0.4062\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.1755 - accuracy: 0.6345 - val_loss: 1.8283 - val_accuracy: 0.4688\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.9404 - accuracy: 0.6641 - val_loss: 1.9647 - val_accuracy: 0.4062\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.0532 - accuracy: 0.6313 - val_loss: 1.6160 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.1501 - accuracy: 0.5397 - val_loss: 2.0097 - val_accuracy: 0.3750\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 1.1622 - accuracy: 0.5905 - val_loss: 1.6020 - val_accuracy: 0.4062\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.0806 - accuracy: 0.6010 - val_loss: 1.7745 - val_accuracy: 0.4375\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.0063 - accuracy: 0.6760 - val_loss: 1.7691 - val_accuracy: 0.4062\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.1460 - accuracy: 0.5832 - val_loss: 1.7748 - val_accuracy: 0.3750\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.0571 - accuracy: 0.6292 - val_loss: 1.8401 - val_accuracy: 0.3750\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.0146 - accuracy: 0.6504 - val_loss: 1.6014 - val_accuracy: 0.5625\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.0733 - accuracy: 0.6838 - val_loss: 1.8847 - val_accuracy: 0.4062\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.9628 - accuracy: 0.6682 - val_loss: 1.5531 - val_accuracy: 0.5312\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.0258 - accuracy: 0.6427 - val_loss: 1.6726 - val_accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.0159 - accuracy: 0.6568 - val_loss: 1.6747 - val_accuracy: 0.4688\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.1378 - accuracy: 0.6140 - val_loss: 1.8196 - val_accuracy: 0.4062\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 1.0844 - accuracy: 0.6540 - val_loss: 1.8157 - val_accuracy: 0.3750\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 1.0344 - accuracy: 0.6599 - val_loss: 2.0489 - val_accuracy: 0.4062\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 1.2544 - accuracy: 0.5717 - val_loss: 1.9093 - val_accuracy: 0.3750\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 1.1019 - accuracy: 0.6005 - val_loss: 1.8737 - val_accuracy: 0.4375\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 1.0371 - accuracy: 0.6523 - val_loss: 1.8683 - val_accuracy: 0.3750\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.9600 - accuracy: 0.6996 - val_loss: 2.0592 - val_accuracy: 0.4375\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1784f61588>"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVlRXzU2jPUS"
      },
      "source": [
        "**Check the Training Procedure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9TqBr3k6aOC",
        "outputId": "293d9162-bf00-4ab4-d151-3d9c04243ea8"
      },
      "source": [
        "!cat MSR_msr.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch,accuracy,loss,val_accuracy,val_loss\r\n",
            "0,0.109375,2.7331318855285645,0.09375,2.625044345855713\r\n",
            "1,0.13671875,2.5888350009918213,0.21875,2.328624725341797\r\n",
            "2,0.16015625,2.460993528366089,0.15625,2.413884162902832\r\n",
            "3,0.22265625,2.3397932052612305,0.28125,2.256467342376709\r\n",
            "4,0.2109375,2.3709373474121094,0.09375,2.6772618293762207\r\n",
            "5,0.20703125,2.2181200981140137,0.28125,2.138782262802124\r\n",
            "6,0.23046875,2.1651408672332764,0.15625,2.1856629848480225\r\n",
            "7,0.25390625,2.045325994491577,0.28125,2.119523048400879\r\n",
            "8,0.2578125,2.1448357105255127,0.125,2.6467413902282715\r\n",
            "9,0.2578125,2.183107852935791,0.28125,2.007443428039551\r\n",
            "10,0.2578125,1.9957664012908936,0.3125,1.9742414951324463\r\n",
            "11,0.3125,1.9473087787628174,0.25,2.1622121334075928\r\n",
            "12,0.3046875,2.0909368991851807,0.21875,2.069599151611328\r\n",
            "13,0.25390625,2.059213638305664,0.25,2.154174327850342\r\n",
            "14,0.2890625,1.9441293478012085,0.40625,1.8930060863494873\r\n",
            "15,0.31640625,1.944522500038147,0.3125,1.930655837059021\r\n",
            "16,0.3359375,1.9441438913345337,0.21875,2.3046016693115234\r\n",
            "17,0.34765625,1.8547921180725098,0.3125,1.8923404216766357\r\n",
            "18,0.30078125,1.9926915168762207,0.3125,2.1125049591064453\r\n",
            "19,0.296875,1.8958438634872437,0.40625,1.9024591445922852\r\n",
            "20,0.31640625,1.882568120956421,0.3125,1.95003080368042\r\n",
            "21,0.30078125,1.8938844203948975,0.28125,1.9850764274597168\r\n",
            "22,0.3359375,1.8104891777038574,0.3125,1.9220479726791382\r\n",
            "23,0.328125,1.8519374132156372,0.40625,1.8161921501159668\r\n",
            "24,0.359375,1.758953332901001,0.25,2.04001522064209\r\n",
            "25,0.35546875,1.8707021474838257,0.34375,2.0727522373199463\r\n",
            "26,0.38671875,1.7965855598449707,0.21875,2.319106101989746\r\n",
            "27,0.34765625,1.7956148386001587,0.28125,1.9772372245788574\r\n",
            "28,0.36328125,1.739715337753296,0.375,1.909505844116211\r\n",
            "29,0.38671875,1.7057585716247559,0.375,1.9927526712417603\r\n",
            "30,0.40234375,1.6828166246414185,0.25,1.8574168682098389\r\n",
            "31,0.3984375,1.627139925956726,0.28125,2.081937313079834\r\n",
            "32,0.40234375,1.6248854398727417,0.34375,1.7847416400909424\r\n",
            "33,0.4375,1.5194783210754395,0.3125,2.0810353755950928\r\n",
            "34,0.43359375,1.5991675853729248,0.375,1.8395870923995972\r\n",
            "35,0.42578125,1.5247230529785156,0.4375,1.7110182046890259\r\n",
            "36,0.453125,1.5140029191970825,0.3125,2.0193676948547363\r\n",
            "37,0.4453125,1.4885996580123901,0.3125,2.1196279525756836\r\n",
            "38,0.47265625,1.4816484451293945,0.375,1.8462934494018555\r\n",
            "39,0.44921875,1.531144380569458,0.28125,1.8581750392913818\r\n",
            "40,0.44140625,1.4870569705963135,0.46875,1.6666399240493774\r\n",
            "41,0.4140625,1.622315526008606,0.28125,1.8041722774505615\r\n",
            "42,0.45703125,1.5225404500961304,0.3125,2.0114009380340576\r\n",
            "43,0.41015625,1.4888627529144287,0.34375,1.9224624633789062\r\n",
            "44,0.46875,1.4662867784500122,0.375,2.0606179237365723\r\n",
            "45,0.4765625,1.4008843898773193,0.34375,1.9285249710083008\r\n",
            "46,0.4765625,1.4465062618255615,0.34375,1.9545562267303467\r\n",
            "47,0.5,1.4142454862594604,0.46875,1.691098690032959\r\n",
            "48,0.49609375,1.369735836982727,0.375,1.7525060176849365\r\n",
            "49,0.5234375,1.349623441696167,0.28125,1.689232587814331\r\n",
            "50,0.49609375,1.3750382661819458,0.4375,1.978851079940796\r\n",
            "51,0.51171875,1.401829481124878,0.40625,2.006338119506836\r\n",
            "52,0.50390625,1.3376902341842651,0.34375,1.9711058139801025\r\n",
            "53,0.515625,1.3420491218566895,0.34375,2.085928440093994\r\n",
            "54,0.4921875,1.4466520547866821,0.40625,1.9584602117538452\r\n",
            "55,0.52734375,1.3076317310333252,0.34375,1.874356985092163\r\n",
            "56,0.5390625,1.2997524738311768,0.375,1.9145227670669556\r\n",
            "57,0.5390625,1.3328300714492798,0.4375,1.7844862937927246\r\n",
            "58,0.51953125,1.3639920949935913,0.5625,1.6517692804336548\r\n",
            "59,0.53515625,1.30527925491333,0.375,1.816575527191162\r\n",
            "60,0.59765625,1.2643628120422363,0.5,1.565434455871582\r\n",
            "61,0.5390625,1.3218815326690674,0.4375,1.9601986408233643\r\n",
            "62,0.58984375,1.250941276550293,0.4375,1.6913306713104248\r\n",
            "63,0.5625,1.2507318258285522,0.4375,1.725301742553711\r\n",
            "64,0.54296875,1.3068400621414185,0.28125,2.0491652488708496\r\n",
            "65,0.546875,1.2138818502426147,0.40625,1.7875871658325195\r\n",
            "66,0.55859375,1.1966952085494995,0.34375,1.830381989479065\r\n",
            "67,0.58203125,1.1581108570098877,0.3125,2.000455141067505\r\n",
            "68,0.56640625,1.3409593105316162,0.34375,1.958160161972046\r\n",
            "69,0.58984375,1.199708342552185,0.40625,2.01784610748291\r\n",
            "70,0.53515625,1.2179083824157715,0.28125,2.0349063873291016\r\n",
            "71,0.57421875,1.201724886894226,0.375,1.9621310234069824\r\n",
            "72,0.61328125,1.1663626432418823,0.375,1.830873727798462\r\n",
            "73,0.5390625,1.235388159751892,0.375,2.156318426132202\r\n",
            "74,0.578125,1.0992379188537598,0.3125,1.9475793838500977\r\n",
            "75,0.59765625,1.1727830171585083,0.34375,1.981377124786377\r\n",
            "76,0.56640625,1.1674094200134277,0.40625,2.006511688232422\r\n",
            "77,0.546875,1.2128570079803467,0.40625,1.9645135402679443\r\n",
            "78,0.58203125,1.1657342910766602,0.40625,1.854461908340454\r\n",
            "79,0.6015625,1.1763328313827515,0.46875,1.8282986879348755\r\n",
            "80,0.62890625,1.007209062576294,0.40625,1.964653730392456\r\n",
            "81,0.59375,1.1463513374328613,0.5,1.6160449981689453\r\n",
            "82,0.54296875,1.1454535722732544,0.375,2.0096654891967773\r\n",
            "83,0.578125,1.194399118423462,0.40625,1.601973295211792\r\n",
            "84,0.60546875,1.089926838874817,0.4375,1.7745383977890015\r\n",
            "85,0.64453125,1.0390114784240723,0.40625,1.7691164016723633\r\n",
            "86,0.5546875,1.2256377935409546,0.375,1.774810552597046\r\n",
            "87,0.62890625,1.0760504007339478,0.375,1.8401199579238892\r\n",
            "88,0.60546875,1.1290347576141357,0.5625,1.6014330387115479\r\n",
            "89,0.6484375,1.136050820350647,0.40625,1.8846802711486816\r\n",
            "90,0.61328125,1.0704777240753174,0.53125,1.5531394481658936\r\n",
            "91,0.6171875,1.102197289466858,0.5,1.6726243495941162\r\n",
            "92,0.6328125,1.0659523010253906,0.46875,1.6746597290039062\r\n",
            "93,0.578125,1.1592917442321777,0.40625,1.8196040391921997\r\n",
            "94,0.62890625,1.1075822114944458,0.375,1.8157075643539429\r\n",
            "95,0.59765625,1.1446797847747803,0.40625,2.0489187240600586\r\n",
            "96,0.5625,1.238481879234314,0.375,1.9092787504196167\r\n",
            "97,0.59765625,1.0766668319702148,0.4375,1.8737473487854004\r\n",
            "98,0.62109375,1.0473241806030273,0.375,1.8682520389556885\r\n",
            "99,0.67578125,0.9787576198577881,0.4375,2.0592331886291504\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npumlm1HiU3S"
      },
      "source": [
        "batch_size=1\n",
        "test_generator = DataGenerator('./test.txt', batch_size = batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBJED60tsviX"
      },
      "source": [
        "**Test the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV2bKcx5n8ue",
        "outputId": "c9f7f4d2-0e73-43c3-91f6-a8126f4b8296"
      },
      "source": [
        "print(model.evaluate_generator(generator = test_generator))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.436551570892334, 0.375]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ]
        }
      ]
    }
  ]
}