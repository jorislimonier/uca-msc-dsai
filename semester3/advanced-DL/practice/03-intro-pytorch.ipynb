{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qJ1q23I4GP9r"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# !pip install numpy\n",
        "# !pip install torch\n",
        "# !pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4_1MtQsGP9v"
      },
      "source": [
        "\n",
        "# Introduction to Deep Learning in Pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7N5PXdIGP9x"
      },
      "source": [
        "PyTorch provides the elegantly designed modules and classes [torch.nn](https://pytorch.org/docs/stable/nn.html) ,\n",
        "[torch.optim](https://pytorch.org/docs/stable/optim.html) ,\n",
        "[Dataset](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset) ,\n",
        "and [DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader)\n",
        "to help you create and train neural networks.\n",
        "\n",
        "In order to fully utilize their power and customize\n",
        "them for your problem, you need to really understand exactly what they're\n",
        "doing. To develop this understanding, we will first train basic neural net\n",
        "on the digits data set without using any features from these models; we will\n",
        "initially only use the most basic PyTorch tensor functionality. Then, we will\n",
        "incrementally add one feature from ``torch.nn``, ``torch.optim``, ``Dataset``, or\n",
        "``DataLoader`` at a time, showing exactly what each piece does, and how it\n",
        "works to make the code either more concise, or more flexible.\n",
        "\n",
        "**This tutorial assumes you already have PyTorch installed, and are familiar\n",
        "with the basics of tensor operations.** (If you're familiar with Numpy array\n",
        "operations, you'll find the PyTorch tensor operations used here nearly identical)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khe39_71P6re"
      },
      "source": [
        "## Digits Dataset setup\n",
        "\n",
        "We will use the classic [digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) dataset,\n",
        "a simplified version of the [mnist](http://deeplearning.net/data/mnist/) dataset provided by scikit-learn. \n",
        "which consists of black-and-white images of hand-drawn digits (between 0 and 9).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c7ROCF9P6rf",
        "outputId": "64d3515c-3ff1-49cc-84d5-d9a181f3da3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]] [0 1 2 ... 8 9 8]\n",
            "Number of samples: 1797, Number of features: 64\n",
            "Labels range 0 - 9, Number of classes: 10\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "import numpy as np\n",
        "\n",
        "x, y = load_digits(return_X_y=True)\n",
        "print(x, y)\n",
        "\n",
        "n_samples, n_features = x.shape\n",
        "n_classes = len(np.unique(y))\n",
        "\n",
        "print(f\"Number of samples: {n_samples}, Number of features: {n_features}\")\n",
        "print(f\"Labels range {y.min()} - {y.max()}, Number of classes: {n_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYkMJ-X5P6rf"
      },
      "source": [
        "Each image is 8 x 8, and is being stored as a flattened row of length 64. Let's take a look at one; we need to reshape it to 2d\n",
        "first.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "JGk24RTlP6rg",
        "outputId": "86bbdb11-5f3c-423e-c24c-d9f6992687c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1797, 64)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.imshow(x[3].reshape((8, 8)), cmap=\"gray\")\n",
        "print(x.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhz6-e30ZmmB"
      },
      "source": [
        "The input data is stored with values in $[0, 16]$. We need to normalize it in $[0, 1]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVtQymQLZmJY",
        "outputId": "3a7c672f-f3f4-46c6-8af6-30551a17d4f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.     0.     0.3125 ... 0.     0.     0.    ]\n",
            " [0.     0.     0.     ... 0.625  0.     0.    ]\n",
            " [0.     0.     0.     ... 1.     0.5625 0.    ]\n",
            " ...\n",
            " [0.     0.     0.0625 ... 0.375  0.     0.    ]\n",
            " [0.     0.     0.125  ... 0.75   0.     0.    ]\n",
            " [0.     0.     0.625  ... 0.75   0.0625 0.    ]]\n"
          ]
        }
      ],
      "source": [
        "def normalize(data):\n",
        "  data = data - data.min()\n",
        "  data = data / data.max()\n",
        "  return data\n",
        "\n",
        "\n",
        "x = normalize(x)\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpHEcVCkP6rf"
      },
      "source": [
        "We have to split the dataset into training and validation. To do so we can use one of the many functions provided by scikit-learn. For example we can call ``sklearn.model_selection.StratifiedKFold()`` to have a cross validation generator. \n",
        "\n",
        "For the sake of simplicity, however, in this tutorial we will use ``sklearn.model_selection.train_test_split`` which performs a simple holdout cross-validation to create a single train test split (with 90% - 10% of data in this case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jLZUs8MPP6rf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a4IWEyHP6rg"
      },
      "source": [
        "PyTorch uses ``torch.tensor``, rather than numpy arrays, so we need to\n",
        "convert our data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "DFue-AfvP6rg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "X_train = torch.as_tensor(X_train, dtype=torch.float32)\n",
        "X_val = torch.as_tensor(X_val, dtype=torch.float32)\n",
        "y_train = torch.as_tensor(y_train, dtype=torch.long)\n",
        "y_val = torch.as_tensor(y_val, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK3O1YQTGP92"
      },
      "source": [
        "## Neural networks from scratch (no torch.nn)\n",
        "\n",
        "Let's first create a model using nothing but PyTorch tensor operations. We assume you're already familiar with the basics of neural networks. \n",
        "\n",
        "PyTorch provides methods to create random or zero-filled tensors, which we will\n",
        "use to create our weights and bias for a simple linear model. These are just regular\n",
        "tensors, with one very special addition: we tell PyTorch that they require a\n",
        "**gradient**. This causes PyTorch to record all of the operations done on the tensor,\n",
        "so that it can calculate the gradient during back-propagation **automatically**!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnOoA2mycudn"
      },
      "source": [
        "### The Model\n",
        "\n",
        "We will use a very simple logistic regression with 10 output nodes (as many as the number of classes).\n",
        "\n",
        "For the weights, we set ``requires_grad`` after the initialization, since we\n",
        "don't want that step included in the gradient. \n",
        "\n",
        "#### To Note: \n",
        "1. We are initializing the weights here with the [Xavier initialisation](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf), by multiplying with 1/sqrt(n_features)).\n",
        "2. The trailing ``_`` in PyTorch signifies that the operation is performed in-place (``requires_grad_()``)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nso__EchGP92",
        "outputId": "c36bdf4f-28c8-4d66-b3cd-48a42d2fa9f7"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def initialize_weights_and_bias() -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
        "  weights = torch.randn(n_features, n_classes) / np.sqrt(n_features)\n",
        "  bias = torch.randn(n_classes) / np.sqrt(n_features)\n",
        "  weights.requires_grad_()\n",
        "  bias.requires_grad_()\n",
        "\n",
        "  return weights, bias\n",
        "\n",
        "\n",
        "weights, bias = initialize_weights_and_bias()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-568H7UXGP93"
      },
      "source": [
        "Thanks to PyTorch's ability to calculate gradients automatically, we can\n",
        "use any standard Python function (or callable object) as a model!\n",
        "\n",
        "Let's just write a plain matrix multiplication and broadcasted addition\n",
        "to create a simple linear model. We also need an activation function, so\n",
        "we'll write `log_softmax` and use it.\n",
        "\n",
        "Although PyTorch provides lots of pre-written loss functions, activation functions, and so forth, you can easily write your own using plain python. \n",
        "PyTorch will even create fast GPU or vectorized CPU code for your function\n",
        "**automatically**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zUvDrG0HGP93"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x: torch.FloatTensor):\n",
        "  return x - x.exp().sum(-1).log().unsqueeze(-1)  # => log(exp(x)/sum(exp(X_i)))\n",
        "\n",
        "\n",
        "def model(xb):\n",
        "  return log_softmax(xb @ weights + bias)  # a @ b -> torch.matmul(a, b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpSdCzfMGP93"
      },
      "source": [
        "In the above, the ``@`` stands for the *matrix multiplication* operation. We will call\n",
        "our function on one batch of data (in this case, 64 images).  This is\n",
        "one *forward pass*.  \n",
        "\n",
        "Note: our predictions won't be any better than\n",
        "random at this stage, since we start with random weights and we have not done any training step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY17VDFLGP94",
        "outputId": "60794f84-dc0e-45b9-867a-37a20bf0408f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.9821, -1.9767, -2.3197, -2.6570, -2.3440, -2.5760, -2.4005, -2.4403,\n",
            "        -2.2276, -2.3265], grad_fn=<SelectBackward0>)\n",
            "torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "bs = 64               # batch size\n",
        "xb = X_train[0:bs]    # a mini-batch from x\n",
        "preds = model(xb)     # predictions\n",
        "print(preds[0])\n",
        "print(preds.shape)\n",
        "# print(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmJJ7kPoGP94"
      },
      "source": [
        "As you see, the ``preds`` tensor contains not only the tensor values, but also a\n",
        "gradient function. We'll use this later to do the backpropagation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZuGvyy7c-7K"
      },
      "source": [
        "### Loss and Metric\n",
        "\n",
        "Let's implement negative log-likelihood to use as the loss function\n",
        "(again, we can just use standard Python). Note that the way in which we have implemented it is just a clever way of doing the selection of the prediction corresponding to the correct label as in: $\\sum_i y_i * log(f_i)$. You can find further information on how to compute the cross entropy loss in different scenarios in this [tutorial](https://towardsdatascience.com/cross-entropy-negative-log-likelihood-and-all-that-jazz-47a95bd2e81).\n",
        "\n",
        "\n",
        "If we check our loss with our random model now, we can see if we improve\n",
        "after a backprop pass later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVhzufT0GP94",
        "outputId": "080338d5-6f06-4308-da60-9d9b02045734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Loss: 2.2936666011810303\n"
          ]
        }
      ],
      "source": [
        "def nll(output, target):\n",
        "    \"\"\"Negative log-likelihood.\"\"\"\n",
        "    return -output[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll\n",
        "l = loss_func(model(X_train), y_train)\n",
        "print(f\"Initial Loss: {l}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfXzwWbCGP95"
      },
      "source": [
        "Let's also implement a function to calculate the accuracy of our model.\n",
        "For each prediction, if the index with the largest value matches the\n",
        "target value, then the prediction was correct.\n",
        "\n",
        "Let's check the accuracy of our random model, so we can see if our\n",
        "accuracy improves as our loss improves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1AVMzXCGP95",
        "outputId": "fcddfc9e-4142-4e6e-89e3-7456ae51ee26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Accuracy: 17.2542 %\n"
          ]
        }
      ],
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean() * 100\n",
        "\n",
        "acc = accuracy(model(X_train), y_train)\n",
        "print(f\"Initial Accuracy: {acc:.4f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOkrEDv2GP95"
      },
      "source": [
        "### The training loop\n",
        "\n",
        "We can now run a training loop.  For each iteration, we will:\n",
        "\n",
        "1. select a mini-batch of data (of size ``bs``)\n",
        "2. use the model to make predictions\n",
        "3. calculate the loss\n",
        "4. ``loss.backward()`` computes the gradients of the model, in this case, ``weights`` and ``bias``.\n",
        "5. update the parameters to optimize the model\n",
        "\n",
        "Note:\n",
        "\n",
        "- We do the latter within the ``torch.no_grad()`` context manager, because we do not want these\n",
        "actions to be recorded for our next calculation of the gradient.  You can read\n",
        "more about how PyTorch's Autograd records operations\n",
        "[here](https://pytorch.org/docs/stable/notes/autograd.html).\n",
        "- We then set the gradients to zero, so that we are ready for the next loop.\n",
        "Otherwise, our gradients would record a running tally of all the operations\n",
        "that had happened (i.e. ``loss.backward()`` *adds* the gradients to whatever is\n",
        "already stored, rather than replacing them).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights_initial = weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gRahb4YGP96",
        "outputId": "f1a8068a-cd89-4ea0-e6c8-dda4e07932db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "hovertemplate": "variable=loss<br>index=%{x}<br>value=%{y}<extra></extra>",
                  "legendgroup": "loss",
                  "line": {
                    "color": "#636efa",
                    "dash": "solid"
                  },
                  "marker": {
                    "symbol": "circle"
                  },
                  "mode": "lines",
                  "name": "loss",
                  "orientation": "v",
                  "showlegend": true,
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19
                  ],
                  "xaxis": "x",
                  "y": [
                    0.9976825714111328,
                    0.6325810551643372,
                    0.4849233627319336,
                    0.40526509284973145,
                    0.354847252368927,
                    0.3196455240249634,
                    0.29341480135917664,
                    0.2729529142379761,
                    0.2564423680305481,
                    0.24277004599571228,
                    0.23121336102485657,
                    0.2212809920310974,
                    0.2126263678073883,
                    0.204997256398201,
                    0.19820545613765717,
                    0.1921074390411377,
                    0.18659158051013947,
                    0.18156976997852325,
                    0.17697130143642426,
                    0.17273885011672974
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "legend": {
                  "title": {
                    "text": "variable"
                  },
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "index"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "value"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "lr = 0.5  # learning rate\n",
        "epochs = 20  # how many epochs to train for\n",
        "train_samples = X_train.shape[0]\n",
        "weights, bias = initialize_weights_and_bias()\n",
        "\n",
        "loss_res_store = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((train_samples - 1) // bs + 1):\n",
        "\n",
        "    # Get start and end indices\n",
        "    i_start = bs * i\n",
        "    i_end = bs * (i + 1)\n",
        "\n",
        "    X_curr = X_train[i_start:i_end]\n",
        "    y_curr = y_train[i_start:i_end]\n",
        "\n",
        "    y_pred_curr = model(X_curr)\n",
        "    loss = loss_func(y_pred_curr, y_curr)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      weights -= lr * weights.grad\n",
        "      bias -= lr * bias.grad\n",
        "\n",
        "      weights.grad.zero_()\n",
        "      bias.grad.zero_()\n",
        "\n",
        "  loss_res = loss_func(model(X_train), y_train)\n",
        "  loss_res_store.append(float(loss_res))\n",
        "\n",
        "  # print(f\"Epoch {epoch}: {loss_res}\")\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\"loss\": loss_res_store})\n",
        "px.line(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwJKP_LTGP96"
      },
      "source": [
        "That's it: we've created and trained a minimal neural network (in this case, a\n",
        "logistic regression, since we have no hidden layers) entirely from scratch!\n",
        "\n",
        "Let's check the loss and accuracy and compare those to what we got\n",
        "earlier. We expect that the loss will have decreased and accuracy to\n",
        "have increased, and they have. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ETCDTnIGP96",
        "outputId": "9751eb29-e1ab-4097-93e8-ae71131eb9ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss after training: 0.17273885011672974\n",
            "Accuracy after training: 96.90785217285156\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loss after training: {loss_func(model(X_train), y_train)}\")\n",
        "print(f\"Accuracy after training: {accuracy(model(X_train), y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obKr5LdyJ-X3",
        "outputId": "43c7a614-c429-4427-998b-fb132ef4cdc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1600, 1664, 1617)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i_start, i_end, train_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqOgP0Q6GP96"
      },
      "source": [
        "## Let's refactor our code using torch.nn\n",
        "\n",
        "We will now refactor our code, so that it does the same thing as before, only\n",
        "we'll start taking advantage of PyTorch's ``nn`` classes to make it more concise\n",
        "and flexible. At each step from here, we should be making our code one or more\n",
        "of: shorter, more understandable, and/or more flexible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMZrCmLHrULU"
      },
      "source": [
        "\n",
        "### Refactor using nn.functional\n",
        "The first and easiest step is to make our code shorter by replacing our\n",
        "hand-written activation and loss functions with those from ``torch.nn.functional``\n",
        "(which is generally imported into the namespace ``F`` by convention). This module\n",
        "contains all the functions in the ``torch.nn`` library (whereas other parts of the\n",
        "library contain classes). As well as a wide range of loss and activation\n",
        "functions, you'll also find here some convenient functions for creating deep neural\n",
        "networks, such as pooling functions. \n",
        "\n",
        "If you're using negative log likelihood loss and log softmax activation,\n",
        "then Pytorch provides a single function ``F.cross_entropy`` that combines\n",
        "the two. So we can even remove the activation function from our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Cnb9SnSVGP96"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "    return xb @ weights + bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFCQsLm8GP97"
      },
      "source": [
        "Note that we no longer call ``log_softmax`` in the ``model`` function. Let's\n",
        "confirm that our loss and accuracy are the same as before:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g22boR9RGP97",
        "outputId": "97c5322c-b95c-4c5a-f532-39a881a1bf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1727, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(X_train), y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ4oD7VZGP97"
      },
      "source": [
        "### Refactor using nn.Module\n",
        "Next up, we'll use ``nn.Module`` (*uppercase M*) and ``nn.Parameter``, for a clearer and more\n",
        "concise training loop. We subclass ``nn.Module`` (which itself is a class and\n",
        "able to keep track of its attributes).  In this case, we want to create a class that\n",
        "holds our weights, bias, and method for the forward step.  ``nn.Module`` has a\n",
        "number of attributes and methods (such as ``.parameters()`` and ``.zero_grad()``)\n",
        "which we will be using.\n",
        "\n",
        "Since we're now using an object instead of just using a function, we\n",
        "first have to instantiate our model:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "dGBBDsleGP97"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class DigitsLogistic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    init_weights = torch.randn(n_features, n_classes) / np.sqrt(n_features)\n",
        "    init_bias = torch.randn(n_classes) / np.sqrt(n_features)\n",
        "\n",
        "    self.weights = nn.Parameter(init_weights)\n",
        "    self.bias = nn.Parameter(init_bias)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    return xb @ self.weights + self.bias\n",
        "\n",
        "\n",
        "model = DigitsLogistic()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pnf7Nu4GP98"
      },
      "source": [
        "Now we can calculate the loss in the same way as before. Note that\n",
        "``nn.Module`` objects are used as if they are functions (i.e they are\n",
        "*callable*), but behind the scenes Pytorch will call our ``forward``\n",
        "method automatically, i.e.\n",
        "```\n",
        "  def __call__(self, *args, **kwargs):\n",
        "    return self.forward(args, kwargs)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjtCUYrvGP98",
        "outputId": "c429a924-6e35-48c2-ffe4-85366c6051de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4159, grad_fn=<NllLossBackward0>) tensor(14.7186)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(X_train), y_train), accuracy(model(X_train), y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFocHmEIGP98"
      },
      "source": [
        "#### model.parameters() and model.zero_grad()\n",
        "\n",
        "Previously for our training loop we had to update the values for each parameter\n",
        "by name, and manually zero out the grads for each parameter separately, like this:\n",
        "```\n",
        "  with torch.no_grad():\n",
        "      weights -= weights.grad * lr\n",
        "      bias -= bias.grad * lr\n",
        "      weights.grad.zero_()\n",
        "      bias.grad.zero_()\n",
        "```\n",
        "\n",
        "Now we can take advantage of model.parameters() and model.zero_grad() to make those steps more concise\n",
        "and less prone to the error of forgetting some of our parameters, particularly\n",
        "if we had a more complicated model:\n",
        "```\n",
        "  with torch.no_grad():\n",
        "      for p in model.parameters(): \n",
        "          p -= p.grad * lr\n",
        "      model.zero_grad()\n",
        "```\n",
        "\n",
        "We'll wrap our little training loop in a ``fit`` function so we can run it\n",
        "again later. And we double-check that our loss has gone down:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.1875, 0.7500,  ..., 1.0000, 1.0000, 0.1875],\n",
              "        [0.0000, 0.0000, 0.5625,  ..., 0.5000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0625, 0.7500,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.8125, 0.0625, 0.0000]],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\")\n",
        "X_train.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvkInV04GP98",
        "outputId": "b37e0559-2878-4310-826c-e222533fcb2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, 1.0037500858306885\n",
            "Epoch: 1, 0.6402100920677185\n",
            "Epoch: 2, 0.4916084110736847\n",
            "Epoch: 3, 0.4108574092388153\n",
            "Epoch: 4, 0.3595569431781769\n",
            "Epoch: 5, 0.3236690163612366\n",
            "Epoch: 6, 0.2968989610671997\n",
            "Epoch: 7, 0.2760049104690552\n",
            "Epoch: 8, 0.25914156436920166\n",
            "Epoch: 9, 0.24517661333084106\n",
            "Epoch: 10, 0.23337386548519135\n",
            "Epoch: 11, 0.22323216497898102\n",
            "Epoch: 12, 0.21439768373966217\n",
            "Epoch: 13, 0.2066127210855484\n",
            "Epoch: 14, 0.19968485832214355\n",
            "Epoch: 15, 0.19346727430820465\n",
            "Epoch: 16, 0.18784567713737488\n",
            "Epoch: 17, 0.18272985517978668\n",
            "Epoch: 18, 0.17804740369319916\n",
            "Epoch: 19, 0.17373961210250854\n",
            "Accuracy: 96.96969604492188\n"
          ]
        }
      ],
      "source": [
        "model = DigitsLogistic()\n",
        "\n",
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((train_samples - 1) // bs + 1):\n",
        "\n",
        "      # Get start and end indices\n",
        "      i_start = bs * i\n",
        "      i_end = bs * (i + 1)\n",
        "\n",
        "      X_curr = X_train[i_start:i_end]\n",
        "      y_curr = y_train[i_start:i_end]\n",
        "\n",
        "      y_pred_curr = model(X_curr)\n",
        "      loss = loss_func(y_pred_curr, y_curr)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= lr * p.grad\n",
        "        model.zero_grad()\n",
        "\n",
        "    print(f\"Epoch: {epoch}, {loss_func(model(X_train), y_train)}\")\n",
        "\n",
        "\n",
        "fit()\n",
        "print(f\"Accuracy: {accuracy(model(X_train), y_train)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzMBuDeFGP99"
      },
      "source": [
        "### Refactor using nn.Linear\n",
        "\n",
        "We continue to refactor our code.  Instead of manually defining and\n",
        "initializing ``self.weights`` and ``self.bias``, and calculating ``xb  @\n",
        "self.weights + self.bias``, we will instead use the Pytorch class\n",
        "[nn.Linear](https://pytorch.org/docs/stable/nn.html#linear-layers) for a\n",
        "linear layer, which does all that for us. Pytorch has many types of\n",
        "predefined layers that can greatly simplify our code, and often makes it\n",
        "faster too.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "FSnmEI1JGP99"
      },
      "outputs": [],
      "source": [
        "class DigitsLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(n_features, n_classes)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFS60dpFGP99"
      },
      "source": [
        "We instantiate our model and calculate the loss in the same way as before:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFW4bMSUGP99",
        "outputId": "b3aee3b5-7057-4871-a481-dac974a28978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.352463960647583, Accuracy: 9.894866943359375\n"
          ]
        }
      ],
      "source": [
        "model = DigitsLogistic()\n",
        "print(f\"Loss: {loss_func(model(X_train), y_train)}, Accuracy: {accuracy(model(X_train), y_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZJfkdWmGP9-"
      },
      "source": [
        "We are still able to use our same ``fit`` method as before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zau12rXJGP9-",
        "outputId": "17eef966-f63a-4eea-a58e-d1e20651f9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, 1.015250563621521\n",
            "Epoch: 1, 0.6464740037918091\n",
            "Epoch: 2, 0.49488410353660583\n",
            "Epoch: 3, 0.4127863347530365\n",
            "Epoch: 4, 0.3608166575431824\n",
            "Epoch: 5, 0.32455649971961975\n",
            "Epoch: 6, 0.29755905270576477\n",
            "Epoch: 7, 0.2765157222747803\n",
            "Epoch: 8, 0.25954899191856384\n",
            "Epoch: 9, 0.24550966918468475\n",
            "Epoch: 10, 0.23365166783332825\n",
            "Epoch: 11, 0.22346796095371246\n",
            "Epoch: 12, 0.21460078656673431\n",
            "Epoch: 13, 0.20678995549678802\n",
            "Epoch: 14, 0.1998412013053894\n",
            "Epoch: 15, 0.1936063915491104\n",
            "Epoch: 16, 0.18797050416469574\n",
            "Epoch: 17, 0.18284249305725098\n",
            "Epoch: 18, 0.1781495362520218\n",
            "Epoch: 19, 0.17383252084255219\n",
            "Loss: 0.17383252084255219, Accuracy: 96.84600830078125\n"
          ]
        }
      ],
      "source": [
        "fit()\n",
        "print(f\"Loss: {loss_func(model(X_train), y_train)}, Accuracy: {accuracy(model(X_train), y_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHBvm9BMGP9-"
      },
      "source": [
        "## Refactor using optim\n",
        "\n",
        "Pytorch also has a package with various optimization algorithms, ``torch.optim``.\n",
        "We can use the ``step`` method from our optimizer to take a forward step, instead\n",
        "of manually updating each parameter.\n",
        "\n",
        "This will let us replace our previous manually coded optimization step:\n",
        "```\n",
        "  with torch.no_grad():\n",
        "      for p in model.parameters(): \n",
        "          p -= p.grad * lr\n",
        "      model.zero_grad()\n",
        "```\n",
        "\n",
        "and instead use just:\n",
        "```\n",
        "# before the training loop\n",
        "opt = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# in the training loop\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```\n",
        "\n",
        "``optim.zero_grad()`` resets the gradient to 0 and we need to call it before\n",
        "computing the gradient for the next minibatch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4wtsLH1GP9-",
        "outputId": "49ed00f2-2891-4cf1-d711-be9dfd617b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.3472847938537598, Accuracy: 2.721088409423828\n",
            "Loss: 1.0039067268371582,  Accuracy: 82.62213897705078\n",
            "Loss: 0.638529896736145,  Accuracy: 89.36302185058594\n",
            "Loss: 0.4893985688686371,  Accuracy: 91.71304321289062\n",
            "Loss: 0.4087451100349426,  Accuracy: 92.7025375366211\n",
            "Loss: 0.3576916754245758,  Accuracy: 93.44464874267578\n",
            "Loss: 0.3220568597316742,  Accuracy: 93.93939208984375\n",
            "Loss: 0.29550960659980774,  Accuracy: 94.37229919433594\n",
            "Loss: 0.27480337023735046,  Accuracy: 94.61966705322266\n",
            "Loss: 0.25809645652770996,  Accuracy: 94.92887878417969\n",
            "Loss: 0.2442619800567627,  Accuracy: 95.23809814453125\n",
            "Loss: 0.23256851732730865,  Accuracy: 95.48546600341797\n",
            "Loss: 0.22251909971237183,  Accuracy: 95.79468536376953\n",
            "Loss: 0.213763028383255,  Accuracy: 95.98020935058594\n",
            "Loss: 0.20604512095451355,  Accuracy: 96.16574096679688\n",
            "Loss: 0.19917498528957367,  Accuracy: 96.2894287109375\n",
            "Loss: 0.19300724565982819,  Accuracy: 96.4749526977539\n",
            "Loss: 0.18742893636226654,  Accuracy: 96.59864044189453\n",
            "Loss: 0.18235087394714355,  Accuracy: 96.72232055664062\n",
            "Loss: 0.1777014434337616,  Accuracy: 96.72232055664062\n",
            "Loss: 0.17342254519462585,  Accuracy: 96.72232055664062\n"
          ]
        }
      ],
      "source": [
        "from torch import optim\n",
        "\n",
        "model = DigitsLogistic()\n",
        "print(\n",
        "  f\"Loss: {loss_func(model(X_train), y_train)},\",\n",
        "  f\"Accuracy: {accuracy(model(X_train), y_train)}\",\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((train_samples - 1) // bs + 1):\n",
        "\n",
        "    # Get start and end indices\n",
        "    i_start = bs * i\n",
        "    i_end = bs * (i + 1)\n",
        "\n",
        "    X_curr = X_train[i_start:i_end]\n",
        "    y_curr = y_train[i_start:i_end]\n",
        "\n",
        "    y_pred_curr = model(X_curr)\n",
        "    loss = loss_func(y_pred_curr, y_curr)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "  print(\n",
        "    f\"Loss: {loss_func(model(X_train), y_train)}, \",\n",
        "    f\"Accuracy: {accuracy(model(X_train), y_train)}\",\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "size = 400\n",
        "b = torch.ones(size, size)\n",
        "b = torch.ones(size, size).cuda()\n",
        "for _ in range(1000000):\n",
        "  b += b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAa3H3EkGP9_"
      },
      "source": [
        "## Refactor using Dataset\n",
        "\n",
        "PyTorch has an abstract Dataset class.  A Dataset can be anything that has:\n",
        "*   a ``__len__`` function (called by Python's standard ``len`` function)\n",
        "*   a ``__getitem__`` function as a way of indexing into it.\n",
        "\n",
        "There are many pre-existing datasets in the [torchvision](https://pytorch.org/vision/stable/datasets.html) library. Otherwise you can also create your own.\n",
        "[This tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)\n",
        "walks through a nice example of creating a custom ``FacialLandmarkDataset`` class\n",
        "as a subclass of ``Dataset``.\n",
        "\n",
        "PyTorch's [TensorDataset](https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#TensorDataset)\n",
        "is a Dataset wrapping tensors. By defining a length and way of indexing,\n",
        "this also gives us a way to iterate, index, and slice along the first\n",
        "dimension of a tensor.\n",
        "\n",
        "Both ``X_train`` and ``y_train`` can be combined in a single ``TensorDataset``,\n",
        "which will be easier to iterate over and slice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "a7jC6HSPGP9_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "train_ds = TensorDataset(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvKdmDrzGP9_"
      },
      "source": [
        "Previously, we had to iterate through minibatches of x and y values separately:\n",
        "```\n",
        "    xb = X_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "```\n",
        "\n",
        "Now, we can do these two steps together:\n",
        "```\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs] # we access all tensors in the dataset with one slicing\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh3uQWbgGP9_",
        "outputId": "7387cfd2-74b4-4958-9c71-fdbeb288c6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.6178284883499146, Accuracy: 88.31169128417969\n",
            "Loss: 0.1950487345457077, Accuracy: 94.80519104003906\n",
            "Loss: 0.13885028660297394, Accuracy: 95.79468536376953\n",
            "Loss: 0.1414077877998352, Accuracy: 95.54730987548828\n",
            "Loss: 0.10676081478595734, Accuracy: 97.21707153320312\n",
            "Loss: 0.10150665789842606, Accuracy: 96.53679656982422\n",
            "Loss: 0.09754589945077896, Accuracy: 97.03153991699219\n",
            "Loss: 0.09218311309814453, Accuracy: 97.0933837890625\n",
            "Loss: 0.10971467196941376, Accuracy: 96.2894287109375\n",
            "Loss: 0.2088923156261444, Accuracy: 93.69202423095703\n",
            "Loss: 0.07963976263999939, Accuracy: 97.58812713623047\n",
            "Loss: 0.10042999684810638, Accuracy: 97.15522766113281\n",
            "Loss: 0.05820527672767639, Accuracy: 97.40259552001953\n",
            "Loss: 0.09650305658578873, Accuracy: 97.40259552001953\n",
            "Loss: 0.09147771447896957, Accuracy: 96.96969604492188\n",
            "Loss: 0.06348846107721329, Accuracy: 97.83550262451172\n",
            "Loss: 0.04842009022831917, Accuracy: 98.5157699584961\n",
            "Loss: 0.042959947139024734, Accuracy: 98.76314544677734\n",
            "Loss: 0.0846385657787323, Accuracy: 97.8973388671875\n",
            "Loss: 0.030388379469513893, Accuracy: 99.01051330566406\n"
          ]
        }
      ],
      "source": [
        "model = DigitsLogistic()\n",
        "opt = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "opt = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((train_samples - 1) // bs + 1):\n",
        "\n",
        "    # Get start and end indices\n",
        "    i_start = bs * i\n",
        "    i_end = bs * (i + 1)\n",
        "\n",
        "    X_curr, y_curr = train_ds[i_start:i_end]\n",
        "\n",
        "    y_pred_curr = model(X_curr)\n",
        "    loss = loss_func(y_pred_curr, y_curr)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "  print(f\"Loss: {loss_func(model(X_train), y_train)}, Accuracy: {accuracy(model(X_train), y_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spVPEQSbGP9_"
      },
      "source": [
        "## Refactor using DataLoader\n",
        "\n",
        "Pytorch's ``DataLoader`` is responsible for managing batches. You can\n",
        "create a ``DataLoader`` from any ``Dataset``. ``DataLoader`` makes it easier\n",
        "to iterate over batches. Rather than having to use ``train_ds[i*bs : i*bs+bs]``,\n",
        "the DataLoader gives us each minibatch automatically.\n",
        "\n",
        "Also Shuffling the training data is\n",
        "[important](https://www.quora.com/Does-the-order-of-training-data-matter-when-training-neural-networks)\n",
        "to prevent correlation between batches and overfitting. DataLoader provides the parameter ``shuffle=True`` to do it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "dUKoDBjtGP-A"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = TensorDataset(X_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzWYd4sjGP-A"
      },
      "source": [
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "\n",
        "      for i in range((n-1)//bs + 1):\n",
        "          xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "          pred = model(xb)\n",
        "\n",
        "Now, our loop is much cleaner, as (xb, yb) are loaded automatically from the data loader:\n",
        "\n",
        "      for xb,yb in train_dl:\n",
        "          pred = model(xb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBvpcKS4GP-A",
        "outputId": "6ec4fa16-5ef5-47f0-e46a-25f62f89c5d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 3.0654661655426025, Accuracy: 54.730979919433594\n",
            "Loss: 3.7525501251220703, Accuracy: 39.20840835571289\n",
            "Loss: 2.4088025093078613, Accuracy: 55.28757095336914\n",
            "Loss: 2.286783218383789, Accuracy: 58.6270866394043\n",
            "Loss: 2.2476277351379395, Accuracy: 61.904762268066406\n",
            "Loss: 1.099810242652893, Accuracy: 74.14966583251953\n",
            "Loss: 0.8170061111450195, Accuracy: 78.78787994384766\n",
            "Loss: 1.591383457183838, Accuracy: 62.83240509033203\n",
            "Loss: 1.2384121417999268, Accuracy: 69.44960021972656\n",
            "Loss: 0.5009112358093262, Accuracy: 86.39456176757812\n",
            "Loss: 0.5471395254135132, Accuracy: 87.0748291015625\n",
            "Loss: 0.7944393157958984, Accuracy: 84.168212890625\n",
            "Loss: 0.8606475591659546, Accuracy: 83.54978942871094\n",
            "Loss: 0.8084270358085632, Accuracy: 83.79715728759766\n",
            "Loss: 0.7312576174736023, Accuracy: 84.60111236572266\n",
            "Loss: 0.5299633741378784, Accuracy: 87.26036071777344\n",
            "Loss: 0.38536572456359863, Accuracy: 90.10513305664062\n",
            "Loss: 0.35825225710868835, Accuracy: 90.97093200683594\n",
            "Loss: 0.3621997535228729, Accuracy: 90.78540802001953\n",
            "Loss: 0.3719482123851776, Accuracy: 90.04328918457031\n",
            "Loss: 0.39800265431404114, Accuracy: 90.10513305664062\n",
            "Loss: 0.3872557580471039, Accuracy: 90.90909576416016\n",
            "Loss: 0.353523313999176, Accuracy: 91.34198760986328\n",
            "Loss: 0.2873532474040985, Accuracy: 92.76437377929688\n",
            "Loss: 0.2357419729232788, Accuracy: 93.63018035888672\n",
            "Loss: 0.2080826610326767, Accuracy: 94.3104476928711\n",
            "Loss: 0.20223519206047058, Accuracy: 94.37229919433594\n",
            "Loss: 0.21771542727947235, Accuracy: 94.3104476928711\n",
            "Loss: 0.2211783528327942, Accuracy: 93.75386047363281\n",
            "Loss: 0.21819308400154114, Accuracy: 93.63018035888672\n",
            "Loss: 0.2134939581155777, Accuracy: 93.93939208984375\n",
            "Loss: 0.21605972945690155, Accuracy: 94.186767578125\n",
            "Loss: 0.213960200548172, Accuracy: 94.43413543701172\n",
            "Loss: 0.2053854763507843, Accuracy: 94.24861145019531\n",
            "Loss: 0.19738569855690002, Accuracy: 94.80519104003906\n",
            "Loss: 0.18831495940685272, Accuracy: 95.42362976074219\n",
            "Loss: 0.19095563888549805, Accuracy: 95.05256652832031\n",
            "Loss: 0.18019311130046844, Accuracy: 94.86703491210938\n",
            "Loss: 0.16930480301380157, Accuracy: 95.91836547851562\n",
            "Loss: 0.1700528860092163, Accuracy: 94.74335479736328\n",
            "Loss: 0.1990409791469574, Accuracy: 94.37229919433594\n",
            "Loss: 0.22228315472602844, Accuracy: 93.81570434570312\n",
            "Loss: 0.21220019459724426, Accuracy: 94.186767578125\n",
            "Loss: 0.16812804341316223, Accuracy: 94.99072265625\n",
            "Loss: 0.13046401739120483, Accuracy: 96.2894287109375\n",
            "Loss: 0.14621280133724213, Accuracy: 95.85652160644531\n",
            "Loss: 0.18593469262123108, Accuracy: 94.68151092529297\n",
            "Loss: 0.23051059246063232, Accuracy: 93.25911712646484\n",
            "Loss: 0.24889136850833893, Accuracy: 92.76437377929688\n",
            "Loss: 0.18157075345516205, Accuracy: 94.43413543701172\n",
            "Loss: 0.13382191956043243, Accuracy: 95.91836547851562\n",
            "Loss: 0.11928790807723999, Accuracy: 95.98020935058594\n",
            "Loss: 0.18480834364891052, Accuracy: 94.80519104003906\n",
            "Loss: 0.3094906806945801, Accuracy: 91.89857482910156\n",
            "Loss: 0.44514623284339905, Accuracy: 89.54854583740234\n",
            "Loss: 0.46848970651626587, Accuracy: 89.61038970947266\n",
            "Loss: 0.30129826068878174, Accuracy: 92.02226257324219\n",
            "Loss: 0.15094725787639618, Accuracy: 95.79468536376953\n",
            "Loss: 0.1779693365097046, Accuracy: 95.23809814453125\n",
            "Loss: 0.3049463927745819, Accuracy: 92.8880615234375\n",
            "Loss: 0.4058547616004944, Accuracy: 91.52751922607422\n",
            "Loss: 0.4586695432662964, Accuracy: 90.90909576416016\n",
            "Loss: 0.43083205819129944, Accuracy: 91.21830749511719\n",
            "Loss: 0.30989569425582886, Accuracy: 93.13543701171875\n",
            "Loss: 0.17338372766971588, Accuracy: 95.1762466430664\n",
            "Loss: 0.14870305359363556, Accuracy: 95.42362976074219\n",
            "Loss: 0.1917453408241272, Accuracy: 94.55782318115234\n",
            "Loss: 0.3224668502807617, Accuracy: 92.51700592041016\n",
            "Loss: 0.45144155621528625, Accuracy: 90.41434478759766\n",
            "Loss: 0.3953667879104614, Accuracy: 91.15646362304688\n",
            "Loss: 0.24319946765899658, Accuracy: 93.69202423095703\n",
            "Loss: 0.1440492868423462, Accuracy: 95.6709976196289\n",
            "Loss: 0.2245461493730545, Accuracy: 93.44464874267578\n",
            "Loss: 0.3429092466831207, Accuracy: 91.2801513671875\n",
            "Loss: 0.35453271865844727, Accuracy: 91.34198760986328\n",
            "Loss: 0.26447153091430664, Accuracy: 93.5064926147461\n",
            "Loss: 0.20250365138053894, Accuracy: 94.80519104003906\n",
            "Loss: 0.1984264999628067, Accuracy: 94.55782318115234\n",
            "Loss: 0.19785656034946442, Accuracy: 94.61966705322266\n",
            "Loss: 0.15835700929164886, Accuracy: 95.85652160644531\n",
            "Loss: 0.13783729076385498, Accuracy: 96.22757720947266\n",
            "Loss: 0.15757592022418976, Accuracy: 95.73284149169922\n",
            "Loss: 0.2187497615814209, Accuracy: 94.12492370605469\n",
            "Loss: 0.2981448173522949, Accuracy: 92.02226257324219\n",
            "Loss: 0.30045032501220703, Accuracy: 91.96041870117188\n",
            "Loss: 0.2283778339624405, Accuracy: 93.32096862792969\n",
            "Loss: 0.12916681170463562, Accuracy: 95.6091537475586\n",
            "Loss: 0.08794432878494263, Accuracy: 97.34075927734375\n",
            "Loss: 0.10872329026460648, Accuracy: 96.59864044189453\n",
            "Loss: 0.1451369673013687, Accuracy: 95.98020935058594\n",
            "Loss: 0.16424277424812317, Accuracy: 95.36177825927734\n",
            "Loss: 0.15309923887252808, Accuracy: 95.98020935058594\n",
            "Loss: 0.1244615837931633, Accuracy: 96.59864044189453\n",
            "Loss: 0.106565460562706, Accuracy: 97.0933837890625\n",
            "Loss: 0.10284508764743805, Accuracy: 97.21707153320312\n",
            "Loss: 0.09424605965614319, Accuracy: 97.34075927734375\n",
            "Loss: 0.09175985306501389, Accuracy: 97.21707153320312\n",
            "Loss: 0.0931912288069725, Accuracy: 97.58812713623047\n",
            "Loss: 0.10775835067033768, Accuracy: 97.03153991699219\n",
            "Loss: 0.11561577022075653, Accuracy: 96.78417205810547\n",
            "Loss: 0.12320690602064133, Accuracy: 96.53679656982422\n",
            "Loss: 0.12819531559944153, Accuracy: 95.98020935058594\n",
            "Loss: 0.13302278518676758, Accuracy: 96.2894287109375\n",
            "Loss: 0.14206142723560333, Accuracy: 96.2894287109375\n",
            "Loss: 0.12575237452983856, Accuracy: 96.53679656982422\n",
            "Loss: 0.12396223098039627, Accuracy: 96.78417205810547\n",
            "Loss: 0.11568307876586914, Accuracy: 96.90785217285156\n",
            "Loss: 0.11028244346380234, Accuracy: 97.0933837890625\n",
            "Loss: 0.10225851833820343, Accuracy: 97.03153991699219\n",
            "Loss: 0.09244897216558456, Accuracy: 97.21707153320312\n",
            "Loss: 0.07638343423604965, Accuracy: 97.83550262451172\n",
            "Loss: 0.07081659138202667, Accuracy: 97.8973388671875\n",
            "Loss: 0.07180365920066833, Accuracy: 97.7118148803711\n",
            "Loss: 0.07574507594108582, Accuracy: 97.7118148803711\n",
            "Loss: 0.07483557611703873, Accuracy: 97.83550262451172\n",
            "Loss: 0.08100374788045883, Accuracy: 97.58812713623047\n",
            "Loss: 0.08214548230171204, Accuracy: 97.34075927734375\n",
            "Loss: 0.08476089686155319, Accuracy: 97.46443939208984\n",
            "Loss: 0.08758063614368439, Accuracy: 97.46443939208984\n",
            "Loss: 0.07825509458780289, Accuracy: 97.64997100830078\n",
            "Loss: 0.06985586881637573, Accuracy: 98.02102661132812\n",
            "Loss: 0.06875970959663391, Accuracy: 97.83550262451172\n",
            "Loss: 0.06710691004991531, Accuracy: 98.02102661132812\n",
            "Loss: 0.06893642246723175, Accuracy: 98.02102661132812\n",
            "Loss: 0.06986676156520844, Accuracy: 97.83550262451172\n",
            "Loss: 0.07047989219427109, Accuracy: 97.95918273925781\n",
            "Loss: 0.06746489554643631, Accuracy: 97.7118148803711\n",
            "Loss: 0.060206227004528046, Accuracy: 98.14470672607422\n",
            "Loss: 0.062263280153274536, Accuracy: 98.08287048339844\n",
            "Loss: 0.06781177967786789, Accuracy: 97.77365112304688\n",
            "Loss: 0.07396005839109421, Accuracy: 97.64997100830078\n",
            "Loss: 0.07990007102489471, Accuracy: 97.2789077758789\n",
            "Loss: 0.0848127081990242, Accuracy: 97.0933837890625\n",
            "Loss: 0.09605526924133301, Accuracy: 96.53679656982422\n",
            "Loss: 0.09442301094532013, Accuracy: 96.72232055664062\n",
            "Loss: 0.07951095700263977, Accuracy: 97.21707153320312\n",
            "Loss: 0.06513261049985886, Accuracy: 98.14470672607422\n",
            "Loss: 0.059370316565036774, Accuracy: 98.14470672607422\n",
            "Loss: 0.06639689952135086, Accuracy: 97.95918273925781\n",
            "Loss: 0.08075358718633652, Accuracy: 97.21707153320312\n",
            "Loss: 0.07508827745914459, Accuracy: 97.52628326416016\n",
            "Loss: 0.06890984624624252, Accuracy: 97.7118148803711\n",
            "Loss: 0.06990733742713928, Accuracy: 97.77365112304688\n",
            "Loss: 0.07526446878910065, Accuracy: 97.58812713623047\n",
            "Loss: 0.09711731225252151, Accuracy: 96.78417205810547\n",
            "Loss: 0.1091332659125328, Accuracy: 96.4131088256836\n",
            "Loss: 0.1213318482041359, Accuracy: 96.16574096679688\n",
            "Loss: 0.12384005635976791, Accuracy: 95.98020935058594\n",
            "Loss: 0.09342656284570694, Accuracy: 97.21707153320312\n",
            "Loss: 0.091229148209095, Accuracy: 96.59864044189453\n",
            "Loss: 0.11567645519971848, Accuracy: 95.98020935058594\n",
            "Loss: 0.16217683255672455, Accuracy: 95.11441040039062\n",
            "Loss: 0.1731993556022644, Accuracy: 94.24861145019531\n",
            "Loss: 0.10435692220926285, Accuracy: 96.4131088256836\n",
            "Loss: 0.06451945751905441, Accuracy: 97.7118148803711\n",
            "Loss: 0.11430956423282623, Accuracy: 95.91836547851562\n",
            "Loss: 0.23251676559448242, Accuracy: 93.38280487060547\n",
            "Loss: 0.27471572160720825, Accuracy: 93.01174926757812\n",
            "Loss: 0.2350112646818161, Accuracy: 93.87755584716797\n",
            "Loss: 0.19406941533088684, Accuracy: 95.05256652832031\n",
            "Loss: 0.11081048101186752, Accuracy: 96.53679656982422\n",
            "Loss: 0.06367170810699463, Accuracy: 98.02102661132812\n",
            "Loss: 0.060742225497961044, Accuracy: 98.08287048339844\n",
            "Loss: 0.08120223879814148, Accuracy: 97.21707153320312\n",
            "Loss: 0.07833560556173325, Accuracy: 97.34075927734375\n",
            "Loss: 0.09735766798257828, Accuracy: 96.90785217285156\n",
            "Loss: 0.07714090496301651, Accuracy: 97.2789077758789\n",
            "Loss: 0.0841766968369484, Accuracy: 97.40259552001953\n",
            "Loss: 0.10023651272058487, Accuracy: 96.72232055664062\n",
            "Loss: 0.12193369120359421, Accuracy: 96.04205322265625\n",
            "Loss: 0.10376645624637604, Accuracy: 96.59864044189453\n",
            "Loss: 0.08402577042579651, Accuracy: 97.34075927734375\n",
            "Loss: 0.07604756206274033, Accuracy: 97.34075927734375\n",
            "Loss: 0.089124895632267, Accuracy: 97.34075927734375\n",
            "Loss: 0.0877373218536377, Accuracy: 97.21707153320312\n",
            "Loss: 0.09738481044769287, Accuracy: 96.66048431396484\n",
            "Loss: 0.08778799325227737, Accuracy: 97.2789077758789\n",
            "Loss: 0.08868327736854553, Accuracy: 97.34075927734375\n",
            "Loss: 0.11927685886621475, Accuracy: 96.22757720947266\n",
            "Loss: 0.1412556916475296, Accuracy: 94.80519104003906\n",
            "Loss: 0.1764630526304245, Accuracy: 94.24861145019531\n",
            "Loss: 0.10814668983221054, Accuracy: 96.22757720947266\n",
            "Loss: 0.06975171715021133, Accuracy: 97.83550262451172\n",
            "Loss: 0.07494312524795532, Accuracy: 97.83550262451172\n",
            "Loss: 0.10637637972831726, Accuracy: 97.03153991699219\n",
            "Loss: 0.14234891533851624, Accuracy: 96.10389709472656\n",
            "Loss: 0.11528676003217697, Accuracy: 96.35126495361328\n",
            "Loss: 0.0895637720823288, Accuracy: 96.84600830078125\n",
            "Loss: 0.06557575613260269, Accuracy: 97.83550262451172\n",
            "Loss: 0.06866256147623062, Accuracy: 97.77365112304688\n",
            "Loss: 0.09341485053300858, Accuracy: 96.35126495361328\n",
            "Loss: 0.13474807143211365, Accuracy: 94.92887878417969\n",
            "Loss: 0.19800414144992828, Accuracy: 93.93939208984375\n",
            "Loss: 0.23309235274791718, Accuracy: 92.82622528076172\n",
            "Loss: 0.10225970298051834, Accuracy: 96.84600830078125\n",
            "Loss: 0.06850723177194595, Accuracy: 97.8973388671875\n",
            "Loss: 0.09602612257003784, Accuracy: 96.96969604492188\n",
            "Loss: 0.13522502779960632, Accuracy: 95.79468536376953\n",
            "Loss: 0.18254806101322174, Accuracy: 94.3104476928711\n",
            "Loss: 0.15194176137447357, Accuracy: 95.48546600341797\n",
            "Loss: 0.05146421119570732, Accuracy: 97.8973388671875\n",
            "Loss: 0.03455989807844162, Accuracy: 98.76314544677734\n",
            "Loss: 0.05006150156259537, Accuracy: 98.33023834228516\n",
            "Loss: 0.07456215471029282, Accuracy: 97.40259552001953\n",
            "Loss: 0.08960496634244919, Accuracy: 97.03153991699219\n",
            "Loss: 0.09077198803424835, Accuracy: 97.46443939208984\n",
            "Loss: 0.09878323972225189, Accuracy: 97.0933837890625\n",
            "Loss: 0.09171079844236374, Accuracy: 97.58812713623047\n",
            "Loss: 0.09134549647569656, Accuracy: 97.2789077758789\n",
            "Loss: 0.11915353685617447, Accuracy: 96.4131088256836\n",
            "Loss: 0.13511241972446442, Accuracy: 95.98020935058594\n",
            "Loss: 0.13476938009262085, Accuracy: 95.98020935058594\n",
            "Loss: 0.09952748566865921, Accuracy: 97.15522766113281\n",
            "Loss: 0.0757531151175499, Accuracy: 97.8973388671875\n",
            "Loss: 0.0628058910369873, Accuracy: 98.33023834228516\n",
            "Loss: 0.06342605501413345, Accuracy: 98.08287048339844\n",
            "Loss: 0.07218226045370102, Accuracy: 97.58812713623047\n",
            "Loss: 0.07748163491487503, Accuracy: 97.95918273925781\n",
            "Loss: 0.10097696632146835, Accuracy: 96.90785217285156\n",
            "Loss: 0.13498391211032867, Accuracy: 96.04205322265625\n",
            "Loss: 0.16046495735645294, Accuracy: 95.11441040039062\n",
            "Loss: 0.1135299801826477, Accuracy: 96.72232055664062\n",
            "Loss: 0.07019796222448349, Accuracy: 97.7118148803711\n",
            "Loss: 0.061802446842193604, Accuracy: 98.20655822753906\n",
            "Loss: 0.08436553180217743, Accuracy: 97.7118148803711\n",
            "Loss: 0.10548239201307297, Accuracy: 97.0933837890625\n",
            "Loss: 0.12149092555046082, Accuracy: 96.53679656982422\n",
            "Loss: 0.11573982983827591, Accuracy: 96.90785217285156\n",
            "Loss: 0.11443665623664856, Accuracy: 96.72232055664062\n",
            "Loss: 0.10843578726053238, Accuracy: 96.78417205810547\n",
            "Loss: 0.08005298674106598, Accuracy: 97.58812713623047\n",
            "Loss: 0.08027318865060806, Accuracy: 97.77365112304688\n",
            "Loss: 0.08386527746915817, Accuracy: 97.7118148803711\n",
            "Loss: 0.06930633634328842, Accuracy: 97.64997100830078\n",
            "Loss: 0.1053154468536377, Accuracy: 96.4749526977539\n",
            "Loss: 0.13125604391098022, Accuracy: 96.22757720947266\n",
            "Loss: 0.17027755081653595, Accuracy: 95.1762466430664\n",
            "Loss: 0.23364482820034027, Accuracy: 94.06307983398438\n",
            "Loss: 0.16969366371631622, Accuracy: 95.42362976074219\n",
            "Loss: 0.08594559878110886, Accuracy: 97.77365112304688\n",
            "Loss: 0.04740043357014656, Accuracy: 98.45392608642578\n",
            "Loss: 0.07434692978858948, Accuracy: 97.46443939208984\n",
            "Loss: 0.16032929718494415, Accuracy: 95.11441040039062\n",
            "Loss: 0.22818784415721893, Accuracy: 93.75386047363281\n",
            "Loss: 0.17700889706611633, Accuracy: 94.92887878417969\n",
            "Loss: 0.10821688920259476, Accuracy: 96.96969604492188\n",
            "Loss: 0.06606047600507736, Accuracy: 97.95918273925781\n",
            "Loss: 0.060249313712120056, Accuracy: 98.26839447021484\n",
            "Loss: 0.0715508759021759, Accuracy: 97.95918273925781\n",
            "Loss: 0.09756458550691605, Accuracy: 97.46443939208984\n",
            "Loss: 0.11850089579820633, Accuracy: 97.03153991699219\n",
            "Loss: 0.15055221319198608, Accuracy: 95.85652160644531\n",
            "Loss: 0.20670735836029053, Accuracy: 94.49597930908203\n",
            "Loss: 0.18754814565181732, Accuracy: 94.92887878417969\n",
            "Loss: 0.12832722067832947, Accuracy: 96.72232055664062\n",
            "Loss: 0.08640865981578827, Accuracy: 97.64997100830078\n",
            "Loss: 0.075376495718956, Accuracy: 97.64997100830078\n",
            "Loss: 0.10895771533250809, Accuracy: 97.03153991699219\n",
            "Loss: 0.14923907816410065, Accuracy: 96.10389709472656\n",
            "Loss: 0.11672452837228775, Accuracy: 96.35126495361328\n",
            "Loss: 0.09668734669685364, Accuracy: 97.21707153320312\n",
            "Loss: 0.11852701008319855, Accuracy: 96.66048431396484\n",
            "Loss: 0.1630864143371582, Accuracy: 95.98020935058594\n",
            "Loss: 0.19217373430728912, Accuracy: 95.23809814453125\n",
            "Loss: 0.1723574697971344, Accuracy: 95.79468536376953\n",
            "Loss: 0.16092607378959656, Accuracy: 96.4131088256836\n",
            "Loss: 0.1420302838087082, Accuracy: 96.59864044189453\n",
            "Loss: 0.09186983108520508, Accuracy: 97.52628326416016\n",
            "Loss: 0.07875331491231918, Accuracy: 97.64997100830078\n",
            "Loss: 0.1061786562204361, Accuracy: 96.78417205810547\n",
            "Loss: 0.15636558830738068, Accuracy: 95.6091537475586\n",
            "Loss: 0.199967622756958, Accuracy: 95.23809814453125\n",
            "Loss: 0.20386594533920288, Accuracy: 94.86703491210938\n",
            "Loss: 0.13652555644512177, Accuracy: 96.4749526977539\n",
            "Loss: 0.07123836874961853, Accuracy: 97.83550262451172\n",
            "Loss: 0.05351061001420021, Accuracy: 98.70130157470703\n",
            "Loss: 0.05098956450819969, Accuracy: 98.45392608642578\n",
            "Loss: 0.061647169291973114, Accuracy: 97.95918273925781\n",
            "Loss: 0.0833161398768425, Accuracy: 97.52628326416016\n",
            "Loss: 0.08300711214542389, Accuracy: 97.40259552001953\n",
            "Loss: 0.0673605352640152, Accuracy: 98.08287048339844\n",
            "Loss: 0.05973511189222336, Accuracy: 97.95918273925781\n",
            "Loss: 0.05374269187450409, Accuracy: 98.33023834228516\n",
            "Loss: 0.05109085142612457, Accuracy: 98.08287048339844\n",
            "Loss: 0.04327680543065071, Accuracy: 98.08287048339844\n",
            "Loss: 0.04063127189874649, Accuracy: 98.20655822753906\n",
            "Loss: 0.04091223329305649, Accuracy: 98.39208221435547\n",
            "Loss: 0.04049944877624512, Accuracy: 98.5776138305664\n",
            "Loss: 0.039494115859270096, Accuracy: 98.5157699584961\n",
            "Loss: 0.03695531561970711, Accuracy: 98.76314544677734\n",
            "Loss: 0.03540462255477905, Accuracy: 98.82498168945312\n",
            "Loss: 0.03530627116560936, Accuracy: 99.07235717773438\n",
            "Loss: 0.04227680712938309, Accuracy: 98.76314544677734\n",
            "Loss: 0.046709708869457245, Accuracy: 98.76314544677734\n",
            "Loss: 0.04652634635567665, Accuracy: 98.5157699584961\n",
            "Loss: 0.048477016389369965, Accuracy: 98.76314544677734\n",
            "Loss: 0.05184544622898102, Accuracy: 98.70130157470703\n",
            "Loss: 0.05433916300535202, Accuracy: 98.63945770263672\n",
            "Loss: 0.048892609775066376, Accuracy: 98.63945770263672\n",
            "Loss: 0.04364229366183281, Accuracy: 98.76314544677734\n",
            "Loss: 0.038588374853134155, Accuracy: 98.76314544677734\n",
            "Loss: 0.03443746641278267, Accuracy: 99.07235717773438\n",
            "Loss: 0.033011294901371, Accuracy: 99.01051330566406\n",
            "Loss: 0.04066165164113045, Accuracy: 98.5776138305664\n",
            "Loss: 0.03960075601935387, Accuracy: 98.5776138305664\n",
            "Loss: 0.04472580552101135, Accuracy: 98.70130157470703\n",
            "Loss: 0.044295310974121094, Accuracy: 98.76314544677734\n",
            "Loss: 0.04076860472559929, Accuracy: 98.82498168945312\n",
            "Loss: 0.0356026217341423, Accuracy: 98.94866943359375\n",
            "Loss: 0.035994645208120346, Accuracy: 98.76314544677734\n",
            "Loss: 0.04123321920633316, Accuracy: 98.70130157470703\n",
            "Loss: 0.028298962861299515, Accuracy: 99.19603729248047\n",
            "Loss: 0.02714901603758335, Accuracy: 99.19603729248047\n",
            "Loss: 0.030690044164657593, Accuracy: 99.01051330566406\n",
            "Loss: 0.038912415504455566, Accuracy: 98.70130157470703\n",
            "Loss: 0.04256391525268555, Accuracy: 98.5776138305664\n",
            "Loss: 0.037737611681222916, Accuracy: 98.5776138305664\n",
            "Loss: 0.028160832822322845, Accuracy: 99.3197250366211\n",
            "Loss: 0.03750074282288551, Accuracy: 98.82498168945312\n",
            "Loss: 0.06592371314764023, Accuracy: 98.02102661132812\n",
            "Loss: 0.08703026175498962, Accuracy: 97.46443939208984\n",
            "Loss: 0.07033366709947586, Accuracy: 97.52628326416016\n",
            "Loss: 0.051132965832948685, Accuracy: 97.8973388671875\n",
            "Loss: 0.05589869245886803, Accuracy: 97.8973388671875\n",
            "Loss: 0.04285120964050293, Accuracy: 98.5776138305664\n",
            "Loss: 0.06923601776361465, Accuracy: 97.7118148803711\n",
            "Loss: 0.08686863631010056, Accuracy: 96.96969604492188\n",
            "Loss: 0.08617643266916275, Accuracy: 97.2789077758789\n",
            "Loss: 0.09631886333227158, Accuracy: 97.0933837890625\n",
            "Loss: 0.06887941807508469, Accuracy: 97.95918273925781\n",
            "Loss: 0.04319385811686516, Accuracy: 98.88683319091797\n",
            "Loss: 0.04085523635149002, Accuracy: 98.76314544677734\n",
            "Loss: 0.039634350687265396, Accuracy: 98.76314544677734\n",
            "Loss: 0.04270380362868309, Accuracy: 98.76314544677734\n",
            "Loss: 0.03574848920106888, Accuracy: 98.94866943359375\n",
            "Loss: 0.03555770590901375, Accuracy: 98.94866943359375\n",
            "Loss: 0.04120665788650513, Accuracy: 98.5157699584961\n",
            "Loss: 0.03443514183163643, Accuracy: 98.76314544677734\n",
            "Loss: 0.05197640880942345, Accuracy: 98.26839447021484\n",
            "Loss: 0.09657488763332367, Accuracy: 97.64997100830078\n",
            "Loss: 0.1671343594789505, Accuracy: 95.42362976074219\n",
            "Loss: 0.09678235650062561, Accuracy: 97.15522766113281\n",
            "Loss: 0.05774752423167229, Accuracy: 98.14470672607422\n",
            "Loss: 0.04653860256075859, Accuracy: 98.45392608642578\n",
            "Loss: 0.04703516140580177, Accuracy: 98.5157699584961\n",
            "Loss: 0.0470033660531044, Accuracy: 98.76314544677734\n",
            "Loss: 0.04925735667347908, Accuracy: 98.5776138305664\n",
            "Loss: 0.05206652358174324, Accuracy: 98.39208221435547\n",
            "Loss: 0.05126556009054184, Accuracy: 98.33023834228516\n",
            "Loss: 0.0527128167450428, Accuracy: 98.39208221435547\n",
            "Loss: 0.05583881586790085, Accuracy: 98.39208221435547\n",
            "Loss: 0.04678270220756531, Accuracy: 98.5157699584961\n",
            "Loss: 0.036968909204006195, Accuracy: 98.63945770263672\n",
            "Loss: 0.028099654242396355, Accuracy: 99.13420104980469\n",
            "Loss: 0.028361456468701363, Accuracy: 99.13420104980469\n",
            "Loss: 0.035824790596961975, Accuracy: 99.07235717773438\n",
            "Loss: 0.04166901111602783, Accuracy: 99.01051330566406\n",
            "Loss: 0.050761878490448, Accuracy: 98.76314544677734\n",
            "Loss: 0.05161106586456299, Accuracy: 98.5776138305664\n",
            "Loss: 0.043414611369371414, Accuracy: 98.88683319091797\n",
            "Loss: 0.04090414196252823, Accuracy: 98.70130157470703\n",
            "Loss: 0.033229660242795944, Accuracy: 98.63945770263672\n",
            "Loss: 0.024255886673927307, Accuracy: 99.3815689086914\n",
            "Loss: 0.04164838045835495, Accuracy: 98.08287048339844\n",
            "Loss: 0.08057037740945816, Accuracy: 97.15522766113281\n",
            "Loss: 0.14216472208499908, Accuracy: 95.6091537475586\n",
            "Loss: 0.161500945687294, Accuracy: 95.29993438720703\n",
            "Loss: 0.10800988972187042, Accuracy: 97.03153991699219\n",
            "Loss: 0.04289493337273598, Accuracy: 98.45392608642578\n",
            "Loss: 0.038269102573394775, Accuracy: 98.5776138305664\n",
            "Loss: 0.05665363743901253, Accuracy: 98.26839447021484\n",
            "Loss: 0.061463553458452225, Accuracy: 98.08287048339844\n",
            "Loss: 0.06848181039094925, Accuracy: 98.20655822753906\n",
            "Loss: 0.10206987708806992, Accuracy: 97.34075927734375\n",
            "Loss: 0.16303469240665436, Accuracy: 96.04205322265625\n",
            "Loss: 0.20635652542114258, Accuracy: 94.86703491210938\n",
            "Loss: 0.15527138113975525, Accuracy: 96.04205322265625\n",
            "Loss: 0.0907604843378067, Accuracy: 97.2789077758789\n",
            "Loss: 0.06753884255886078, Accuracy: 97.7118148803711\n",
            "Loss: 0.08484308421611786, Accuracy: 96.84600830078125\n",
            "Loss: 0.12860123813152313, Accuracy: 96.2894287109375\n",
            "Loss: 0.1700468212366104, Accuracy: 96.04205322265625\n",
            "Loss: 0.1525026261806488, Accuracy: 96.4749526977539\n",
            "Loss: 0.11117014288902283, Accuracy: 96.96969604492188\n",
            "Loss: 0.05401008203625679, Accuracy: 98.14470672607422\n",
            "Loss: 0.03904211148619652, Accuracy: 98.76314544677734\n",
            "Loss: 0.08010239899158478, Accuracy: 97.83550262451172\n",
            "Loss: 0.1224275529384613, Accuracy: 96.53679656982422\n",
            "Loss: 0.17485946416854858, Accuracy: 95.11441040039062\n",
            "Loss: 0.0974765345454216, Accuracy: 96.53679656982422\n",
            "Loss: 0.07063562422990799, Accuracy: 97.52628326416016\n",
            "Loss: 0.06040356308221817, Accuracy: 98.33023834228516\n",
            "Loss: 0.07652804255485535, Accuracy: 97.64997100830078\n",
            "Loss: 0.1028442308306694, Accuracy: 97.03153991699219\n",
            "Loss: 0.126609668135643, Accuracy: 96.90785217285156\n",
            "Loss: 0.1319218873977661, Accuracy: 96.96969604492188\n",
            "Loss: 0.155544713139534, Accuracy: 96.4131088256836\n",
            "Loss: 0.17510545253753662, Accuracy: 95.79468536376953\n",
            "Loss: 0.1870090812444687, Accuracy: 95.54730987548828\n",
            "Loss: 0.19046492874622345, Accuracy: 95.54730987548828\n",
            "Loss: 0.15526916086673737, Accuracy: 96.10389709472656\n",
            "Loss: 0.11255838721990585, Accuracy: 96.59864044189453\n",
            "Loss: 0.09032639116048813, Accuracy: 96.96969604492188\n",
            "Loss: 0.09645373374223709, Accuracy: 97.34075927734375\n",
            "Loss: 0.13828256726264954, Accuracy: 95.85652160644531\n",
            "Loss: 0.1848304122686386, Accuracy: 95.05256652832031\n",
            "Loss: 0.13443873822689056, Accuracy: 96.04205322265625\n",
            "Loss: 0.08592474460601807, Accuracy: 97.34075927734375\n",
            "Loss: 0.05571286752820015, Accuracy: 98.26839447021484\n",
            "Loss: 0.060186855494976044, Accuracy: 98.08287048339844\n",
            "Loss: 0.09523549675941467, Accuracy: 96.96969604492188\n",
            "Loss: 0.07305265963077545, Accuracy: 97.46443939208984\n",
            "Loss: 0.047274962067604065, Accuracy: 98.08287048339844\n",
            "Loss: 0.04754076153039932, Accuracy: 98.5157699584961\n",
            "Loss: 0.03310786932706833, Accuracy: 99.01051330566406\n",
            "Loss: 0.04692116007208824, Accuracy: 98.33023834228516\n",
            "Loss: 0.07861154526472092, Accuracy: 97.15522766113281\n",
            "Loss: 0.09640102833509445, Accuracy: 96.66048431396484\n",
            "Loss: 0.10548523813486099, Accuracy: 96.53679656982422\n",
            "Loss: 0.12313615530729294, Accuracy: 96.4131088256836\n",
            "Loss: 0.11148396134376526, Accuracy: 96.2894287109375\n",
            "Loss: 0.0897599533200264, Accuracy: 97.40259552001953\n",
            "Loss: 0.05705254152417183, Accuracy: 98.08287048339844\n",
            "Loss: 0.028349433094263077, Accuracy: 99.13420104980469\n",
            "Loss: 0.025619253516197205, Accuracy: 99.3197250366211\n",
            "Loss: 0.031508903950452805, Accuracy: 99.25788879394531\n",
            "Loss: 0.039497166872024536, Accuracy: 98.82498168945312\n",
            "Loss: 0.054259758442640305, Accuracy: 98.14470672607422\n",
            "Loss: 0.06987351179122925, Accuracy: 97.95918273925781\n",
            "Loss: 0.08758825063705444, Accuracy: 97.46443939208984\n",
            "Loss: 0.054016098380088806, Accuracy: 98.5157699584961\n",
            "Loss: 0.04793162643909454, Accuracy: 98.88683319091797\n",
            "Loss: 0.04119570925831795, Accuracy: 98.82498168945312\n",
            "Loss: 0.05575108528137207, Accuracy: 98.5157699584961\n",
            "Loss: 0.10001179575920105, Accuracy: 96.90785217285156\n",
            "Loss: 0.13180115818977356, Accuracy: 96.16574096679688\n",
            "Loss: 0.11887525022029877, Accuracy: 96.66048431396484\n",
            "Loss: 0.09646405279636383, Accuracy: 96.90785217285156\n",
            "Loss: 0.07675644010305405, Accuracy: 97.64997100830078\n",
            "Loss: 0.06051783263683319, Accuracy: 98.08287048339844\n",
            "Loss: 0.04216473177075386, Accuracy: 98.26839447021484\n",
            "Loss: 0.034156717360019684, Accuracy: 98.5157699584961\n",
            "Loss: 0.03286077454686165, Accuracy: 98.5776138305664\n",
            "Loss: 0.047165755182504654, Accuracy: 98.20655822753906\n",
            "Loss: 0.06367883086204529, Accuracy: 97.83550262451172\n",
            "Loss: 0.0742754191160202, Accuracy: 97.34075927734375\n",
            "Loss: 0.04723668098449707, Accuracy: 98.14470672607422\n",
            "Loss: 0.053001768887043, Accuracy: 98.33023834228516\n",
            "Loss: 0.07986713200807571, Accuracy: 97.52628326416016\n",
            "Loss: 0.0905463844537735, Accuracy: 97.0933837890625\n",
            "Loss: 0.0927325189113617, Accuracy: 97.52628326416016\n",
            "Loss: 0.12495138496160507, Accuracy: 97.2789077758789\n",
            "Loss: 0.11805972456932068, Accuracy: 97.46443939208984\n",
            "Loss: 0.0986858457326889, Accuracy: 97.64997100830078\n",
            "Loss: 0.08746176213026047, Accuracy: 97.64997100830078\n",
            "Loss: 0.07212351262569427, Accuracy: 98.08287048339844\n",
            "Loss: 0.04382847622036934, Accuracy: 98.63945770263672\n",
            "Loss: 0.026129893958568573, Accuracy: 99.3197250366211\n",
            "Loss: 0.017375817522406578, Accuracy: 99.25788879394531\n",
            "Loss: 0.015114810317754745, Accuracy: 99.3815689086914\n",
            "Loss: 0.02013428881764412, Accuracy: 99.3197250366211\n",
            "Loss: 0.02620067074894905, Accuracy: 98.94866943359375\n",
            "Loss: 0.03831205889582634, Accuracy: 98.45392608642578\n",
            "Loss: 0.04586457088589668, Accuracy: 98.5157699584961\n",
            "Loss: 0.06238635256886482, Accuracy: 98.26839447021484\n",
            "Loss: 0.05223067104816437, Accuracy: 98.26839447021484\n",
            "Loss: 0.05425908416509628, Accuracy: 98.63945770263672\n",
            "Loss: 0.05535615608096123, Accuracy: 98.39208221435547\n",
            "Loss: 0.05595366284251213, Accuracy: 98.45392608642578\n",
            "Loss: 0.05705031380057335, Accuracy: 98.70130157470703\n",
            "Loss: 0.03141746297478676, Accuracy: 99.01051330566406\n",
            "Loss: 0.025022970512509346, Accuracy: 99.07235717773438\n",
            "Loss: 0.0315537303686142, Accuracy: 98.94866943359375\n",
            "Loss: 0.045739106833934784, Accuracy: 98.70130157470703\n",
            "Loss: 0.059551212936639786, Accuracy: 98.39208221435547\n",
            "Loss: 0.07670541852712631, Accuracy: 97.7118148803711\n",
            "Loss: 0.06310785561800003, Accuracy: 98.39208221435547\n",
            "Loss: 0.050604794174432755, Accuracy: 98.5157699584961\n",
            "Loss: 0.04485933855175972, Accuracy: 98.70130157470703\n",
            "Loss: 0.0382116436958313, Accuracy: 98.82498168945312\n",
            "Loss: 0.026102324947714806, Accuracy: 99.19603729248047\n",
            "Loss: 0.025056641548871994, Accuracy: 99.3197250366211\n",
            "Loss: 0.031172415241599083, Accuracy: 99.13420104980469\n",
            "Loss: 0.04573819786310196, Accuracy: 98.5776138305664\n",
            "Loss: 0.06939996033906937, Accuracy: 98.20655822753906\n",
            "Loss: 0.09138999879360199, Accuracy: 97.34075927734375\n",
            "Loss: 0.08480913937091827, Accuracy: 97.52628326416016\n",
            "Loss: 0.08821985125541687, Accuracy: 97.46443939208984\n",
            "Loss: 0.06640653312206268, Accuracy: 98.08287048339844\n",
            "Loss: 0.04058618098497391, Accuracy: 98.82498168945312\n",
            "Loss: 0.02466885931789875, Accuracy: 99.07235717773438\n",
            "Loss: 0.017554238438606262, Accuracy: 99.50525665283203\n",
            "Loss: 0.018497377634048462, Accuracy: 99.62894439697266\n",
            "Loss: 0.026034759357571602, Accuracy: 99.19603729248047\n",
            "Loss: 0.05343569070100784, Accuracy: 98.45392608642578\n",
            "Loss: 0.08102352172136307, Accuracy: 97.46443939208984\n",
            "Loss: 0.10331684350967407, Accuracy: 96.78417205810547\n",
            "Loss: 0.10861209034919739, Accuracy: 96.72232055664062\n",
            "Loss: 0.0757545456290245, Accuracy: 97.8973388671875\n",
            "Loss: 0.050366710871458054, Accuracy: 98.5157699584961\n",
            "Loss: 0.04049052298069, Accuracy: 98.82498168945312\n",
            "Loss: 0.04377855733036995, Accuracy: 98.76314544677734\n",
            "Loss: 0.04342179000377655, Accuracy: 98.76314544677734\n",
            "Loss: 0.03089006245136261, Accuracy: 99.19603729248047\n",
            "Loss: 0.025473935529589653, Accuracy: 99.3197250366211\n",
            "Loss: 0.02545309253036976, Accuracy: 99.3815689086914\n",
            "Loss: 0.027429750189185143, Accuracy: 99.3197250366211\n",
            "Loss: 0.02850942499935627, Accuracy: 99.19603729248047\n",
            "Loss: 0.028733545914292336, Accuracy: 99.3197250366211\n",
            "Loss: 0.029794063419103622, Accuracy: 99.3197250366211\n",
            "Loss: 0.030239911749958992, Accuracy: 99.25788879394531\n",
            "Loss: 0.026091359555721283, Accuracy: 99.13420104980469\n",
            "Loss: 0.019762910902500153, Accuracy: 99.25788879394531\n",
            "Loss: 0.01587696187198162, Accuracy: 99.44341278076172\n",
            "Loss: 0.013433660380542278, Accuracy: 99.69078063964844\n",
            "Loss: 0.013180541805922985, Accuracy: 99.62894439697266\n",
            "Loss: 0.018619047477841377, Accuracy: 99.44341278076172\n",
            "Loss: 0.023656193166971207, Accuracy: 99.25788879394531\n",
            "Loss: 0.029126551002264023, Accuracy: 99.07235717773438\n",
            "Loss: 0.037773407995700836, Accuracy: 98.5157699584961\n"
          ]
        }
      ],
      "source": [
        "model = DigitsLogistic()\n",
        "opt = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for X_curr, y_curr in train_dl:\n",
        "\n",
        "    y_pred_curr = model(X_curr)\n",
        "    loss = loss_func(y_pred_curr, y_curr)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "    print(\n",
        "    f\"Loss: {loss_func(model(X_train), y_train)}, Accuracy: {accuracy(model(X_train), y_train)}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_RoAmr7GP-A"
      },
      "source": [
        "Thanks to Pytorch's ``nn.Module``, ``nn.Parameter``, ``Dataset``, and ``DataLoader``,\n",
        "our training loop is now dramatically smaller and easier to understand. Let's\n",
        "now try to add the basic features necessary to create effective models in practice.\n",
        "\n",
        "## Add validation\n",
        "\n",
        "In section 1, we were just trying to get a reasonable training loop set up for\n",
        "use on our training data.  In reality, you **always** should also have\n",
        "a [validation set](https://www.fast.ai/2017/11/13/validation-sets/), in order\n",
        "to identify if you are overfitting.\n",
        "\n",
        "We'll use a batch size for the validation set that is twice as large as\n",
        "that for the training set. This is because the validation set does not\n",
        "need backpropagation and thus takes less memory (it doesn't need to\n",
        "store the gradients). We take advantage of this to use a larger batch\n",
        "size and compute the loss more quickly by inserting the validation loop in a ``with torch.no_grad():``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "OeNLS88OGP-A"
      },
      "outputs": [],
      "source": [
        "train_ds = TensorDataset(X_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "\n",
        "valid_ds = TensorDataset(X_val, y_val)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=bs * 2) # Non need to shuffle the Validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KoFuQxUGP-A"
      },
      "source": [
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call ``model.train()`` before training, and ``model.eval()``\n",
        "before inference, because these are used by layers such as ``nn.BatchNorm2d``\n",
        "and ``nn.Dropout`` to ensure appropriate behaviour for these different phases.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.optim.adam.Adam"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(optim.Adam(model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGVGM59HGP-A",
        "outputId": "c183158f-eb22-4112-fe79-26b0fab02c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Val Loss 0.48, Val Acc: 88.37\n",
            "Epoch 1: Val Loss 0.32, Val Acc: 91.75\n",
            "Epoch 2: Val Loss 0.24, Val Acc: 93.02\n",
            "Epoch 3: Val Loss 0.20, Val Acc: 93.80\n",
            "Epoch 4: Val Loss 0.17, Val Acc: 94.61\n",
            "Epoch 5: Val Loss 0.17, Val Acc: 94.86\n",
            "Epoch 6: Val Loss 0.17, Val Acc: 94.71\n",
            "Epoch 7: Val Loss 0.16, Val Acc: 94.94\n",
            "Epoch 8: Val Loss 0.15, Val Acc: 95.26\n",
            "Epoch 9: Val Loss 0.14, Val Acc: 95.41\n",
            "Epoch 10: Val Loss 0.13, Val Acc: 95.72\n",
            "Epoch 11: Val Loss 0.12, Val Acc: 95.96\n",
            "Epoch 12: Val Loss 0.12, Val Acc: 96.14\n",
            "Epoch 13: Val Loss 0.12, Val Acc: 96.33\n",
            "Epoch 14: Val Loss 0.13, Val Acc: 96.24\n",
            "Epoch 15: Val Loss 0.13, Val Acc: 96.20\n",
            "Epoch 16: Val Loss 0.12, Val Acc: 96.34\n",
            "Epoch 17: Val Loss 0.12, Val Acc: 96.37\n",
            "Epoch 18: Val Loss 0.12, Val Acc: 96.48\n",
            "Epoch 19: Val Loss 0.11, Val Acc: 96.60\n",
            "Epoch 20: Val Loss 0.11, Val Acc: 96.68\n",
            "Epoch 21: Val Loss 0.12, Val Acc: 96.57\n",
            "Epoch 22: Val Loss 0.11, Val Acc: 96.62\n",
            "Epoch 23: Val Loss 0.11, Val Acc: 96.66\n",
            "Epoch 24: Val Loss 0.12, Val Acc: 96.65\n",
            "Epoch 25: Val Loss 0.12, Val Acc: 96.65\n",
            "Epoch 26: Val Loss 0.12, Val Acc: 96.64\n",
            "Epoch 27: Val Loss 0.13, Val Acc: 96.52\n",
            "Epoch 28: Val Loss 0.13, Val Acc: 96.53\n",
            "Epoch 29: Val Loss 0.13, Val Acc: 96.55\n",
            "Epoch 30: Val Loss 0.14, Val Acc: 96.57\n",
            "Epoch 31: Val Loss 0.14, Val Acc: 96.50\n",
            "Epoch 32: Val Loss 0.14, Val Acc: 96.58\n",
            "Epoch 33: Val Loss 0.14, Val Acc: 96.59\n",
            "Epoch 34: Val Loss 0.15, Val Acc: 96.57\n",
            "Epoch 35: Val Loss 0.15, Val Acc: 96.63\n",
            "Epoch 36: Val Loss 0.15, Val Acc: 96.64\n",
            "Epoch 37: Val Loss 0.15, Val Acc: 96.63\n",
            "Epoch 38: Val Loss 0.15, Val Acc: 96.67\n",
            "Epoch 39: Val Loss 0.14, Val Acc: 96.72\n",
            "Epoch 40: Val Loss 0.14, Val Acc: 96.71\n",
            "Epoch 41: Val Loss 0.15, Val Acc: 96.72\n",
            "Epoch 42: Val Loss 0.14, Val Acc: 96.74\n",
            "Epoch 43: Val Loss 0.15, Val Acc: 96.75\n",
            "Epoch 44: Val Loss 0.15, Val Acc: 96.78\n",
            "Epoch 45: Val Loss 0.14, Val Acc: 96.81\n",
            "Epoch 46: Val Loss 0.14, Val Acc: 96.83\n",
            "Epoch 47: Val Loss 0.14, Val Acc: 96.88\n",
            "Epoch 48: Val Loss 0.14, Val Acc: 96.88\n",
            "Epoch 49: Val Loss 0.14, Val Acc: 96.89\n",
            "Epoch 50: Val Loss 0.14, Val Acc: 96.93\n",
            "Epoch 51: Val Loss 0.14, Val Acc: 96.94\n",
            "Epoch 52: Val Loss 0.14, Val Acc: 96.96\n",
            "Epoch 53: Val Loss 0.14, Val Acc: 96.98\n",
            "Epoch 54: Val Loss 0.14, Val Acc: 97.00\n",
            "Epoch 55: Val Loss 0.15, Val Acc: 97.00\n",
            "Epoch 56: Val Loss 0.14, Val Acc: 97.03\n",
            "Epoch 57: Val Loss 0.14, Val Acc: 97.03\n",
            "Epoch 58: Val Loss 0.14, Val Acc: 97.05\n",
            "Epoch 59: Val Loss 0.14, Val Acc: 97.09\n",
            "Epoch 60: Val Loss 0.14, Val Acc: 97.11\n",
            "Epoch 61: Val Loss 0.14, Val Acc: 97.12\n",
            "Epoch 62: Val Loss 0.14, Val Acc: 97.15\n",
            "Epoch 63: Val Loss 0.14, Val Acc: 97.14\n",
            "Epoch 64: Val Loss 0.14, Val Acc: 97.16\n",
            "Epoch 65: Val Loss 0.14, Val Acc: 97.17\n",
            "Epoch 66: Val Loss 0.14, Val Acc: 97.18\n",
            "Epoch 67: Val Loss 0.14, Val Acc: 97.18\n",
            "Epoch 68: Val Loss 0.14, Val Acc: 97.20\n",
            "Epoch 69: Val Loss 0.14, Val Acc: 97.19\n",
            "Epoch 70: Val Loss 0.14, Val Acc: 97.19\n",
            "Epoch 71: Val Loss 0.15, Val Acc: 97.19\n",
            "Epoch 72: Val Loss 0.15, Val Acc: 97.20\n",
            "Epoch 73: Val Loss 0.15, Val Acc: 97.22\n",
            "Epoch 74: Val Loss 0.14, Val Acc: 97.22\n",
            "Epoch 75: Val Loss 0.14, Val Acc: 97.25\n",
            "Epoch 76: Val Loss 0.14, Val Acc: 97.27\n",
            "Epoch 77: Val Loss 0.14, Val Acc: 97.26\n",
            "Epoch 78: Val Loss 0.15, Val Acc: 97.27\n",
            "Epoch 79: Val Loss 0.15, Val Acc: 97.28\n",
            "Epoch 80: Val Loss 0.15, Val Acc: 97.29\n",
            "Epoch 81: Val Loss 0.15, Val Acc: 97.28\n",
            "Epoch 82: Val Loss 0.15, Val Acc: 97.27\n",
            "Epoch 83: Val Loss 0.15, Val Acc: 97.26\n",
            "Epoch 84: Val Loss 0.15, Val Acc: 97.26\n",
            "Epoch 85: Val Loss 0.15, Val Acc: 97.25\n",
            "Epoch 86: Val Loss 0.15, Val Acc: 97.24\n",
            "Epoch 87: Val Loss 0.15, Val Acc: 97.25\n",
            "Epoch 88: Val Loss 0.15, Val Acc: 97.25\n",
            "Epoch 89: Val Loss 0.15, Val Acc: 97.25\n",
            "Epoch 90: Val Loss 0.15, Val Acc: 97.25\n",
            "Epoch 91: Val Loss 0.15, Val Acc: 97.26\n",
            "Epoch 92: Val Loss 0.15, Val Acc: 97.26\n",
            "Epoch 93: Val Loss 0.15, Val Acc: 97.26\n",
            "Epoch 94: Val Loss 0.15, Val Acc: 97.26\n",
            "Epoch 95: Val Loss 0.15, Val Acc: 97.27\n",
            "Epoch 96: Val Loss 0.15, Val Acc: 97.27\n",
            "Epoch 97: Val Loss 0.15, Val Acc: 97.27\n",
            "Epoch 98: Val Loss 0.15, Val Acc: 97.27\n",
            "Epoch 99: Val Loss 0.15, Val Acc: 97.27\n"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "hovertemplate": "index=%{x}<br>valid_acc=%{y}<extra></extra>",
                  "legendgroup": "",
                  "line": {
                    "color": "#636efa",
                    "dash": "solid"
                  },
                  "marker": {
                    "symbol": "circle"
                  },
                  "mode": "lines",
                  "name": "",
                  "orientation": "v",
                  "showlegend": false,
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49,
                    50,
                    51,
                    52,
                    53,
                    54,
                    55,
                    56,
                    57,
                    58,
                    59,
                    60,
                    61,
                    62,
                    63,
                    64,
                    65,
                    66,
                    67,
                    68,
                    69,
                    70,
                    71,
                    72,
                    73,
                    74,
                    75,
                    76,
                    77,
                    78,
                    79,
                    80,
                    81,
                    82,
                    83,
                    84,
                    85,
                    86,
                    87,
                    88,
                    89,
                    90,
                    91,
                    92,
                    93,
                    94,
                    95,
                    96,
                    97,
                    98,
                    99,
                    100,
                    101,
                    102,
                    103,
                    104,
                    105,
                    106,
                    107,
                    108,
                    109,
                    110,
                    111,
                    112,
                    113,
                    114,
                    115,
                    116,
                    117,
                    118,
                    119,
                    120,
                    121,
                    122,
                    123,
                    124,
                    125,
                    126,
                    127,
                    128,
                    129,
                    130,
                    131,
                    132,
                    133,
                    134,
                    135,
                    136,
                    137,
                    138,
                    139,
                    140,
                    141,
                    142,
                    143,
                    144,
                    145,
                    146,
                    147,
                    148,
                    149,
                    150,
                    151,
                    152,
                    153,
                    154,
                    155,
                    156,
                    157,
                    158,
                    159,
                    160,
                    161,
                    162,
                    163,
                    164,
                    165,
                    166,
                    167,
                    168,
                    169,
                    170,
                    171,
                    172,
                    173,
                    174,
                    175,
                    176,
                    177,
                    178,
                    179,
                    180,
                    181,
                    182,
                    183,
                    184,
                    185,
                    186,
                    187,
                    188,
                    189,
                    190,
                    191,
                    192,
                    193,
                    194,
                    195,
                    196,
                    197,
                    198,
                    199
                  ],
                  "xaxis": "x",
                  "y": [
                    88.28125,
                    88.46153259277344,
                    92.1875,
                    98.07691955566406,
                    96.875,
                    94.23077392578125,
                    96.09375,
                    96.15384674072266,
                    97.65625,
                    98.07691955566406,
                    96.09375,
                    96.15384674072266,
                    95.3125,
                    92.30769348144531,
                    96.875,
                    96.15384674072266,
                    97.65625,
                    98.07691955566406,
                    99.21875,
                    94.23077392578125,
                    97.65625,
                    100,
                    99.21875,
                    98.07691955566406,
                    98.4375,
                    98.07691955566406,
                    97.65625,
                    100,
                    97.65625,
                    92.30769348144531,
                    96.875,
                    94.23077392578125,
                    99.21875,
                    98.07691955566406,
                    97.65625,
                    96.15384674072266,
                    96.875,
                    100,
                    97.65625,
                    100,
                    98.4375,
                    98.07691955566406,
                    94.53125,
                    94.23077392578125,
                    99.21875,
                    96.15384674072266,
                    96.875,
                    98.07691955566406,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.09375,
                    90.38461303710938,
                    95.3125,
                    98.07691955566406,
                    96.09375,
                    98.07691955566406,
                    98.4375,
                    96.15384674072266,
                    96.09375,
                    92.30769348144531,
                    98.4375,
                    100,
                    96.09375,
                    98.07691955566406,
                    95.3125,
                    96.15384674072266,
                    97.65625,
                    100,
                    97.65625,
                    96.15384674072266,
                    98.4375,
                    94.23077392578125,
                    98.4375,
                    98.07691955566406,
                    99.21875,
                    98.07691955566406,
                    96.09375,
                    96.15384674072266,
                    96.09375,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    97.65625,
                    96.15384674072266,
                    98.4375,
                    98.07691955566406,
                    98.4375,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    98.4375,
                    100,
                    96.875,
                    96.15384674072266,
                    96.875,
                    98.07691955566406,
                    97.65625,
                    100,
                    97.65625,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    98.4375,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    98.4375,
                    98.07691955566406,
                    98.4375,
                    100,
                    98.4375,
                    98.07691955566406,
                    96.09375,
                    100,
                    97.65625,
                    100,
                    95.3125,
                    98.07691955566406,
                    96.09375,
                    100,
                    99.21875,
                    96.15384674072266,
                    96.09375,
                    100,
                    96.875,
                    98.07691955566406,
                    96.875,
                    100,
                    98.4375,
                    94.23077392578125,
                    97.65625,
                    96.15384674072266,
                    96.875,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    97.65625,
                    100,
                    96.875,
                    98.07691955566406,
                    97.65625,
                    100,
                    97.65625,
                    100,
                    96.09375,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    97.65625,
                    98.07691955566406,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    98.07691955566406,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406,
                    96.875,
                    98.07691955566406
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "index"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "valid_acc"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from typing import Callable\n",
        "\n",
        "\n",
        "model = DigitsLogistic()\n",
        "opt = optim.Adam(model.parameters(), lr=lr)\n",
        "epochs = 100\n",
        "\n",
        "def fit(\n",
        "  model: nn.Module,\n",
        "  opt: optim.Adam,\n",
        "  epochs: int,\n",
        "  loss_func: Callable,\n",
        "  train_dl: TensorDataset,\n",
        "  valid_dl: TensorDataset,\n",
        "):\n",
        "\n",
        "  valid_losses = []\n",
        "  valid_accs = []\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    for X_curr, y_curr in train_dl:\n",
        "      y_pred_curr = model(X_curr)\n",
        "      loss = loss_func(y_pred_curr, y_curr)\n",
        "\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    for X_val_curr, y_val_curr in valid_dl:\n",
        "      valid_loss = float(loss_func(model(X_val_curr), y_val_curr))\n",
        "      valid_losses.append(valid_loss)\n",
        "\n",
        "      acc_loss = accuracy(model(X_val_curr), y_val_curr)\n",
        "      valid_accs.append(acc_loss)\n",
        "\n",
        "    print(\n",
        "      f\"Epoch {epoch}: Val Loss {np.mean(valid_losses):.2f}, \"\n",
        "      f\"Val Acc: {np.mean(valid_accs):.2f}\"\n",
        "    )\n",
        "\n",
        "  df = pd.DataFrame({\"valid_loss\": valid_losses, \"valid_acc\": valid_accs})\n",
        "  px.line(df, y=\"valid_acc\").show()\n",
        "\n",
        "fit(model, opt, epochs, loss_func, train_dl, valid_dl)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccS_IWFCEPTf"
      },
      "source": [
        "### Saving best model: early stopping\n",
        "It may have happend that the model has reached the highest validation accuracy (and/or lower validation loss) not at the last epoch. It means that the model overfitted the training data.\n",
        "\n",
        "A possible way to avoid this phenomenon is to save the model achieving the best validation accuracy (other possible solutions includes reducing the learning rate and decreasing the number of training epochs).\n",
        "\n",
        "There exists two possible way to do it in pytorch. ``torch.save()`` and ``torch.load()`` can be used with any kind of objects. Torch will serialized this object through pickle. However, if the code generating the object is modified the code might brake in several ways. To avoid this issue, torch provides another couple of functions, ``model.state_dict()`` and ``model.load_state_dict()``, which only save and load the weights of the network.\n",
        "\n",
        "    torch.save(model.state_dict(), \"best_model.pt\")\n",
        "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "For further information on this topic, please read this [tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7uoHLFmUzRk",
        "outputId": "8031d89b-e7bd-4c6e-aa9d-d99465cd66d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Val Loss 0.99, Val Acc: 91.47\n",
            "Epoch 1: Val Loss 0.81, Val Acc: 92.62\n",
            "Epoch 4: Val Loss 0.57, Val Acc: 93.05\n",
            "Epoch 5: Val Loss 0.53, Val Acc: 93.63\n",
            "Epoch 6: Val Loss 0.49, Val Acc: 93.99\n",
            "Epoch 7: Val Loss 0.46, Val Acc: 94.25\n",
            "Epoch 8: Val Loss 0.44, Val Acc: 94.50\n",
            "Epoch 9: Val Loss 0.41, Val Acc: 94.55\n",
            "Epoch 10: Val Loss 0.39, Val Acc: 94.73\n",
            "Epoch 11: Val Loss 0.38, Val Acc: 94.88\n",
            "Epoch 12: Val Loss 0.36, Val Acc: 94.97\n",
            "Epoch 13: Val Loss 0.35, Val Acc: 95.08\n",
            "Epoch 14: Val Loss 0.34, Val Acc: 95.15\n",
            "Epoch 15: Val Loss 0.33, Val Acc: 95.21\n",
            "Epoch 16: Val Loss 0.32, Val Acc: 95.29\n",
            "Epoch 17: Val Loss 0.31, Val Acc: 95.34\n",
            "Epoch 18: Val Loss 0.30, Val Acc: 95.40\n",
            "Epoch 19: Val Loss 0.29, Val Acc: 95.43\n",
            "Epoch 20: Val Loss 0.29, Val Acc: 95.50\n",
            "Epoch 21: Val Loss 0.28, Val Acc: 95.57\n",
            "Epoch 22: Val Loss 0.27, Val Acc: 95.63\n",
            "Epoch 23: Val Loss 0.27, Val Acc: 95.66\n",
            "Epoch 24: Val Loss 0.26, Val Acc: 95.70\n",
            "Epoch 25: Val Loss 0.26, Val Acc: 95.73\n",
            "Epoch 26: Val Loss 0.25, Val Acc: 95.76\n",
            "Epoch 27: Val Loss 0.25, Val Acc: 95.80\n",
            "Epoch 28: Val Loss 0.24, Val Acc: 95.82\n",
            "Epoch 29: Val Loss 0.24, Val Acc: 95.89\n"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "hovertemplate": "index=%{x}<br>valid_acc=%{y}<extra></extra>",
                  "legendgroup": "",
                  "line": {
                    "color": "#636efa",
                    "dash": "solid"
                  },
                  "marker": {
                    "symbol": "circle"
                  },
                  "mode": "lines",
                  "name": "",
                  "orientation": "v",
                  "showlegend": false,
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49,
                    50,
                    51,
                    52,
                    53,
                    54,
                    55,
                    56,
                    57,
                    58,
                    59
                  ],
                  "xaxis": "x",
                  "y": [
                    90.625,
                    92.30769348144531,
                    91.40625,
                    96.15384674072266,
                    91.40625,
                    92.30769348144531,
                    91.40625,
                    94.23077392578125,
                    94.53125,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    93.75,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    97.65625,
                    98.07691955566406
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "index"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "valid_acc"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acc: 97.86658477783203\n"
          ]
        }
      ],
      "source": [
        "model = DigitsLogistic()\n",
        "opt = optim.SGD(model.parameters(), lr=lr)\n",
        "epochs = 30\n",
        "\n",
        "\n",
        "def fit(\n",
        "  model: nn.Module,\n",
        "  opt: optim.Adam,\n",
        "  epochs: int,\n",
        "  loss_func: Callable,\n",
        "  train_dl: TensorDataset,\n",
        "  valid_dl: TensorDataset,\n",
        "):\n",
        "\n",
        "  valid_losses = []\n",
        "  valid_accs = []\n",
        "  best_acc = 0\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    for X_curr, y_curr in train_dl:\n",
        "      y_pred_curr = model(X_curr)\n",
        "      loss = loss_func(y_pred_curr, y_curr)\n",
        "\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    for X_val_curr, y_val_curr in valid_dl:\n",
        "      valid_loss = float(loss_func(model(X_val_curr), y_val_curr))\n",
        "      valid_losses.append(valid_loss)\n",
        "\n",
        "      acc_loss = accuracy(model(X_val_curr), y_val_curr)\n",
        "      valid_accs.append(acc_loss)\n",
        "\n",
        "    epoch_acc = np.mean(valid_accs)\n",
        "    if epoch_acc > best_acc:\n",
        "      best_acc = epoch_acc\n",
        "      torch.save(model.state_dict(), \"best_model.pt\")\n",
        "\n",
        "      print(\n",
        "          f\"Epoch {epoch}: Val Loss {np.mean(valid_losses):.2f}, \"\n",
        "          f\"Val Acc: {np.mean(valid_accs):.2f}\"\n",
        "      )\n",
        "\n",
        "  df = pd.DataFrame({\"valid_loss\": valid_losses, \"valid_acc\": valid_accs})\n",
        "  px.line(df, y=\"valid_acc\").show()\n",
        "\n",
        "fit(model, opt, epochs, loss_func, train_dl, valid_dl)\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "model.eval()\n",
        "print(f\"Acc: {np.mean([accuracy(model(xb), yb) for xb, yb in valid_dl])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEADjDjZGP-E"
      },
      "source": [
        "## Using your GPU\n",
        "\n",
        "If you're lucky enough to have access to a CUDA-capable GPU you can\n",
        "use it to speed up your code. To do so in COLAB you can change *runtime type* in the *Runtime* dropdown menu to enable GPU computation. After changing the runtime type you will need to rerun the whole notebook beacause all variables will be lost (*Runtime* -> *Run all*).\n",
        "\n",
        "Let's check that your GPU is working with Pytorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0jas1PPGP-E",
        "outputId": "dbaf907f-c926-4d74-fbaf-eae2862c5235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkSz6FMDGP-E"
      },
      "source": [
        "And then create a device object for it:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "uFnllnDDGP-E"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfvKuUCuGP-F"
      },
      "source": [
        "Finally, we can move our model and our data to the GPU. \n",
        "Generally dataset do not fit in the GPU, so we need to move only the batches inside the training/validation loops: \n",
        "\n",
        "    xb = xb.to(dev)\n",
        "    yb = yb.to(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "lGAygmyqGP-F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Val Loss 0.97, Val Acc: 90.47\n",
            "Epoch 1: Val Loss 0.79, Val Acc: 92.04\n",
            "Epoch 2: Val Loss 0.69, Val Acc: 92.69\n",
            "Epoch 3: Val Loss 0.62, Val Acc: 93.11\n",
            "Epoch 5: Val Loss 0.52, Val Acc: 93.34\n",
            "Epoch 6: Val Loss 0.48, Val Acc: 93.60\n",
            "Epoch 7: Val Loss 0.45, Val Acc: 93.92\n",
            "Epoch 8: Val Loss 0.43, Val Acc: 94.12\n",
            "Epoch 9: Val Loss 0.41, Val Acc: 94.28\n",
            "Epoch 10: Val Loss 0.39, Val Acc: 94.48\n",
            "Epoch 11: Val Loss 0.37, Val Acc: 94.65\n",
            "Epoch 12: Val Loss 0.36, Val Acc: 94.79\n",
            "Epoch 13: Val Loss 0.35, Val Acc: 94.89\n",
            "Epoch 14: Val Loss 0.34, Val Acc: 95.00\n",
            "Epoch 15: Val Loss 0.33, Val Acc: 95.09\n",
            "Epoch 16: Val Loss 0.32, Val Acc: 95.18\n",
            "Epoch 17: Val Loss 0.31, Val Acc: 95.25\n",
            "Epoch 18: Val Loss 0.30, Val Acc: 95.39\n",
            "Epoch 19: Val Loss 0.29, Val Acc: 95.44\n",
            "Epoch 20: Val Loss 0.28, Val Acc: 95.48\n",
            "Epoch 21: Val Loss 0.28, Val Acc: 95.54\n",
            "Epoch 22: Val Loss 0.27, Val Acc: 95.57\n",
            "Epoch 23: Val Loss 0.27, Val Acc: 95.62\n",
            "Epoch 24: Val Loss 0.26, Val Acc: 95.66\n",
            "Epoch 25: Val Loss 0.26, Val Acc: 95.71\n",
            "Epoch 26: Val Loss 0.25, Val Acc: 95.74\n",
            "Epoch 27: Val Loss 0.25, Val Acc: 95.78\n",
            "Epoch 28: Val Loss 0.24, Val Acc: 95.80\n",
            "Epoch 29: Val Loss 0.24, Val Acc: 95.84\n",
            "Epoch 30: Val Loss 0.23, Val Acc: 95.87\n",
            "Epoch 31: Val Loss 0.23, Val Acc: 95.91\n",
            "Epoch 32: Val Loss 0.23, Val Acc: 95.97\n",
            "Epoch 33: Val Loss 0.22, Val Acc: 96.02\n",
            "Epoch 34: Val Loss 0.22, Val Acc: 96.06\n",
            "Epoch 35: Val Loss 0.22, Val Acc: 96.11\n",
            "Epoch 36: Val Loss 0.21, Val Acc: 96.15\n",
            "Epoch 37: Val Loss 0.21, Val Acc: 96.20\n",
            "Epoch 38: Val Loss 0.21, Val Acc: 96.21\n",
            "Epoch 39: Val Loss 0.21, Val Acc: 96.26\n",
            "Epoch 40: Val Loss 0.20, Val Acc: 96.29\n",
            "Epoch 41: Val Loss 0.20, Val Acc: 96.33\n",
            "Epoch 42: Val Loss 0.20, Val Acc: 96.35\n",
            "Epoch 43: Val Loss 0.20, Val Acc: 96.35\n",
            "Epoch 44: Val Loss 0.20, Val Acc: 96.38\n",
            "Epoch 45: Val Loss 0.19, Val Acc: 96.42\n",
            "Epoch 46: Val Loss 0.19, Val Acc: 96.45\n",
            "Epoch 47: Val Loss 0.19, Val Acc: 96.48\n",
            "Epoch 48: Val Loss 0.19, Val Acc: 96.48\n",
            "Epoch 49: Val Loss 0.19, Val Acc: 96.51\n",
            "Epoch 50: Val Loss 0.18, Val Acc: 96.54\n",
            "Epoch 51: Val Loss 0.18, Val Acc: 96.56\n",
            "Epoch 52: Val Loss 0.18, Val Acc: 96.59\n",
            "Epoch 53: Val Loss 0.18, Val Acc: 96.61\n",
            "Epoch 54: Val Loss 0.18, Val Acc: 96.64\n",
            "Epoch 55: Val Loss 0.18, Val Acc: 96.66\n",
            "Epoch 56: Val Loss 0.17, Val Acc: 96.68\n",
            "Epoch 57: Val Loss 0.17, Val Acc: 96.69\n",
            "Epoch 58: Val Loss 0.17, Val Acc: 96.71\n",
            "Epoch 59: Val Loss 0.17, Val Acc: 96.73\n",
            "Epoch 60: Val Loss 0.17, Val Acc: 96.75\n",
            "Epoch 61: Val Loss 0.17, Val Acc: 96.77\n",
            "Epoch 62: Val Loss 0.17, Val Acc: 96.79\n",
            "Epoch 63: Val Loss 0.17, Val Acc: 96.80\n",
            "Epoch 64: Val Loss 0.16, Val Acc: 96.80\n",
            "Epoch 65: Val Loss 0.16, Val Acc: 96.82\n",
            "Epoch 66: Val Loss 0.16, Val Acc: 96.84\n",
            "Epoch 67: Val Loss 0.16, Val Acc: 96.85\n",
            "Epoch 68: Val Loss 0.16, Val Acc: 96.87\n",
            "Epoch 69: Val Loss 0.16, Val Acc: 96.88\n",
            "Epoch 70: Val Loss 0.16, Val Acc: 96.89\n",
            "Epoch 71: Val Loss 0.16, Val Acc: 96.91\n",
            "Epoch 72: Val Loss 0.16, Val Acc: 96.92\n",
            "Epoch 73: Val Loss 0.16, Val Acc: 96.93\n",
            "Epoch 74: Val Loss 0.15, Val Acc: 96.95\n",
            "Epoch 75: Val Loss 0.15, Val Acc: 96.96\n",
            "Epoch 76: Val Loss 0.15, Val Acc: 96.97\n",
            "Epoch 77: Val Loss 0.15, Val Acc: 96.98\n",
            "Epoch 78: Val Loss 0.15, Val Acc: 96.99\n",
            "Epoch 79: Val Loss 0.15, Val Acc: 97.00\n",
            "Epoch 80: Val Loss 0.15, Val Acc: 97.01\n",
            "Epoch 81: Val Loss 0.15, Val Acc: 97.02\n",
            "Epoch 82: Val Loss 0.15, Val Acc: 97.03\n",
            "Epoch 83: Val Loss 0.15, Val Acc: 97.04\n",
            "Epoch 84: Val Loss 0.15, Val Acc: 97.05\n",
            "Epoch 85: Val Loss 0.15, Val Acc: 97.06\n",
            "Epoch 86: Val Loss 0.14, Val Acc: 97.07\n",
            "Epoch 87: Val Loss 0.14, Val Acc: 97.08\n",
            "Epoch 88: Val Loss 0.14, Val Acc: 97.09\n",
            "Epoch 89: Val Loss 0.14, Val Acc: 97.09\n",
            "Epoch 90: Val Loss 0.14, Val Acc: 97.10\n",
            "Epoch 91: Val Loss 0.14, Val Acc: 97.11\n",
            "Epoch 92: Val Loss 0.14, Val Acc: 97.12\n",
            "Epoch 93: Val Loss 0.14, Val Acc: 97.13\n",
            "Epoch 94: Val Loss 0.14, Val Acc: 97.14\n",
            "Epoch 95: Val Loss 0.14, Val Acc: 97.14\n",
            "Epoch 96: Val Loss 0.14, Val Acc: 97.15\n",
            "Epoch 97: Val Loss 0.14, Val Acc: 97.16\n",
            "Epoch 98: Val Loss 0.14, Val Acc: 97.16\n",
            "Epoch 99: Val Loss 0.14, Val Acc: 97.17\n"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "hovertemplate": "index=%{x}<br>valid_acc=%{y}<extra></extra>",
                  "legendgroup": "",
                  "line": {
                    "color": "#636efa",
                    "dash": "solid"
                  },
                  "marker": {
                    "symbol": "circle"
                  },
                  "mode": "lines",
                  "name": "",
                  "orientation": "v",
                  "showlegend": false,
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49,
                    50,
                    51,
                    52,
                    53,
                    54,
                    55,
                    56,
                    57,
                    58,
                    59,
                    60,
                    61,
                    62,
                    63,
                    64,
                    65,
                    66,
                    67,
                    68,
                    69,
                    70,
                    71,
                    72,
                    73,
                    74,
                    75,
                    76,
                    77,
                    78,
                    79,
                    80,
                    81,
                    82,
                    83,
                    84,
                    85,
                    86,
                    87,
                    88,
                    89,
                    90,
                    91,
                    92,
                    93,
                    94,
                    95,
                    96,
                    97,
                    98,
                    99,
                    100,
                    101,
                    102,
                    103,
                    104,
                    105,
                    106,
                    107,
                    108,
                    109,
                    110,
                    111,
                    112,
                    113,
                    114,
                    115,
                    116,
                    117,
                    118,
                    119,
                    120,
                    121,
                    122,
                    123,
                    124,
                    125,
                    126,
                    127,
                    128,
                    129,
                    130,
                    131,
                    132,
                    133,
                    134,
                    135,
                    136,
                    137,
                    138,
                    139,
                    140,
                    141,
                    142,
                    143,
                    144,
                    145,
                    146,
                    147,
                    148,
                    149,
                    150,
                    151,
                    152,
                    153,
                    154,
                    155,
                    156,
                    157,
                    158,
                    159,
                    160,
                    161,
                    162,
                    163,
                    164,
                    165,
                    166,
                    167,
                    168,
                    169,
                    170,
                    171,
                    172,
                    173,
                    174,
                    175,
                    176,
                    177,
                    178,
                    179,
                    180,
                    181,
                    182,
                    183,
                    184,
                    185,
                    186,
                    187,
                    188,
                    189,
                    190,
                    191,
                    192,
                    193,
                    194,
                    195,
                    196,
                    197,
                    198,
                    199
                  ],
                  "xaxis": "x",
                  "y": [
                    86.71875,
                    94.23077392578125,
                    92.96875,
                    94.23077392578125,
                    93.75,
                    94.23077392578125,
                    94.53125,
                    94.23077392578125,
                    91.40625,
                    94.23077392578125,
                    95.3125,
                    94.23077392578125,
                    96.09375,
                    94.23077392578125,
                    96.09375,
                    96.15384674072266,
                    95.3125,
                    96.15384674072266,
                    95.3125,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    97.65625,
                    98.0769271850586,
                    96.875,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    96.09375,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    97.65625,
                    96.15384674072266,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    96.875,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    96.875,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    96.15384674072266,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    96.15384674072266,
                    96.875,
                    96.15384674072266,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    96.15384674072266,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    96.875,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    96.15384674072266,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    96.875,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586,
                    97.65625,
                    98.0769271850586
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "index"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "valid_acc"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = DigitsLogistic().to(dev)\n",
        "opt = optim.SGD(model.parameters(), lr=lr)\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "def fit(\n",
        "  model: nn.Module,\n",
        "  opt: optim.Adam,\n",
        "  epochs: int,\n",
        "  loss_func: Callable,\n",
        "  train_dl: TensorDataset,\n",
        "  valid_dl: TensorDataset,\n",
        "  dev: torch.device,\n",
        "):\n",
        "\n",
        "  valid_losses = []\n",
        "  valid_accs = []\n",
        "  best_acc = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for X_curr, y_curr in train_dl:\n",
        "      X_curr = X_curr.to(dev)\n",
        "      y_curr = y_curr.to(dev)\n",
        "\n",
        "      y_pred_curr = model(X_curr)\n",
        "      loss = loss_func(y_pred_curr, y_curr)\n",
        "\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    model.eval()\n",
        "    for X_val_curr, y_val_curr in valid_dl:\n",
        "      X_val_curr = X_val_curr.to(dev)\n",
        "      y_val_curr = y_val_curr.to(dev)\n",
        "\n",
        "      valid_loss = float(loss_func(model(X_val_curr), y_val_curr).cpu())\n",
        "      valid_losses.append(valid_loss)\n",
        "\n",
        "      acc_loss = accuracy(model(X_val_curr), y_val_curr).cpu()\n",
        "      valid_accs.append(acc_loss)\n",
        "\n",
        "    epoch_acc = np.mean(valid_accs)\n",
        "    if epoch_acc > best_acc:\n",
        "      best_acc = epoch_acc\n",
        "      torch.save(model.state_dict(), \"best_model.pt\")\n",
        "\n",
        "      print(\n",
        "        f\"Epoch {epoch}: Val Loss {np.mean(valid_losses):.2f}, \"\n",
        "        f\"Val Acc: {np.mean(valid_accs):.2f}\"\n",
        "      )\n",
        "\n",
        "  df = pd.DataFrame({\"valid_loss\": valid_losses, \"valid_acc\": valid_accs})\n",
        "  px.line(df, y=\"valid_acc\").show()\n",
        "\n",
        "\n",
        "fit(model, opt, epochs, loss_func, train_dl, valid_dl, dev)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz2QEZ0h0ZBJ"
      },
      "source": [
        "## What has the network learnt?\n",
        "\n",
        "So far we have seen that the network has learnt, but how can we visualize it?\n",
        "There exists several mechanism to do so. On a logistic regression we can directly visualize both biases and weights!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pQfAWYIX0Ydz",
        "outputId": "3f6e5631-cb99-4d48-fed2-8b3d204f4892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bias: tensor([-0.0988, -0.1760, -0.0187,  0.0784,  0.2224, -0.0350, -0.1253,  0.1009,\n",
            "        -0.2838,  0.0298])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAEICAYAAACHyrIWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ7UlEQVR4nO3dfbBU9X3H8feHCypcEJooGfXy1JrQ2qQ+9IoPUJ1A0vEp6kxrKlOtWhubaU11EoaY0mZqO820/mEeGktrwcQqlSjRVB1N6kxwqK0RRKVRwapUAygPPvDgxbl44ds/zsFZ4F7u2b17zi4/Pq+ZHXf3/Di/71n3s79zzt09P0UEZpaOYa0uwMyay6E2S4xDbZYYh9osMQ61WWIcarPEONSHOUnTJb0s6T1JlxZoP1lSSBpeRX1FSLpa0hOtrqNdHFahlvSapPfzN/AmSd+XNLrBdYWkE8tqX6G/Br4bEaMj4kf7L8xfs8+UXYSkr+evUel9pe6wCnXucxExGjgN6Ab+Yv8G7TQKVWAS8EIrC5D0K8BlwJutrCMVh2OoAYiIDcCjwCfhw5H0TyW9DLycP/cFSa9IekfSg5KOz59flq9mVT7q/1697SU9L+lze+uRNELSW5JOrdnFvU7SG5LelDSnpu0wSTdJelXS25LulfSRgbb1IHW9Cvwy8FBe15H7/bu7gIk1y+fWLP59Sb/Ia57XaG2524CvArsO1kjSBEn3S9qSr/u7A7T7tqR1krZLWinpt2qWTZP0dL5sk6Rb8+ePknR3vt6tklZI+tggdbeniDhsbsBrwGfy+xPIRqi/yR8H8BjwEWAkMBN4i2xEPxL4B2BZzboCOLHmcb3t5wI/qHl8CfDz/P7kvP09QCfwKWBLTe03AD8DuvK+/hm4Z4BtHqyuD1+TwV6z/Wr7l/x1OhnoBX6t3try9pcB/z5YLUAHsAr4Zv6aHAXMyJddDTxR0/YK4KPAcOArwEbgqHzZk8CV+f3RwJn5/T8GHgJG5X39JnB0q9+zDb3PW11ApRubvWneA7YCrwP/CIzMlwUws6btQuCWmsejgQ+AyTXtTxxC++OBHXvfOMASYG5+f29wfrWm/S3Awvz+amBWzbLj8r6G97PNg9XVaKi7ap5bDlzeQG1jyPaKBq0FOIvsg62/9ewT6n6WvwucnN9fBtwMHLNfmz8E/hv4jVa/T4d6Oxx3vy+NiHERMSki/iQi3q9Ztq7m/vFkwQcgIt4D3gZOGGC9dbWPiDeA/wJ+R9I44Hxg0X7Naut5Pe8DsuPgB/LdxK1kQdoN9Le7WO92FLWx5v5Osg+Lemv7K+CuiHitQH8TgNcjom+whpLmSFotaVtew1jgmHzxtcAngDX5LvZF+fN3AT8BFueHPLdIGlGgrrZzOIb6YGp/svYG2RsUAEmdZLt0Gwb4t/W2B7iTbFfxMuDJyI7za02ouT8x7wOysJ+ffzjtvR3Vz79vtK5a9f6Mr57aZgF/JmmjpI1k23uvpK8OsN6Jg53EzI+f5wKfB34pIsYB2wABRMTLETEbGA/8PbBEUmdEfBARN0fEScDZwEXAH9S57W3BoR7YPcA1kk7JTyB9A3iqZlTZRHaSqdH2AD8iO9a9AfjXfmr4S0mjJP06cA3wg/z5fwL+VtIkAEnHSrqkwe0YTH91H0w9tc0iO1F5Sn57g+zY9rZ+2i4nOzv+d5I68xNb0/tpNwboI99Vl/R14Oi9CyVdIenYiNhDdhgGsEfSpyV9SlIHsJ3skGFPHdvdPlq9/1/ljYMfs+1zzJs/90XgVeAd4GH2PY78ItmbbCvw+Uba588vAHqA0TXPTc7ruY7sjb6R/Hg7Xz4M+DLwEtlx+avANw6y3Qera8DXJF9+CfCLvO45NbUNr2nzOPBHjdRW9P9Pvnwi2Qfh22Qn/76TP381+TE12UmuO8iC+SbZqP3heoG7gc1k51ZeIDscA5id19xD9kH2Hfo5fj8Ubso3yFokH0k+ERFX1Dw3Gfg/YEQUOIY0q3U4fcmi7eR/v70WuLLVtVg6fEzdIpK+QHby59GIWDZYe7OivPttlhiP1GaJKeWYetSoUTF27NgyVn2APXuq+6tDT09PZX0B9Pb2VtbX6NEN/VitIdu2bausrzFjxlTWF0BnZ2cl/WzdupWdO3eqv2WlhHrs2LFcddVVZaz6ADt37qykH4Dly5dX1hfA2rVrK+vrnHPOqayvhx56qLK+zj777Mr6Auju7q6kn4ULFw64zLvfZolxqM0S41CbJcahNkuMQ22WGIfaLDEOtVliHGqzxDjUZokpFGpJ50l6Kb/M7E1lF2VmjRs01PnlXW4juzDeScBsSSeVXZiZNabISD0NeCUi1kbELmAx2SVuzKwNFQn1Cex7qdr19HN52Xw2iaclPV3ljyzMbF9NO1EWEbdHRHdEdI8aNapZqzWzOhUJ9Qb2vf50F8WvGW1mFSsS6hXAxyVNkXQEcDnwYLllmVmjBr1IQkT0SbqebEqSDuCOiGjp1KdmNrBCVz6JiEeAR0quxcyawN8oM0uMQ22WGIfaLDEOtVliHGqzxDjUZolxqM0SU9pUtsOHVzNLbpVTuKxbt27wRk10wQUXVNbXqlWrKutr165dlfU1cuTIyvoC2LJlSyX9fPDBBwMu80htlhiH2iwxDrVZYhxqs8Q41GaJcajNEuNQmyXGoTZLjENtlhiH2iwxRWbouEPSZknPV1GQmQ1NkZH6+8B5JddhZk0yaKgjYhnwTgW1mFkTNO2Y2tPumLUHT7tjlhif/TZLjENtlpgif9K6B3gSmCppvaRryy/LzBpVZC6t2VUUYmbN4d1vs8Q41GaJcajNEuNQmyXGoTZLjENtlhiH2iwxpcyNI4lhw6r5vKhyWpU5c+ZU1hfAlClTKuurq6ursr6mTZtWWV9VbhfAjh07Kumno6NjwGUeqc0S41CbJcahNkuMQ22WGIfaLDEOtVliHGqzxDjUZolxqM0S41CbJabINcomSFoq6UVJL0i6oYrCzKwxRb773Qd8JSKekTQGWCnpsYh4seTazKwBRabdeTMinsnv7wBWAyeUXZiZNaauY2pJk4FTgaf6WeZpd8zaQOFQSxoN/BC4MSK277/c0+6YtYdCoZY0gizQiyLi/nJLMrOhKHL2W8BCYHVE3Fp+SWY2FEVG6unAlcBMSc/ltwtKrsvMGlRk2p0nAFVQi5k1gb9RZpYYh9osMQ61WWIcarPEONRmiXGozRLjUJslxqE2S0wpc2lFBH19fWWs+gBnnnlmJf0AzJgxo7K+AObNm1dZXxMnTqysr9NPP72yvs4444zK+gK47777KunnYHPVeaQ2S4xDbZYYh9osMQ61WWIcarPEONRmiXGozRLjUJslxqE2S0yRCw8eJWm5pFX5tDs3V1GYmTWmyNdEe4GZEfFefqngJyQ9GhE/K7k2M2tAkQsPBvBe/nBEfosyizKzxhW9mH+HpOeAzcBjEeFpd8zaVKFQR8TuiDgF6AKmSfpkP2087Y5ZG6jr7HdEbAWWAueVU46ZDVWRs9/HShqX3x8JfBZYU3ZhZtaYIme/jwPulNRB9iFwb0Q8XG5ZZtaoIme//4dsTmozOwT4G2VmiXGozRLjUJslxqE2S4xDbZYYh9osMQ61WWIcarPElDLtjiQ6OjrKWPUBLrzwwkr6AXj33Xcr6wtg/PjxlfV17rnnVtbXpEmTKutrzZpqv9G8bdu2SvrZvXv3gMs8UpslxqE2S4xDbZYYh9osMQ61WWIcarPEONRmiXGozRLjUJslxqE2S0zhUOcX9H9Wki86aNbG6hmpbwBWl1WImTVH0Wl3uoALgQXllmNmQ1V0pP4WMBfYM1CD2rm0enp6mlKcmdWvyAwdFwGbI2LlwdrVzqXV2dnZtALNrD5FRurpwMWSXgMWAzMl3V1qVWbWsEFDHRFfi4iuiJgMXA78NCKuKL0yM2uI/05tlpi6LmcUEY8Dj5dSiZk1hUdqs8Q41GaJcajNEuNQmyXGoTZLjENtlhiH2iwxpUy709fXV9kUNb29vZX0A7Bs2bLK+gK4/vrrK+tr6tSplfU1f/78yvpasWJFZX0BHHnkkZX0ExEDLvNIbZYYh9osMQ61WWIcarPEONRmiXGozRLjUJslxqE2S4xDbZYYh9osMYW+JppfSXQHsBvoi4juMosys8bV893vT0fEW6VVYmZN4d1vs8QUDXUA/yFppaTr+mtQO+3O+++/37wKzawuRXe/Z0TEBknjgcckrYmIfX6HGBG3A7cDjB8/fuDfhZlZqQqN1BGxIf/vZuABYFqZRZlZ44pMkNcpacze+8BvA8+XXZiZNabI7vfHgAck7W3/bxHx41KrMrOGDRrqiFgLnFxBLWbWBP6TllliHGqzxDjUZolxqM0S41CbJcahNkuMQ22WmFKm3ZHEiBEjylj1ARYtWlRJPwCLFy+urC+A55+v7ot7M2bMqKyvefPmVdZXldMJQXWv47BhA4/HHqnNEuNQmyXGoTZLjENtlhiH2iwxDrVZYhxqs8Q41GaJcajNEuNQmyWmUKgljZO0RNIaSaslnVV2YWbWmKLf/f428OOI+F1JRwCjSqzJzIZg0FBLGgucA1wNEBG7gF3llmVmjSqy+z0F2AJ8T9Kzkhbk1//eh6fdMWsPRUI9HDgNmB8RpwI9wE37N4qI2yOiOyK6R44c2eQyzayoIqFeD6yPiKfyx0vIQm5mbWjQUEfERmCdpL2/Np8FvFhqVWbWsKJnv78ELMrPfK8FrimvJDMbikKhjojngO6SazGzJvA3yswS41CbJcahNkuMQ22WGIfaLDEOtVliHGqzxDjUZokpZS6tiKC3t7eMVR9g06ZNlfQD0Nl5wI/TSrV06dLK+tq+fXtlfR1xxBGV9TVu3LjK+moXHqnNEuNQmyXGoTZLjENtlhiH2iwxDrVZYhxqs8Q41GaJcajNEjNoqCVNlfRczW27pBurKM7M6jfo10Qj4iXgFABJHcAG4IGS6zKzBtW7+z0LeDUiXi+jGDMbunpDfTlwT38LPO2OWXsoHOr8mt8XA/f1t9zT7pi1h3pG6vOBZyKiut86mlnd6gn1bAbY9Taz9lEo1PnUtZ8F7i+3HDMbqqLT7vQAHy25FjNrAn+jzCwxDrVZYhxqs8Q41GaJcajNEuNQmyXGoTZLjENtlhhFRPNXKm0B6v155jHAW00vpj2kum3ertaZFBHH9reglFA3QtLTEdHd6jrKkOq2ebvak3e/zRLjUJslpp1CfXurCyhRqtvm7WpDbXNMbWbN0U4jtZk1gUNtlpi2CLWk8yS9JOkVSTe1up5mkDRB0lJJL0p6QdINra6pmSR1SHpW0sOtrqWZJI2TtETSGkmrJZ3V6prq1fJj6nyCgP8lu1zSemAFMDsiXmxpYUMk6TjguIh4RtIYYCVw6aG+XXtJ+jLQDRwdERe1up5mkXQn8J8RsSC/gu6oiNja6rrq0Q4j9TTglYhYGxG7gMXAJS2uacgi4s2IeCa/vwNYDZzQ2qqaQ1IXcCGwoNW1NJOkscA5wEKAiNh1qAUa2iPUJwDrah6vJ5E3/16SJgOnAk+1tpKm+RYwF9jT6kKabAqwBfhefmixIL/o5iGlHUKdNEmjgR8CN0bE9lbXM1SSLgI2R8TKVtdSguHAacD8iDgV6AEOuXM87RDqDcCEmsdd+XOHPEkjyAK9KCJSubzydOBiSa+RHSrNlHR3a0tqmvXA+ojYu0e1hCzkh5R2CPUK4OOSpuQnJi4HHmxxTUMmSWTHZqsj4tZW19MsEfG1iOiKiMlk/69+GhFXtLispoiIjcA6SVPzp2YBh9yJzULX/S5TRPRJuh74CdAB3BERL7S4rGaYDlwJ/FzSc/lzfx4Rj7SwJhvcl4BF+QCzFrimxfXUreV/0jKz5mqH3W8zayKH2iwxDrVZYhxqs8Q41GaJcajNEuNQmyXm/wGyXzYGoKXQTwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "learnt_bias = model.lin.bias.cpu().detach()\n",
        "learnt_weights = model.lin.weight.cpu().detach()\n",
        "print(f\"Bias: {learnt_bias}\")\n",
        "for i in range(10):\n",
        "  plt.imshow(learnt_weights[i].reshape((8, 8)), cmap=\"gray\")\n",
        "  plt.title(f\"Prototype of the {i} class\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is7Z94v83efi"
      },
      "source": [
        "Otherwise with more complex model you can still see the distribution of the classes as learnt by the model through some visualization techniques. Personally I like very much [t-sne](https://lvdmaaten.github.io/tsne/): it allows to project into low dimensional representation (e.g. 2D) data which lies in very high dimensional spaces. \n",
        "\n",
        "Here is an example on the weights learnt by the network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "UVPJ69J44gyL",
        "outputId": "2260aa74-a58b-4d5f-9fac-3df6fb0104fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:986: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "projected_weights = TSNE(n_components=2, init=\"pca\", learning_rate='auto').fit_transform(learnt_weights)\n",
        "sns.scatterplot(x=projected_weights[:,0], y=projected_weights[:,1], hue=(str(i) for i in range(10)), legend=False)\n",
        "[plt.text(projected_weights[i,0], projected_weights[i,1], s=str(i)) for i in range(10)]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlmezIow6cZy"
      },
      "source": [
        "But you can do it for all the samples in the dataset as well!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2nJUIJl6b-V"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "projected_samples = TSNE(n_components=2, init=\"pca\", learning_rate='auto').fit_transform(x)\n",
        "sns.scatterplot(x=projected_samples[:,0], y=projected_samples[:,1], hue=[str(y_i) for y_i in y])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NFq0fhbGP-F"
      },
      "source": [
        "## Closing thoughts\n",
        "\n",
        "We now have a general data pipeline and training loop which you can use for\n",
        "training many types of models using Pytorch. \n",
        "\n",
        "We promised at the start of this tutorial we'd explain through example each of\n",
        "``torch.nn``, ``torch.optim``, ``Dataset``, and ``DataLoader``. So let's summarize\n",
        "what we've seen:\n",
        "\n",
        " - **torch.nn**\n",
        "\n",
        "   + ``Module``: creates a callable which behaves like a function, but can also\n",
        "     contain state(such as neural net layer weights). It knows what ``Parameter`` (s) it\n",
        "     contains and can zero all their gradients, loop through them for weight updates, etc.\n",
        "   + ``Parameter``: a wrapper for a tensor that tells a ``Module`` that it has weights\n",
        "     that need updating during backprop. Only tensors with the `requires_grad` attribute set are updated\n",
        "   + ``functional``: a module(usually imported into the ``F`` namespace by convention)\n",
        "     which contains activation functions, loss functions, etc, as well as non-stateful\n",
        "     versions of layers such as convolutional and linear layers.\n",
        " - ``torch.optim``: Contains optimizers such as ``SGD``, which update the weights\n",
        "   of ``Parameter`` during the backward step\n",
        " - ``Dataset``: An abstract interface of objects with a ``__len__`` and a ``__getitem__``,\n",
        "   including classes provided with Pytorch such as ``TensorDataset``\n",
        " - ``DataLoader``: Takes any ``Dataset`` and creates an iterator which returns batches of data.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gAa3H3EkGP9_",
        "spVPEQSbGP9_",
        "J_RoAmr7GP-A",
        "FEADjDjZGP-E",
        "6NFq0fhbGP-F"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
