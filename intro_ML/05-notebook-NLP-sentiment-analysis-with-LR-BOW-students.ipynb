{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01-notebook-NLP-sentiment-analysis-with-LR-students.ipynb","provenance":[],"collapsed_sections":["VQvQni-N2Cqc","NVuZV9x62Cqv"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BCNRejgk2CqQ"},"source":["# Case Study: Sentiment Analysis\n","\n","Text classification is a machine learning technique that assigns a set of predefined categories to open-ended text. Text classifiers can be used to organize, structure, and categorize pretty much any kind of text – from documents, medical studies and files, and all over the web.\n","\n","For example, new articles can be organized by topics; support tickets can be organized by urgency; chat conversations can be organized by language; brand mentions can be organized by sentiment; and so on.\n","\n","Text classification is one of the fundamental tasks in natural language processing with broad applications such as **sentiment analysis**, topic labeling, spam detection, and intent detection.\n","\n","**Why is Text Classification Important?**\n","\n","It’s estimated that around 80% of all information is unstructured, with text being one of the most common types of unstructured data. Because of the messy nature of text, analyzing, understanding, organizing, and sorting through text data is hard and time-consuming, so most companies fail to use it to its full potential.\n","\n","This is where text classification with machine learning comes in. Using text classifiers, companies can automatically structure all manner of relevant text, from emails, legal documents, social media, chatbots, surveys, and more in a fast and cost-effective way. This allows companies to save time analyzing text data, automate business processes, and make data-driven business decisions.\n","\n","**How Does Text Classification Work?**\n","\n","Instead of relying on manually crafted rules, machine learning text classification learns to make classifications based on past observations. By using pre-labeled examples as training data, machine learning algorithms can learn the different associations between pieces of text, and that a particular output (i.e., tags) is expected for a particular input (i.e., text). A “tag” is the pre-determined classification or category that any given text could fall into.\n","\n","The first step towards training a machine learning NLP classifier is feature extraction: a method is used to transform each text into a numerical representation in the form of a vector. One of the most frequently used approaches is bag of words, where a vector represents the frequency of a word in a predefined dictionary of words.\n","\n","Then, the machine learning algorithm is fed with training data that consists of pairs of feature sets (vectors for each text example) and tags (e.g. sports, politics) to produce a classification model:\n","\n","![training](https://monkeylearn.com/static/507a7b5d0557f416857a038f553865d1/2ed04/text_process_training.webp)\n","\n","Once it’s trained with enough training samples, the machine learning model can begin to make accurate predictions. The same feature extractor is used to transform unseen text to feature sets, which can be fed into the classification model to get predictions on tags (e.g., sports, politics):\n","\n","![prediction](https://monkeylearn.com/static/afa7e0536886ee7152dfa4c628fe59f0/2b924/text_process_prediction.webp)\n","\n","Text classification with machine learning is usually much more accurate than human-crafted rule systems, especially on complex NLP classification tasks. Also, classifiers with machine learning are easier to maintain and you can always tag new examples to learn new tasks."]},{"cell_type":"code","metadata":{"id":"H2LHlNq02CqX"},"source":["\"\"\"\n","(Practical tip) Table of contents can be compiled directly in jupyter notebooks using the following code:\n","I set an exception: if the package is in your installation you can import it otherwise you download it \n","then import it.\n","\"\"\"\n","try:\n","    from jyquickhelper import add_notebook_menu \n","except:\n","    !pip install jyquickhelper\n","    from jyquickhelper import add_notebook_menu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJY3IDY42Cqa"},"source":["\"\"\"\n","Output Table of contents to navigate easily in the notebook. \n","For interested readers, the package also includes Ipython magic commands to go back to this cell\n","wherever you are in the notebook to look for cells faster\n","\"\"\"\n","add_notebook_menu()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VQvQni-N2Cqc"},"source":["## 0. Today lab\n","\n","In this lab we use part of the 'Amazon_Unlocked_Mobile.csv' dataset published by Kaggle. The dataset contain the following information:\n","* Product Name\n","* Brand Name\n","* Price\n","* Rating\n","* Reviews\n","* Review Votes\n","\n","We are mainly interested by the 'Reviews' (X) and by the 'Rating' (y)\n","\n","The goal is to try to predict the 'Rating' after reading the 'Reviews'. I've prepared for you TRAIN and TEST set."]},{"cell_type":"markdown","metadata":{"id":"L2Ti1vXd2Cqc"},"source":["## 1. Load and study the dataset"]},{"cell_type":"markdown","metadata":{"id":"Ogk9yG0N2Cqd"},"source":["### 1.1. Imports"]},{"cell_type":"code","metadata":{"id":"CqS_yFTz2Cqd"},"source":["import pandas as pd\n","import numpy as np\n","#import nltk\n","import pylab as pl # package inheriting most of matplotlib package functions with shorter syntax \n","import seaborn as sns \n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FeksHxZ52Cqe"},"source":["### 1.2. [About Train, validation and test sets](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7)\n","![test/train/val](https://miro.medium.com/max/1466/1*aNPC1ifHN2WydKHyEZYENg.png)\n","\n","* **Training Dataset:** The sample of data used to fit the model.\n","* **Validation Dataset:** The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration.\n","* **Test Dataset:** The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset."]},{"cell_type":"code","metadata":{"id":"zqotUQob2Cqe"},"source":["TRAIN = pd.read_csv(\"http://www.i3s.unice.fr/~riveill/dataset/Amazon_Unlocked_Mobile/train.csv.gz\")\n","VAL = pd.read_csv(\"http://www.i3s.unice.fr/~riveill/dataset/Amazon_Unlocked_Mobile/val.csv.gz\")\n","TEST = pd.read_csv(\"http://www.i3s.unice.fr/~riveill/dataset/Amazon_Unlocked_Mobile/test.csv.gz\")\n","\n","TRAIN.head(10)#pass an integer value to specify the number of header lines to output. "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZtZ9fkdR2Cqf"},"source":["### 1.3. Understand the train dataset"]},{"cell_type":"code","metadata":{"id":"Yv78DSsp2Cqf","scrolled":true},"source":["# Tokenized the reviews\n","from nltk.tokenize import word_tokenize\n","#nltk.download('punkt') # If nltk requires to download 'punkt' depending on your installation\n","reviews_tokenized = [word_tokenize(review) for review in TRAIN['Reviews']]\n","for sentence in reviews_tokenized[:10]: print('%s \\n'%sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-DstMsLw2Cqg"},"source":["# Count the vocabulary\n","flatten_reviews = [item for sublist in reviews_tokenized for item in sublist] # contain all words \n","unique_words = list(set(flatten_reviews)) #processed as a list for future analysis\n","vocabulary_size = len(unique_words) # set allows to get unique words contain in flatten_reviews\n","vocabulary_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xT6zfZ4Z2Cqh"},"source":["# Plot the distribution of words\n","from nltk import FreqDist\n","\n","freqDist = FreqDist(flatten_reviews)\n","print(freqDist.most_common(20))\n","full_counts = [x[1] for x in freqDist.most_common()]\n","freqDist.plot(25, cumulative=False)\n","pl.show()\n","pl.figure(figsize=(8,5))\n","#plot\n","sns.kdeplot(full_counts)\n","#labeling features for readibility you have to think about while presenting your results\n","pl.xlabel('word occurrence'); pl.ylabel('probability density'); pl.title('word occurences distribution')\n","pl.show()\n","\n","# most of the time, the most common words are linking words, basic verbs, punctuation\n","# For instance, One can wonder either rare words are more significant for discriminative purposes."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLaJktYA2Cqh"},"source":["# Plot the distibution of word length size\n","len_words = [len(w) for w in flatten_reviews]\n","freqDist2 = FreqDist(len_words)\n","pl.figure(figsize=(8,6))\n","pl.title('word length')\n","freqDist2.plot(cumulative=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RuftOA7X2Cqi"},"source":["# Plot the distribution of sentence lengths\n","len_sentences = [len(s) for s in reviews_tokenized]\n","pl.figure(figsize=(8,6))\n","sns.kdeplot(len_sentences)\n","pl.xlabel('sentence length'); pl.ylabel('density');pl.title('sentence lengths distribution')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_CQEXm-2Cqj"},"source":["# Build a function named get_ngrams that return the list of n grams of a text.\n","from nltk.tokenize import word_tokenize\n","from nltk.util import ngrams\n","\n","def get_ngrams(text, n ):\n","    if len(word_tokenize(text)) < n :\n","        return []\n","    n_grams = ngrams(word_tokenize(text), n)\n","    return [ ' '.join(grams) for grams in n_grams]\n","\n","# Use this function to output/print the ngrams of the following text\n","text = \"I love the chocolate but I hate tea\"\n","\n","get_ngrams('This is the simplest text i could think of', 3 )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9gggq2E2Cqj"},"source":["# For each reviews calculate its 3grams\n","ngrams_reviews = [get_ngrams(' '.join(r), 3) for r in reviews_tokenized]\n","ngrams_reviews[:2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6mKAQIIF2Cqk"},"source":["###  1.4. What about your validation split ?\n","\n","Questions left to the students:\n","\n","    - Is the vocabulary observed in the validation dataset included in the train dataset?\n","    - How similar are distributions of word occurences or word lengths?\n","    - Same for sentence-wise distributions? \n","\n","In practice you do not have prior knowledge on the classification labels of the test dataset, and you want to infer these i.e. be able to generalize this categorization based on known labels of the train dataset. So you use the validation dataset to measure the generalization ability of your model learned on the train dataset.\n","\n","However, you have access to observations from all datasets split (sentences here) in stationary cases (to contrast to online settings where new data comes on the fly)."]},{"cell_type":"code","metadata":{"id":"P0lWXgT_2Cql"},"source":["VAL.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qd20ZUf92Cql"},"source":["\"\"\"\n","Tokenized the reviews of the validation dataset\n","Code previously used for processing the train dataset fails on the validation dataset\n","This is a common situation while dealing with real life datasets built by non machine-learning practitioners.\n","So we also have to know how to preprocess row data.\n","Common problems contain in real life dataset:\n","    contain NaN values; values type are not consistent among a given dataset feature etc.. \n","\"\"\"\n","run_failure = False#True\n","if run_failure: #This code will give you an error\n","    reviews_tokenized_val = [word_tokenize(review) for review in VAL['Reviews']]\n","    for sentence in reviews_tokenized_val[:10]: print('%s \\n'%sentence)\n","else: # Here for practical reasons we just show how to deal with this issue using exceptions\n","    reviews_tokenized_val= []\n","    failed_review=[]\n","    for review in VAL['Reviews']:\n","        try: # Store the result of the function word_tokenize applied on current review if it does not fail \n","            reviews_tokenized_val.append(word_tokenize(review))\n","        except:\n","            failed_review.append(review)\n","            continue\n","    print('How many fails over the whole Validation reviews ? ', len(VAL['Reviews']) - len(reviews_tokenized_val))\n","    print('Look at failures to understand why it happened ? \\nlist of bugged reviews: %s'%failed_review)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbetI5wb2Cqm"},"source":["# validation vocabulary\n","flatten_reviews_val = [item for sublist in reviews_tokenized_val for item in sublist]\n","unique_words_val = list(set(flatten_reviews_val))\n","vocabulary_size_val = len(unique_words_val)\n","print('TRAIN dataset - vocabulary size: %s \\nVAL dataset - vocabulary size: %s '%(vocabulary_size,vocabulary_size_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9fxYv_a2Cqn"},"source":["# Are words in the VALIDATION reviews contained in the TRAINING ones? \n","included_words = []\n","excluded_words = []\n","for word in unique_words_val:\n","    if word in unique_words:\n","        included_words.append(word)\n","    else:\n","        excluded_words.append(word)\n","print('Number of INCLUDED words: %s \\nNumber of EXCLUDED words:%s'%(len(included_words),len(excluded_words)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYD9w73i9XlM"},"source":["# [TO DO - Students] Plot most frequent words present in the validation dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXxFi_PR2Cqo"},"source":["# Plot the distribution of word occurences\n","## Start with plotting the word occurences with distributions from VAL and TRAIN next to each other\n","pl.figure(figsize=(12,5))\n","pl.subplot(121)\n","sns.kdeplot(full_counts_val)\n","pl.xlabel('word occurrence'); pl.ylabel('probability density'); pl.title('[VAL] word occurences distribution')\n","pl.subplot(122)\n","sns.kdeplot(full_counts)\n","pl.xlabel('word occurrence'); pl.ylabel('probability density'); pl.title('[TRAIN] word occurences distribution')\n","pl.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8PLZdAn7oa6T"},"source":["# [TO DO - Students] Then do the same thing for word lengths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEifM2dY2Cqp"},"source":["#  [TO DO - Students] Plot the distribution of sentence lengths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RTlqzhx-2Cqp"},"source":["#  [TO DO - Students] Plot the distribution of word lengths"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d8DZsmx82Cqq"},"source":["## 2. Sentence Classifications"]},{"cell_type":"markdown","metadata":{"id":"EMazEWld2Cqq"},"source":["### 2.1. Build X (features vectors) and y (labels)"]},{"cell_type":"code","metadata":{"id":"LK6otSJU2Cqq"},"source":["# Construct X_train and y_train\n","X_train = TRAIN['Reviews'].fillna(\"\")\n","y_train = TRAIN['Rating']\n","X_train.shape, y_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1u-bbHc32Cqr"},"source":["# Construct X_val and y_val\n","X_val = VAL['Reviews'].fillna(\"\")\n","y_val = VAL['Rating']\n","X_val.shape, y_val.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMZtc-wc2Cqr"},"source":["# Construct X_test and y_test\n","X_test = TEST['Reviews'].fillna(\"\")\n","y_test = TEST['Rating']\n","X_test.shape, y_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OX1lUZ1Q2Cqr"},"source":["### 2.2. Build a Baseline\n","Using a binary `CountVectorizer` and a `LogisticRegression` classifier, learned in a previous lecture, build a first model.\n","\n","For this model, you will not pre-process the text and will only use words (not N-grams). Leaves all parameter as default.\n","\n","The evaluation metric is accuracy."]},{"cell_type":"markdown","metadata":{"id":"xBO3PedQ2Cqs"},"source":["$$[TO DO - Students]$$\n","\n","Explain in your own words both classification models (CountVectorizer & Logistic Regression), feel free to specify key features/hyperparameters of these models that seem the most important ones to tune and explain why. You can include it at the end of the notebook for your conclusion. "]},{"cell_type":"code","metadata":{"id":"SGiYlqFJ2Cqs"},"source":["# Encode X_train\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","cv = CountVectorizer()\n","cv.fit(X_train)\n","X_train_encoded = cv.transform(X_train)\n","X_train_encoded.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JjFPaQlJ2Cqs"},"source":["# What is the vocabulary size ?\n","# Compare with your previous response\n","len(cv.vocabulary_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubIzPYN52Cqt"},"source":["# What is the stop words used\n","cv.stop_words_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KzN0-sr2Cqt"},"source":["# Transform and then inverse transform the following text\n","# Interpret the result\n","text = \"I love the chocolate but I hate tea\"\n","\n","cv.inverse_transform(cv.transform([text]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dP2JB3QR2Cqt"},"source":["# Using LogisticRegression from sklearn, fit a first model\n","from sklearn.linear_model import LogisticRegression\n","\n","lr = LogisticRegression() # Keep default settings we will look into hyperparameters fine-tuning later on\n","lr.fit(X_train_encoded, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPIoyA5H2Cqu"},"source":["# Encode X_test\n","X_test_encoded = cv.transform(X_test)\n","X_test_encoded.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIksonBA2Cqu"},"source":["# Using classification_report, evaluate the model\n","from sklearn.metrics import classification_report\n","\n","y_pred = lr.predict(X_test_encoded)\n","print(classification_report(y_pred, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F1K-1HTE2Cqu"},"source":["$$[ TO DO - Students]$$\n","\n","What do these outputted classsification metrics mean? Interpret these results.  You can include it at the end of the notebook for your conclusion. "]},{"cell_type":"markdown","metadata":{"id":"NVuZV9x62Cqv"},"source":["### 2.3. A better classifier with a preprocessing\n","\n","It's up to you. Try to get a better score (accuracy) using what we have seen in this course:\n","- efficient text pre-processing\n","- choice of feature extraction\n","- use of a more powerful classifier or better hyper-parameter for LogisticRegression.\n","\n","The training of the model must be done on the Train and the evaluation on the Test. You can of course use GridSearchCV or RandomizedSearchCV."]},{"cell_type":"markdown","metadata":{"id":"V9rPR4BZ2Cqv"},"source":["# Some pre-processing"]},{"cell_type":"code","metadata":{"id":"Zp-1Tl7c2Cqv"},"source":["# Write a \"clean_text\" function that accepts a text as input and returns a clean text.\n","# The possible steps (take what you want) are:\n","# - removal of emoji\n","# - lowercase the text\n","# - remove punctuation\n","# - remove words containing numbers\n","# - remove stop words\n","# - stemming or lemmatization\n","# - remove words smaller than nfrom nltk.corpus import stopwords\n","from nltk.tokenize import WhitespaceTokenizer\n","from nltk.stem import WordNetLemmatizer, PorterStemmer\n","from nltk.corpus import stopwords\n","\n","\n","stemmer = PorterStemmer().stem\n","\n","def clean_text(text):\n","    # [TO DO - Students] Create your own preprocessing function\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hfG7bdO2Cqw"},"source":["# Clean, X_train and X_test with the previous preprocessing\n","X_train_cleaned = [clean_text(r) for r in X_train]\n","X_test_cleaned = [clean_text(r) for r in X_test]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdlYMM5w2Cqw"},"source":["# Build, Fit and Evaluate a model using the previous preprocessing\n","# Did you improve the result ? \n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score\n","\n","cv = CountVectorizer(analyzer='word', binary=True)\n","cv.fit(X_train_cleaned)\n","X_train_encoded = cv.transform(X_train_cleaned)\n","\n","X_test_encoded = cv.transform(X_test_cleaned)\n","\n","lr = LogisticRegression()\n","lr.fit(X_train_encoded, y_train)\n","y_pred = lr.predict(X_test_encoded)\n","\n","print('accuracy score: ',accuracy_score(y_pred, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_jUuzJuA2Cqx"},"source":["### 2.4. Search hyper-parameters\n","\n","![GridSearch](https://i.stack.imgur.com/81Yoo.png)"]},{"cell_type":"code","metadata":{"id":"NG803sda2Cqx"},"source":["# Using Grid Search or Random Search try to find some better hyperparameters\n","from nltk import word_tokenize          \n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n","\n","\n","# I use my own tokenizer\n","class MyTokenizer:\n","    def __call__(self, doc):\n","        return [clean_text(t) for t in word_tokenize(doc)]\n","\n","# I define the pipeline\n","pipeline = Pipeline([\n","        ('feature_extraction',  TfidfVectorizer(tokenizer=MyTokenizer())),\n","        ('classification',  LogisticRegression(multi_class='auto', max_iter=400))\n","        ])\n","\n","# I define the parameter space\n","# [TO DO - Students] Etablissez les paramètres à parcourir de votre choix pour la GridSearchCV \n","parameters = {}\n","parameters['feature_extraction__...'] = [...]\n","parameters['feature_extraction__...'] = [...]\n","parameters['feature_extraction__...'] = [...]\n","\n","parameters['classification__...'] = [...]\n","parameters['classification__...'] = [...]\n","\n","\n","# I use GridSearchCV to search best hyper parameter\n","# I use RandomizedSearchCV to search good hyper parameter\n","\n","\n","grid = GridSearchCV(pipeline, parameters, scoring='accuracy', cv=3, verbose=2,n_jobs=None)\n","grid.fit(X_train, y_train);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PGJC0fZz2Cqx"},"source":["## 3. Summarize your conclusion here"]},{"cell_type":"code","metadata":{"id":"9H3XSpN_2Cqy"},"source":["# What is your best params\n","grid.best_params_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWwl8eok2Cqy"},"source":["# What is your best score\n","grid.best_score_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqqNBzQ62Cqy"},"source":["# What is your best estimator\n","grid.best_estimator_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ePj7XyI12Cqz"},"source":["A random draw with balanced classes (as much data from each class) would give an accuracy of 20% (1/5). We notice that a very light pre-processing or even no pre-processing already gives much better results (around 65-66%) and that it is not easy to do much better."]},{"cell_type":"code","metadata":{"id":"BCmtw3AU2Cqz"},"source":["# Print/plot the confusion matrix\n","from sklearn.metrics import plot_confusion_matrix\n","\n","plot_confusion_matrix(grid, X_test, y_test, normalize=='false');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0qxciA62Cqz"},"source":["The confusion matrix helps us understand the quality of the results. On the diagonal we find the quality of the predictions for a given class:\n","* Class 1 is found around 70 %.\n","* Class 2, 3 have a low score < 10%.\n","* Class 4 is found around 16-20 %\n","* Class 5 is found more than 90 %\n","\n","On one line is the way the original class was found. For example for class 2 (depend the run) :\n","* at 59%, the predictor says that a data of this class is of class 1\n","* at 4% of the right class (the 2)\n","* at 2% of class 3\n","* at 4% of class 4\n","* at 31% of class 5\n","The sum is 100%."]}]}