{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfp1U9PMeQU1"
   },
   "source": [
    "# TP CNN\n",
    "\n",
    "### Diane LINGRAND\n",
    "\n",
    "diane.lingrand@univ-cotedazur.fr  \n",
    "2021-2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo8ucmMpgEp9"
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:15:27.613140Z",
     "start_time": "2021-11-27T16:15:27.605763Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "68uwyRRi4BMK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMrLWuFy9gn7"
   },
   "source": [
    "**The GPU**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TO0xCfDwz-zT"
   },
   "source": [
    "To enable GPU backend in Google colab for your notebook:\n",
    "\n",
    "1.  Runtime (top left corner) -> Change runtime type\n",
    "2.  Put GPU as \"Hardware accelerator\"\n",
    "3.  Save.\n",
    "\n",
    "Or run the next cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:01:19.986158Z",
     "start_time": "2021-11-27T16:01:19.712649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 11:55:34.791274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 11:55:34.791521: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/joris/Documents/uca-msc-dsai/intro-DL/06-notebook-CNN.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joris/Documents/uca-msc-dsai/intro-DL/06-notebook-CNN.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(device_name)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joris/Documents/uca-msc-dsai/intro-DL/06-notebook-CNN.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m device_name \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/device:GPU:0\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/joris/Documents/uca-msc-dsai/intro-DL/06-notebook-CNN.ipynb#ch0000005?line=3'>4</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mSystemError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGPU device not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joris/Documents/uca-msc-dsai/intro-DL/06-notebook-CNN.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFound GPU at: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(device_name))\n",
      "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "print(device_name)\n",
    "if device_name != \"/device:GPU:0\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "print(\"Found GPU at: {}\".format(device_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHU7TK6FrHao"
   },
   "source": [
    "## Convolutional Neural Networks (CNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eP0L5uYbfAzC"
   },
   "source": [
    "Derived from the MLP, a convolutional neural network (CNN) is a type of artificial neural network that is specifically designed to process **pixel data**. The layers of a CNN consist of an **input layer**, an **output layer** and **hidden layers** that can include **convolutional layers**, **pooling layers**, **fully connected layers** and **normalization layers**. It exists a lot of techniques to optimize CNN, like for example the dropout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfCDrvt8qQPY"
   },
   "source": [
    "### Loading the dataset\n",
    "\n",
    "In this part, we will use photographies of animals from the kaggle dataset [animals-10](https://www.kaggle.com/alessiocorrado99/animals10). Please connect to their site before loading the dataset from this [zip file](http://www.i3s.unice.fr/~lingrand/raw-img.zip). Decompress the zip file on your disk.\n",
    "\n",
    "If you are using google colab, there is no need to download the dataset because I have a copy on my drive. You just need add to your drive this shared folder: https://drive.google.com/drive/folders/15cB1Ky-7OTUqfcQDZZyzc5HArt0GA6Sm?usp=sharing\n",
    "You need to click on the link and click on \"Add shortcut to Drive\" and then select \"My Drive\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RM78thFqt-ZY"
   },
   "source": [
    "To feed the data to a CNN, we need to shape it as required by Keras. As input, a 2D convolutional layer needs a **4D tensor** with shape: **(batch, rows, cols, channels)**. Therefore, we need to precise the \"channels\" axis, which can be seen as the number of level of color of each input: 3 channels in our case. We will fix the dimension of images according to the VGG-16 network: (224, 224).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:17:51.518829Z",
     "start_time": "2021-11-27T16:17:51.401963Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "i_yPS5rYF1Sk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, MaxPooling2D, Flatten\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# when processing time is long, it's nice to see the progress bar\n",
    "#!pip install tqdm\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IzHkKLqlZPn3"
   },
   "source": [
    "### loading train data\n",
    "\n",
    "Please read the code before running any of the cells!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:18:22.601760Z",
     "start_time": "2021-11-27T16:18:16.102817Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xkVd3v4N3LnB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "(600, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasetRoot = \"/home/lingrand/Ens/MachineLearning/animals/raw-img/\"\n",
    "# datasetRoot='/whereYouPutTheImages/'\n",
    "# datasetRoot='/content/drive/My Drive/raw-img/'\n",
    "# I suggest to reduce the number of classes for a first trial.\n",
    "# If you finish this notebook before the end of the course, you can add more classes (and images per class).\n",
    "classes = [\n",
    "    \"mucca\",\n",
    "    \"elefante\",\n",
    "    \"gatto\",\n",
    "]  # , 'cavallo', 'scoiattolo', 'ragno', 'pecora', 'farfalla', 'gallina', 'cane']\n",
    "nbClasses = len(classes)\n",
    "\n",
    "# training data\n",
    "\n",
    "rootTrain = datasetRoot + \"train/\"\n",
    "classLabel = 0\n",
    "reducedSizePerClass = 200  # in order to reduce the number of images per class\n",
    "totalImg = nbClasses * reducedSizePerClass\n",
    "xTrain = np.empty(shape=(totalImg, 224, 224, 3))\n",
    "yTrain = []\n",
    "first = True\n",
    "i = 0\n",
    "for cl in classes:\n",
    "    listImages = glob.glob(rootTrain + cl + \"/*\")\n",
    "    yTrain += [classLabel] * reducedSizePerClass  # len(listImages) # note that here ...\n",
    "    for pathImg in tqdm(\n",
    "        listImages[:reducedSizePerClass]\n",
    "    ):  # and here, we have reduced the data to be loaded (only 1000 per class)\n",
    "        img = image.load_img(pathImg, target_size=(224, 224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTrain[i, :, :, :] = im\n",
    "        i += 1\n",
    "    classLabel += 1\n",
    "print(len(yTrain))\n",
    "print(xTrain.shape)\n",
    "yTrain = tensorflow.keras.utils.to_categorical(yTrain, nbClasses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56bq9oXanGUm"
   },
   "source": [
    "In order to speed-up the time spent on this part of the lab, you may have noticed that we reduced the number of classes and the number of images per class. You can change these few lines of code if you want to work on the whole dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boNapUgGaEMj"
   },
   "source": [
    "### loading test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:39:11.565427Z",
     "start_time": "2021-11-27T16:39:05.538947Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Zwi5TBlKajtt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  0  images in test dataset.\n",
      "0\n",
      "(0, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# you need to use the same classes for the test dataset than for the train dataset\n",
    "rootTest = datasetRoot + \"test/\"\n",
    "classLabel = 0\n",
    "\n",
    "totalTestImg = 0\n",
    "for cl in classes:\n",
    "    totalTestImg += len(glob.glob(rootTest + cl + \"/*\"))\n",
    "\n",
    "print(\"There are \", totalTestImg, \" images in test dataset.\")\n",
    "xTest = np.empty(shape=(totalTestImg, 224, 224, 3))\n",
    "yTest = []\n",
    "i = 0\n",
    "\n",
    "for cl in classes:\n",
    "    listImages = glob.glob(rootTest + cl + \"/*\")\n",
    "    yTest += [classLabel] * len(listImages)\n",
    "    for pathImg in listImages:\n",
    "        img = image.load_img(pathImg, target_size=(224, 224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTest[i, :, :, :] = im\n",
    "    classLabel += 1\n",
    "print(len(yTest))\n",
    "print(xTest.shape)\n",
    "yTest = tensorflow.keras.utils.to_categorical(yTest, nbClasses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own CNN network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the simplest CNN: 1 conv2D layer + 1 pooling + 1 dense layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:33:54.152252Z",
     "start_time": "2021-11-27T16:33:54.099134Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "layers = [\n",
    "    Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        input_shape=(224, 224, 3),\n",
    "    ),\n",
    "    MaxPooling2D(pool_size=(4, 4), strides=4, padding=\"same\"),\n",
    "    Flatten(),\n",
    "    Dense(nbClasses, activation=\"softmax\"),\n",
    "]\n",
    "for layer in layers:\n",
    "    model.add(layer)\n",
    "    \n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dimension of all inputs and outputs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:33:56.687308Z",
     "start_time": "2021-11-27T16:33:56.674345Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn and test this network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:36:46.534902Z",
     "start_time": "2021-11-27T16:34:01.881134Z"
    }
   },
   "outputs": [],
   "source": [
    "# for you !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T17:26:29.630455Z",
     "start_time": "2021-11-27T17:26:21.961418Z"
    }
   },
   "outputs": [],
   "source": [
    "# for you !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "How is the accuracy or F1-measure on the test dataset?\n",
    "\n",
    "Are you satisfied by the performances?\n",
    "\n",
    "Try to modify the architecture (add layers) and some of the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDg_e-Ax3uci"
   },
   "source": [
    "### About Dropout\n",
    "\n",
    "_Study this part only if you have time for it. It concerns the previous network but prefer to study first part II and come back here after._\n",
    "\n",
    "Simply put, dropout refers to ignoring units (i.e. neurons) during the training phase of certain set of neurons which is chosen at random. By “ignoring”, I mean these units are not considered during a particular forward or backward pass.\n",
    "\n",
    "Why use dropout ? A fully connected layer occupies most of the parameters, and hence, neurons develop co-dependency amongst each other during training which curbs the individual power of each neuron leading to overfitting of training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eC5ct2L36pKC"
   },
   "source": [
    "**Let's add dropout and activation functions to the network!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y20GTiux6uy9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential(name=\"MLP model with dropout\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(200, activation=\"relu\"))\n",
    "# adding dropout to the previous layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(nbClasses, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn again your CNN with dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pre-learned network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Og1KZntwavZT"
   },
   "source": [
    "### loading VGG-16 description part and adding layers to build our own classification network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T14:11:09.440297Z",
     "start_time": "2021-10-12T14:11:09.179442Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ofrQr-x_a-Bi"
   },
   "outputs": [],
   "source": [
    "VGGmodel = VGG16(weights=\"imagenet\", include_top=False)\n",
    "VGGmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T14:11:36.842555Z",
     "start_time": "2021-10-12T14:11:36.806935Z"
    }
   },
   "outputs": [],
   "source": [
    "# we will add layers to this feature extraction part of VGG network\n",
    "m = VGGmodel.output\n",
    "# we start with a global average pooling\n",
    "m = GlobalAveragePooling2D()(m)\n",
    "# and add a fully-connected layer\n",
    "m = Dense(1024, activation=\"relu\")(m)\n",
    "# finally, the softmax layer for predictions (we have nbClasses classes)\n",
    "predictions = Dense(nbClasses, activation=\"softmax\")(m)\n",
    "\n",
    "# global network\n",
    "model = Model(inputs=VGGmodel.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6POPQoXcbPuc",
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "Can you display the architecture of this entire network?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T17:31:47.819971Z",
     "start_time": "2021-11-27T17:31:47.813952Z"
    }
   },
   "outputs": [],
   "source": [
    "# for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrLUhA2-b8Fv"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "ourCallback = tensorflow.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "# training part I: training only the classification part (the end)\n",
    "for layer in VGGmodel.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    epochs=2000,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[ourCallback],\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hgDguiNcNXZ"
   },
   "source": [
    "### fine-tune the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9jmknEpcT1_"
   },
   "source": [
    "Fine-tune the entire network if you have enough computing ressouces, otherwise, carefully choose the layers you want to fine-tune.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T14:13:56.365304Z",
     "start_time": "2021-10-12T14:13:56.350142Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cRr97-2yc6kZ"
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(VGGmodel.layers):\n",
    "    print(i, layer.name)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4eCse6wku5Q"
   },
   "source": [
    "In this example, we will fine-tune the last convolution block starting at layer number 15 (block5_conv).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C17ts6kllGUr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "for layer in model.layers[:11]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[11:]:\n",
    "    layer.trainable = True\n",
    "# need to recompile the network\n",
    "model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.0001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "# and train again ...\n",
    "model.fit(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[ourCallback],\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LrhxQiBmTZj",
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "You already know how to evaluate the performances on the test dataset and display the confusion matrix. You can also modify the code that loads the test dataset in order to reduce it's size. Let's do it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHGxb-PxmiYd"
   },
   "outputs": [],
   "source": [
    "# enter here your code for evaluation of performances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unzKoPOsgNW3",
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "You are now free to experiments changes in the network:\n",
    "\n",
    "- add a dense layer\n",
    "- modify the number of neurons in dense layer(s)\n",
    "- change the global average polling\n",
    "- add classes and data\n",
    "- experiment other optimizers (SGD, Adam, ...)\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ImageClassificationUsingDeepLearning.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "121.85px",
    "left": "491.667px",
    "right": "20px",
    "top": "120px",
    "width": "341.667px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
