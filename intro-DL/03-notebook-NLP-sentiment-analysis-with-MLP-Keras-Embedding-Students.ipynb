{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Zc0WsSkoWK0"
   },
   "source": [
    "# Sentiment analysis with an MLP and vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSuNR5g2oUqH"
   },
   "source": [
    "# Case Study: Sentiment Analysis\n",
    "\n",
    "In this lab we use part of the 'Amazon_Unlocked_Mobile.csv' dataset published by Kaggle. The dataset contain the following information:\n",
    "* Product Name\n",
    "* Brand Name\n",
    "* Price\n",
    "* Rating\n",
    "* Reviews\n",
    "* Review Votes\n",
    "\n",
    "We are mainly interested by the 'Reviews' (X) and by the 'Rating' (y)\n",
    "\n",
    "\n",
    "The goal is to try to predict the 'Rating' after reading the 'Reviews'. I've prepared for you TRAIN and TEST set.\n",
    "The work to be done is as follows:\n",
    "\n",
    "1. Feature extraction and baseline\n",
    "    * read the dataset and understand it\n",
    "    * put it in a format so that you can use `CountVectorizer` or`Tf-IDF` to extract the desired features\n",
    "    * perform on the desired dates and preprocessing\n",
    "    * use one of the classifiers you know to predict the polarity of different sentences\n",
    "1. My first neural network\n",
    "    * reuse the features already extracted \n",
    "    * proposed a neural network built with Keras\n",
    "1. Hyper-parameter fitting\n",
    "    * for the base line: adjust min_df, max_df, ngram, max_features + model's hyper-parameter\n",
    "    * for the neural network: adjust batch size, number of layers and number of neuron by layers, use earlystop\n",
    "1. <span style=\"color:red\">Word embedding\n",
    "    * stage 1 build a network that uses Keras' embedding which is not language sensitive.\n",
    "    * stage 2 build a network that simultaneously uses Keras' embedding and the features extracted in the first weeks.\n",
    "    * stage 3 try to use an existing embedding (https://github.com/facebookresearch/MUSE)\n",
    "    </span>\n",
    "\n",
    "**WARNING:** the dataset is voluminous, I can only encourage you to work first on a small part of it and only at the end, when the code is well debugged and that it is necessary to build the \"final model\", to use the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SWzS9ujoUqI",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Read-the-dataset\" data-toc-modified-id=\"Read-the-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Read the dataset</a></span></li><li><span><a href=\"#Text-normalisation\" data-toc-modified-id=\"Text-normalisation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Text normalisation</a></span></li><li><span><a href=\"#Approach1---BOW-and-MLP-classifier\" data-toc-modified-id=\"Approach1---BOW-and-MLP-classifier-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Approach1 - BOW and MLP classifier</a></span></li><li><span><a href=\"#Approach2---Keras-word-embedding-and-MLP-classifier\" data-toc-modified-id=\"Approach2---Keras-word-embedding-and-MLP-classifier-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Approach2 - Keras word embedding and MLP classifier</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLrXoRQ5oUqI"
   },
   "source": [
    "## Read the dataset\n",
    "\n",
    "Could you find below a proposal. You can complete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:50:54.228140Z",
     "start_time": "2022-01-25T18:50:54.194120Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:51:58.151238Z",
     "start_time": "2022-01-25T18:51:58.143561Z"
    },
    "id": "uMZhHXxzoUqJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Input, TextVectorization, Dense, Flatten, Embedding\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:51:59.283203Z",
     "start_time": "2022-01-25T18:51:58.181634Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "gIXGN8IzoUqJ",
    "outputId": "f9cbed6e-5c8c-45cb-e083-4a9194f12157"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Note 4 N910C Unlocked Cellphone...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>449.99</td>\n",
       "      <td>4</td>\n",
       "      <td>I love it!!! I absolutely love it!! üëåüëç</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLU Energy X Plus Smartphone - With 4000 mAh S...</td>\n",
       "      <td>BLU</td>\n",
       "      <td>139.00</td>\n",
       "      <td>5</td>\n",
       "      <td>I love the BLU phones! This is my second one t...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple iPhone 6 128GB Silver AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>599.95</td>\n",
       "      <td>5</td>\n",
       "      <td>Great phone</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLU Advance 4.0L Unlocked Smartphone -US GSM -...</td>\n",
       "      <td>BLU</td>\n",
       "      <td>51.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Very happy with the performance. The apps work...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huawei P8 Lite US Version- 5 Unlocked Android ...</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>198.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Easy to use great price</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  Samsung Galaxy Note 4 N910C Unlocked Cellphone...    Samsung  449.99   \n",
       "1  BLU Energy X Plus Smartphone - With 4000 mAh S...        BLU  139.00   \n",
       "2                   Apple iPhone 6 128GB Silver AT&T      Apple  599.95   \n",
       "3  BLU Advance 4.0L Unlocked Smartphone -US GSM -...        BLU   51.99   \n",
       "4  Huawei P8 Lite US Version- 5 Unlocked Android ...     Huawei  198.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       4             I love it!!! I absolutely love it!! üëåüëç           0.0  \n",
       "1       5  I love the BLU phones! This is my second one t...           4.0  \n",
       "2       5                                        Great phone           1.0  \n",
       "3       4  Very happy with the performance. The apps work...           2.0  \n",
       "4       5                            Easy to use great price           0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = pd.read_csv(\"http://www.i3s.unice.fr/~riveill/dataset/Amazon_Unlocked_Mobile/train.csv.gz\")\n",
    "TEST = pd.read_csv(\"http://www.i3s.unice.fr/~riveill/dataset/Amazon_Unlocked_Mobile/test.csv.gz\")\n",
    "\n",
    "TRAIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:51:59.343941Z",
     "start_time": "2022-01-25T18:51:59.302031Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdeAXW40oUqJ",
    "outputId": "d99ac22b-c7e5-4c4a-f817-d8e25ff2a28c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000,), (5000, 5), array([1, 2, 3, 4, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Construct X_train and y_train '''\n",
    "X_train = TRAIN['Reviews']\n",
    "y_train = np.array(TRAIN['Rating']).reshape(-1,1)\n",
    "\n",
    "X_test = TEST['Reviews']\n",
    "y_test = np.array(TEST['Rating']).reshape(-1,1)\n",
    "\n",
    "nb_classes = len(np.unique(y_train))\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "y_train_enc = ohe.fit_transform(y_train)\n",
    "y_test_enc = ohe.fit_transform(y_test)\n",
    "\n",
    "X_train.shape, y_train_enc.shape, np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T18:00:17.888390Z",
     "start_time": "2021-01-03T18:00:17.884865Z"
    },
    "id": "SDWDQSbEoUqL"
   },
   "source": [
    "## Approach1 - BOW and MLP classifier\n",
    "\n",
    "Using the course companion notebook, build a multi-layer perceptron using a BOW representation of the dataset and evaluate the model.\n",
    "\n",
    "The dataset being unbalanced the metric will be the f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$TO DO STUDENT$$\n",
    "> * Build BOW representation of the train and test set\n",
    "> * Fix a value for vocab_size = the maximum number of words to keep, based on word frequency. Only the most common vocab_size-1 words will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:51:59.382488Z",
     "start_time": "2022-01-25T18:51:59.362857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-21T17:12:34.858519Z",
     "start_time": "2022-01-21T17:12:34.850825Z"
    }
   },
   "source": [
    "$$TO DO STUDENT$$\n",
    "\n",
    "> * Build an MLP and print the model (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:51:59.435559Z",
     "start_time": "2022-01-25T18:51:59.417373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ TO DO STUDENT $$\n",
    "> * Compile the network\n",
    "> * Fit the network using EarlyStopping\n",
    "> * Babysit your model\n",
    "> * Evaluate the network with f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:51:59.458052Z",
     "start_time": "2022-01-25T18:51:59.451081Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7EloujaoUqM",
    "outputId": "189dd8fa-293f-450c-e513-3d1cb094fe4d"
   },
   "outputs": [],
   "source": [
    "# compile the model with f1 metrics\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:02.139166Z",
     "start_time": "2022-01-25T18:52:02.134752Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit model using ealy stopping\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:08.205615Z",
     "start_time": "2022-01-25T18:52:02.879433Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l4/ptzjj6dn0_x5trgl90dc98g40000gn/T/ipykernel_20549/66446061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Babysit the model - use you favourite plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m pd.DataFrame({#'val_loss':history.history['val_loss'],\n\u001b[0m\u001b[1;32m      3\u001b[0m               \u001b[0;31m#'loss':history.history['loss'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0;31m#'val_f1_score':history.history['val_f1_score'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0;31m# 'f1_score':history.history['f1_score'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m# no non-numeric frames or series allowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no numeric data to plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_ndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "# Babysit the model - use you favourite plot\n",
    "pd.DataFrame({#'val_loss':history.history['val_loss'],\n",
    "              #'loss':history.history['loss'],\n",
    "              #'val_f1_score':history.history['val_f1_score'],\n",
    "              # 'f1_score':history.history['f1_score'],\n",
    "              #'val_accuracy':history.history['val_accuracy'],\n",
    "              #'accuracy':history.history['accuracy']\n",
    "             }).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:15.716618Z",
     "start_time": "2022-01-25T18:52:15.704147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model with f1 metrics (Tensorflow f1 metrics or sklearn)\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4BohkzOoUqO"
   },
   "source": [
    "## Approach2 - Keras word embedding and MLP classifier\n",
    "\n",
    "Using the course companion notebook, build a multi-layer perceptron using an Embedding Keras layer and the same classifier as in approach 1. Evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ TO DO STUDENTS $$\n",
    "> * fix the max_lengh of a review (max number of token in a review)\n",
    "> * use the same vocab_size as previously\n",
    "> * fix the embedding dimension (embed_dim variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:07:40.982620Z",
     "start_time": "2022-01-22T16:07:40.978854Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = ...   # Sequence length to pad the outputs to.\n",
    "                # In order to fix it, you have to know the distribution on lengh... see first lab\n",
    "embed_dim = ... # embedding dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ TO DO STUDENTS $$\n",
    "\n",
    ">* Create a vectorizer_layer with TextVectorization function\n",
    ">* Fit the vectorizer_layer (adapt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:20.520759Z",
     "start_time": "2022-01-25T18:52:20.510528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$TO DO STUDENT$$\n",
    "\n",
    "> * Build an MLP and print the model (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:21.254213Z",
     "start_time": "2022-01-25T18:52:21.244686Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4BPv2OGoUqO",
    "outputId": "4cbf391a-81b9-447d-a0af-d6b469f85e2b"
   },
   "outputs": [],
   "source": [
    "# Your code... perhaps you need to use Flatten after Embedding in order to reduce the dimension of tensors\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ TO DO STUDENT $$\n",
    "> * Compile the network\n",
    "> * Fit the network using EarlyStopping\n",
    "> * Babysit your model\n",
    "> * Evaluate the network with f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:22.548119Z",
     "start_time": "2022-01-25T18:52:22.525400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7oN2bZkoUqP",
    "outputId": "8d7d5b26-b925-4e79-ad97-7aecd8980243"
   },
   "outputs": [],
   "source": [
    "# compile the model with metrics f1 score\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:23.009408Z",
     "start_time": "2022-01-25T18:52:23.002836Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "ZJjc2ISZoUqP",
    "outputId": "4585f6aa-bda8-4d82-885f-cece12094694"
   },
   "outputs": [],
   "source": [
    "# fit model using ealy stopping\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:23.547244Z",
     "start_time": "2022-01-25T18:52:23.306348Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1XWqf1QKoUqQ",
    "outputId": "3c73908b-3066-4c32-92f8-df458dc7f8cb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l4/ptzjj6dn0_x5trgl90dc98g40000gn/T/ipykernel_20549/1799899310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Babysit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m pd.DataFrame({'val_loss':history.history['val_loss'],\n\u001b[0m\u001b[1;32m      3\u001b[0m               \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0;34m'val_f1_score'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               'f1_score':history.history['f1_score']}).plot(figsize=(8,5))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Babysit the model\n",
    "pd.DataFrame({'val_loss':history.history['val_loss'],\n",
    "              'loss':history.history['loss'],\n",
    "             'val_f1_score':history.history['val_f1_score'],\n",
    "              'f1_score':history.history['f1_score']}).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T18:52:23.656331Z",
     "start_time": "2022-01-25T18:52:23.650537Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3I9EmdInoUqQ",
    "outputId": "2b7de358-c515-4d89-e452-a63e38bc1577"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach3 - Word embedding and MLP classifier\n",
    "\n",
    "Using the course companion notebook, build a multi-layer perceptron using an existing embedding matrix (Word2Vec / Glove or FastText), or on an embedding matrix that you will have built using Gensim.\n",
    "\n",
    "Use the same constant as a previous steps.\n",
    "\n",
    "Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:10:34.090507Z",
     "start_time": "2022-01-22T16:10:33.791036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same steps as Keras Embedding\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:10:34.616434Z",
     "start_time": "2022-01-22T16:10:34.608449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build word dict\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:10:40.482971Z",
     "start_time": "2022-01-22T16:10:35.796195Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a dict mapping words (strings) to their NumPy vector representation:\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:10:40.501686Z",
     "start_time": "2022-01-22T16:10:40.486672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare embedding matrix\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:10:40.514550Z",
     "start_time": "2022-01-22T16:10:40.505765Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define embedding layers\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:10:40.595998Z",
     "start_time": "2022-01-22T16:10:40.520383Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:12:53.907137Z",
     "start_time": "2022-01-22T16:12:53.889560Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:10.014860Z",
     "start_time": "2022-01-22T16:12:54.629020Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit model using ealy stopping\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:49.491655Z",
     "start_time": "2022-01-22T16:13:49.287384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Babysit the model\n",
    "pd.DataFrame({'val_loss':history.history['val_loss'],\n",
    "              'loss':history.history['loss'],\n",
    "             'val_f1_score':history.history['val_f1_score'],\n",
    "              'f1_score':history.history['f1_score']}).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:52.382395Z",
     "start_time": "2022-01-22T16:13:52.244523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach3 - Word embedding and MLP classifier\n",
    "\n",
    "Using the course companion notebook, build a multi-layer perceptron using an existing embedding matrix (Word2Vec / Glove or FastText), or on an embedding matrix that you will have built using Gensim.\n",
    "\n",
    "Use the same constant as a previous steps.\n",
    "\n",
    "Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:54.537177Z",
     "start_time": "2022-01-22T16:13:54.533166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Avalaible in your gensim installation... \n",
    "# You can also use the train reviews.\n",
    "corpus_path=\"/Users/riveill/opt/miniconda3/lib/python3.9/site-packages/gensim/test/test_data/\"\n",
    "corpus=\"lee_background.cor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:56.715903Z",
     "start_time": "2022-01-22T16:13:54.981458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build gensim model\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(corpus_path+corpus):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)\n",
    "            \n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences, vector_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:56.775478Z",
     "start_time": "2022-01-22T16:13:56.718276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export gensim model\n",
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    print(temporary_filepath)\n",
    "    model.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "    new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:57.290934Z",
     "start_time": "2022-01-22T16:13:57.261810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load gensim model\n",
    "new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:58.280075Z",
     "start_time": "2022-01-22T16:13:58.264761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare embedding matrix\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:13:59.350378Z",
     "start_time": "2022-01-22T16:13:59.345572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define embedding layers\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:14:00.261340Z",
     "start_time": "2022-01-22T16:14:00.113370Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:14:01.012932Z",
     "start_time": "2022-01-22T16:14:00.994486Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:17:21.897247Z",
     "start_time": "2022-01-22T16:14:01.789033Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit model using ealy stopping\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:18:06.562082Z",
     "start_time": "2022-01-22T16:18:06.339038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Babysit the model\n",
    "pd.DataFrame({'val_loss':history.history['val_loss'],\n",
    "              'loss':history.history['loss'],\n",
    "             'val_f1_score':history.history['val_f1_score'],\n",
    "              'f1_score':history.history['f1_score']}).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T16:18:19.860091Z",
     "start_time": "2022-01-22T16:18:19.555310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook-NLP-sentiment-analysis-with-MLP-Keras embedding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
